{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3cd8e0",
   "metadata": {},
   "source": [
    "# Exploring Fact-Based QA with RAG: Romeo and Juliet\n",
    "### Chris Endemann, endemann@wisc.edu\n",
    "### [Nexus version](https://uw-madison-datascience.github.io/ML-X-Nexus/Learn/Notebooks/2025-05-07_RAG-Romeo-Juliet.html)\n",
    "### Categories\n",
    "- Notebooks\n",
    "- RAG\n",
    "- Retrieval\n",
    "- NLP\n",
    "- LLM\n",
    "- Embeddings\n",
    "- Text analysis\n",
    "- Deep learning\n",
    "- Prompt engineering\n",
    "- Code-along\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the use of a Retrieval-Augmented Generation (RAG) system to answer factual questions from Shakespeare's *Romeo and Juliet*. Our long-term goal is to build a RAG-powered chatbot that supports literary exploration—helping readers investigate character dynamics, thematic development, and emotional subtext.\n",
    "\n",
    "In this first part of the demo, we focus on low-hanging fruit: factual, quote-supported questions that a RAG pipeline can answer reliably. These examples will help us introduce key RAG components, and set a performance baseline before tackling more interpretive questions. \n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Identify the key components of a basic Retrieval-Augmented Generation (RAG) system.\n",
    "- Use a sentence-transformer model to create embeddings from text passages.\n",
    "- Run simple retrieval using vector similarity and evaluate retrieved chunks.\n",
    "- Generate answers to factual questions using retrieved content as context.\n",
    "- Understand early limitations of RAG pipelines and motivate future improvements.\n",
    "\n",
    "### Step-by-step overview\n",
    "\n",
    "1. **Load the corpus**\n",
    "   - We use Shakespeare texts from the workshop's `data.csv` file.\n",
    "\n",
    "2. **Split text into chunks**\n",
    "   - Long texts are broken into smaller passages (~200 words) so they're easier to search and analyze.\n",
    "\n",
    "3. **Create embeddings**\n",
    "   - Each chunk is converted into a vector — a mathematical representation of its meaning — using a pretrained model from `sentence-transformers`.\n",
    "\n",
    "4. **Retrieve relevant chunks**\n",
    "   - When you ask a question, we embed the question and compare it to the embedded text chunks to find the most similar passages.\n",
    "\n",
    "5. **Ask a language model**\n",
    "   - We take the most relevant passages and feed them (along with your question) into a pretrained language model (like GPT-2) to generate an answer.\n",
    "\n",
    "This is not training a model from scratch — it's a lightweight, modular way to build smart question-answering tools on top of your own text collection.\n",
    "\n",
    "We'll explore the strengths and limitations of this approach along the way.\n",
    "\n",
    "## Step 1: Load the corpus\n",
    "In this example, we'll use \"Romeo and Juliet\" as our text corpus. This text is freely available via [Project Gutenberg](https://uw-madison-datascience.github.io/ML-X-Nexus/Toolbox/Data/Gutenberg.html).\n",
    "\n",
    "Preview the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812173ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Romeo and Juliet from Project Gutenberg\n",
    "import requests\n",
    "\n",
    "url = 'https://www.gutenberg.org/files/1112/1112-0.txt'\n",
    "response = requests.get(url)\n",
    "file_contents = response.text\n",
    "\n",
    "# Preview first 3000 characters\n",
    "preview_len = 3000\n",
    "print(file_contents[:preview_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393eec73",
   "metadata": {},
   "source": [
    "*** START OF THE PROJECT GUTENBERG EBOOK 1112 ***\n",
    "    \n",
    "    \n",
    "    Executive Director's Notes:\n",
    "    \n",
    "    In addition to the notes below, and so you will *NOT* think all\n",
    "    the spelling errors introduced by the printers of the time have\n",
    "    been corrected, here are the first few lines of Hamlet, as they\n",
    "    are presented herein:\n",
    "    \n",
    "      Barnardo. Who's there?\n",
    "      Fran. Nay answer me: Stand & vnfold\n",
    "    your selfe\n",
    "    \n",
    "       Bar. Long liue the King\n",
    "    \n",
    "           *       *       *       *       *\n",
    "    \n",
    "    As I understand it, the printers often ran out of certain words\n",
    "    or letters they had often packed into a \"cliche\". . .this is the\n",
    "    original meaning of the term cliche. . .and thus, being unwilling\n",
    "    to unpack the cliches, and thus you will see some substitutions\n",
    "    that look very odd. . .such as the exchanges of u for v, v for u,\n",
    "    above. . .and you may wonder why they did it this way, presuming\n",
    "    Shakespeare did not actually write the play in this manner. . . .\n",
    "    \n",
    "    The answer is that they MAY have packed \"liue\" into a cliche at a\n",
    "    time when they were out of \"v\"'s. . .possibly having used \"vv\" in\n",
    "    place of some \"w\"'s, etc.  This was a common practice of the day,\n",
    "    as print was still quite expensive, and they didn't want to spend\n",
    "    more on a wider selection of characters than they had to.\n",
    "    \n",
    "    You will find a lot of these kinds of \"errors\" in this text, as I\n",
    "    have mentioned in other times and places, many \"scholars\" have an\n",
    "    extreme attachment to these errors, and many have accorded them a\n",
    "    very high place in the \"canon\" of Shakespeare.  My father read an\n",
    "    assortment of these made available to him by Cambridge University\n",
    "    in England for several months in a glass room constructed for the\n",
    "    purpose.  To the best of my knowledge he read ALL those available\n",
    "    . . .in great detail. . .and determined from the various changes,\n",
    "    that Shakespeare most likely did not write in nearly as many of a\n",
    "    variety of errors we credit him for, even though he was in/famous\n",
    "    for signing his name with several different spellings.\n",
    "    \n",
    "    So, please take this into account when reading the comments below\n",
    "    made by our volunteer who prepared this file:  you may see errors\n",
    "    that are \"not\" errors. . . .\n",
    "    \n",
    "    So. . .with this caveat. . .we have NOT changed the canon errors,\n",
    "    here is the Project Gutenberg Etext of Shakespeare's The first\n",
    "    Part of Henry the Sixt.\n",
    "    \n",
    "    Michael S. Hart\n",
    "    Project Gutenberg\n",
    "    Executive Director\n",
    "    \n",
    "           *       *       *       *       *\n",
    "    \n",
    "    Scanner's Notes:\n",
    "    \n",
    "    What this is and isn't. This was taken from a copy of\n",
    "    Shakespeare's first folio and it is as close as I can come in\n",
    "    ASCII to the printed text.\n",
    "    \n",
    "    The elongated S's have been changed to small s's and the\n",
    "    conjoined ae have been changed to ae. I have left the spelling,\n",
    "    punctuation, capitalization as close as possible to the printed\n",
    "    text. I have corrected some spelling mistakes (I have put\n",
    "    together a spelling dictionary devised from the spellings of\n",
    "    the Geneva Bible and Shakespeare's First Folio and have unified\n",
    "    spellings according to this template), typo's and expanded\n",
    "    abbreviations as I have come across them. Everything within\n",
    "    br\n",
    "\n",
    "\n",
    "## Step 2: Split text into \"chunks\"\n",
    "Next, we define a function to split the corpus into smaller chunks based on word count. The simplest \"chunking\" approach is to chunk by word count or character count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf73c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_words=200):\n",
    "    import re  # Regular expressions will help us split the text more precisely\n",
    "\n",
    "    # Use regex to tokenize the text:\n",
    "    # This pattern splits the text into:\n",
    "    #   - words (\\w+)\n",
    "    #   - whitespace (\\s+)\n",
    "    #   - punctuation or other non-whitespace symbols ([^\\w\\s])\n",
    "    words = re.findall(r'\\w+|\\s+|[^\\w\\s]', text)\n",
    "\n",
    "    chunks = []  # List to store the resulting text chunks\n",
    "    chunk = []   # Temporary buffer to build up each chunk\n",
    "\n",
    "    # Iterate through each token (word, space, or punctuation)\n",
    "    for word in words:\n",
    "        chunk.append(word)  # Add token to the current chunk\n",
    "        if len(chunk) >= max_words:\n",
    "            # Once we reach the max word count, join tokens into a string and store the chunk\n",
    "            chunks.append(\"\".join(chunk))  # Use \"\".join() to preserve punctuation/spacing\n",
    "            chunk = []  # Reset for the next chunk\n",
    "\n",
    "    # If there's leftover content after the loop, add the final chunk\n",
    "    if chunk:\n",
    "        chunks.append(\"\".join(chunk))\n",
    "\n",
    "    return chunks  # Return list of chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d607cd",
   "metadata": {},
   "source": [
    "We then apply our chunking function to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the chunking function to your full text file\n",
    "chunks = chunk_text(file_contents, max_words=200)\n",
    "\n",
    "# Show how many chunks were created\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# Preview one of the chunks (by index)\n",
    "chunk_ex_ind = 1  # Feel free to change this number to explore different parts of the text\n",
    "print(f\"Chunk {chunk_ex_ind} \\n{chunks[chunk_ex_ind]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0a8a9",
   "metadata": {},
   "source": [
    "Number of chunks: 291\n",
    "    Chunk 1 \n",
    "     packed into a \"cliche\". . .this is the\n",
    "    original meaning of the term cliche. . .and thus, being unwilling\n",
    "    to unpack the cliches, and thus you will see some substitutions\n",
    "    that look very odd. . .such as the exchanges of u for v, v for u,\n",
    "    above. . .and you may wonder why they did it this way, presuming\n",
    "    Shakespeare did not actually write the play in this manner. . . .\n",
    "    \n",
    "    The answer is that they MAY have packed \"liue\" into a cliche at a\n",
    "    time when they were out\n",
    "\n",
    "\n",
    "## Step 3: Embed chunks with sentence transformers\n",
    "\n",
    "To enable semantic search, we need to convert our text chunks into numerical vectors—high-dimensional representations that capture meaning beyond simple keyword overlap. This process is called *embedding*, and it allows us to compare the semantic similarity between a user's question and the contents of a document.\n",
    "\n",
    "This is done using an **encoder-only transformer model**. Unlike decoder or encoder-decoder models, encoder-only models are not designed to generate text. Instead, they are optimized for understanding input sequences and producing meaningful vector representations. These models take in text and output fixed-size embeddings that capture semantic content—ideal for tasks like search, retrieval, and clustering.\n",
    "\n",
    "We'll use:\n",
    "\n",
    "- The [`sentence-transformers`](https://www.sbert.net/) library  \n",
    "  - A widely used library that wraps encoder-only transformer models for generating sentence- and paragraph-level embeddings.\n",
    "  - It provides a simple interface (`model.encode()`) and is optimized for performance and batching, making it well-suited for retrieval-augmented generation (RAG) workflows.\n",
    "  - It supports both short queries and longer document chunks, embedding them into the same shared vector space.\n",
    "\n",
    "- A pretrained model: [`multi-qa-MiniLM-L6-cos-v1`](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1)  \n",
    "  - A compact encoder-only model (6 layers) designed for semantic search and question answering.\n",
    "  - Trained using contrastive learning on query-passage pairs, so it learns to embed related questions and answers close together in vector space.\n",
    "  - It's efficient enough to run on CPUs or entry-level GPUs, making it great for experimentation and prototyping.\n",
    "\n",
    "### Why embeddings matter in RAG\n",
    "\n",
    "In a RAG system, embeddings are the foundation for connecting a user's question to the most relevant content in your corpus.\n",
    "\n",
    "Rather than relying on exact keyword matches, embeddings represent both queries and document chunks in the same semantic space. When a user asks a question, we:\n",
    "\n",
    "1. Convert the user's question into a vector using the same encoder-only embedding model that was used to encode the document chunks.\n",
    "2. Compute similarity scores (e.g., cosine similarity) between the query vector and each chunk vector.\n",
    "3. Retrieve the top-matching chunks to pass along as context to the language model.\n",
    "\n",
    "This allows the system to surface text that is meaningfully related to the question—even if it doesn't use the same words. For example, a question like \"*What does Juliet think of Romeo?*\" might retrieve a passage describing her inner turmoil or emotional reaction, even if the words \"think\" or \"Romeo\" aren't explicitly present. Embedding-based retrieval improves relevance, flexibility, and ultimately the quality of the answers your language model can generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # make sure you have GPU enabled in colab to speed things up!\n",
    "print(f'device={device}')\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1', device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018441f2",
   "metadata": {},
   "source": [
    "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
    "      import pynvml  # type: ignore[import]\n",
    "\n",
    "\n",
    "    device=cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(chunks, device=device)\n",
    "\n",
    "print(f\"Shape of embedding matrix: {np.array(embeddings).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab61a93",
   "metadata": {},
   "source": [
    "Shape of embedding matrix: (291, 384)\n",
    "\n",
    "\n",
    "**Note**: The shape of our embedding matrix is (283, 384) — representing the 283 chunks we prepared, and the 384 features describing each chunk. These are neural network derived features, lacking direct interpretability.\n",
    "\n",
    "## Step 4: Retrieve Relevant Chunks\n",
    "\n",
    "In this step, we demonstrate a core component of a RAG (Retrieval-Augmented Generation) pipeline — finding the most relevant pieces of text to answer a user's question. Here's how it works:\n",
    "\n",
    "- We take the user's question and convert it into a vector embedding using the *same model* we used to embed the original text chunks.\n",
    "- Then we use cosine similarity to compare the question's embedding to all text chunk embeddings.\n",
    "- We select the top *N* most similar chunks to use as context for the language model.\n",
    "\n",
    "### Are question embeddings and chunk embeddings really comparable?\n",
    "\n",
    "We're assuming that the embedding model (e.g., `all-MiniLM-L6-v2`) was trained in such a way that *questions and answers occupy the same semantic space*. That is, if a question and a passage are semantically aligned (e.g., about the same topic or fact), their embeddings should be close. This assumption holds reasonably well for general-purpose models trained on sentence pairs, but it's not perfect — especially for very abstract or indirect questions. If a model was only trained to embed statements, it may not align questions correctly. You might retrieve chunks that are **related but not directly useful** for answering the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def retrieve_relevant_chunks(model, query, chunks, embeddings, top_n=3):\n",
    "    query_embedding = model.encode([query],device=device)\n",
    "    scores = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    results = [(chunks[i], scores[i]) for i in top_indices]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who kills Mercutio?\" # Answer: Tybalt, Juliet's cousin\n",
    "top_chunks = retrieve_relevant_chunks(model, question, chunks, embeddings)\n",
    "\n",
    "for i, (chunk, score) in enumerate(top_chunks, 1):\n",
    "    print(f\"\\n\\n############ CHUNK {i} ############\")\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486a1b2",
   "metadata": {},
   "source": [
    "############ CHUNK 1 ############\n",
    "    Score: 0.4397\n",
    "    , he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    \n",
    "       Prin. Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "       Cap. Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "       Prin. And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest\n",
    "    \n",
    "    \n",
    "    ############ CHUNK 2 ############\n",
    "    Score: 0.4059\n",
    "    vnluckie Mannage of this fatall brall:\n",
    "    There lies the man slaine by young Romeo,\n",
    "    That slew thy kinsman braue Mercutio\n",
    "    \n",
    "       Cap. Wi. Tybalt, my Cozin? O my Brothers Child,\n",
    "    O Prince, O Cozin, Husband, O the blood is spild\n",
    "    Of my deare kinsman. Prince as thou art true,\n",
    "    For bloud of ours, shed bloud of Mountague.\n",
    "    O Cozin, Cozin\n",
    "    \n",
    "       Prin. Benuolio, who began this Fray?\n",
    "      Ben. Tybalt here slaine, whom Romeo's hand did slay,\n",
    "    Romeo that spoke him faire, bid him bethinke\n",
    "    How nice the Quarrell was, and\n",
    "    \n",
    "    \n",
    "    ############ CHUNK 3 ############\n",
    "    Score: 0.4028\n",
    "    hast, least mine be about your eares ere it be out\n",
    "    \n",
    "       Tib. I am for you\n",
    "    \n",
    "       Rom. Gentle Mercutio, put thy Rapier vp\n",
    "    \n",
    "       Mer. Come sir, your Passado\n",
    "    \n",
    "       Rom. Draw Benuolio, beat downe their weapons:\n",
    "    Gentlemen, for shame forbeare this outrage,\n",
    "    Tibalt, Mercutio, the Prince expresly hath\n",
    "    Forbidden bandying in Verona streetes.\n",
    "    Hold Tybalt, good Mercutio.\n",
    "    \n",
    "    Exit Tybalt.\n",
    "    \n",
    "      Mer. I am hurt.\n",
    "    A plague a both the Houses, I am sped:\n",
    "    Is he gone and hath nothing?\n",
    "      Ben. What art thou hurt?\n",
    "      Mer. I, I, a scratch\n",
    "\n",
    "\n",
    "### Summary: Retrieval results for factual query\n",
    "\n",
    "The following output shows how a RAG system handles the factual question \"Who kills Mercutio?\" using a chunked version of *Romeo and Juliet*. While no chunk explicitly states \"Tybalt kills Mercutio\" in modern phrasing, the system successfully retrieves highly relevant context. The Project Gutenberg edition uses the older spelling \"Tibalt\", which the retriever still resolves semantically.\n",
    "\n",
    "* **Chunk 1** is the most direct and useful. It captures the aftermath of the duel, with citizens exclaiming:\n",
    "  * \"*Which way ran he that kild Mercutio? Tibalt that Murtherer, which way ran he?*\". Despite the archaic spelling and phrasing, this chunk effectively provides the answer when interpreted in context.\n",
    "\n",
    "* **Chunk 2** sets up the conflict. It includes Mercutio and Benvolio discussing that:\n",
    "  * \"*Tibalt, the kinsman to old Capulet, hath sent a Letter*\" ... \"*A challenge on my life*\". While it doesn't answer the question directly, it reinforces that Tibalt is the antagonist and establishes his role in escalating the violence.\n",
    "\n",
    "* **Chunk 3** presents the Prince's legal judgment:\n",
    "  * \"*Romeo, Prince, he was Mercutios Friend… The life of Tibalt*.\" The Prince confirms that Tybalt (Tibalt) has been killed in consequence of Mercutio's death. This chunk emphasizes closure rather than causality, but still supports the factual chain.\n",
    "\n",
    "### Observations\n",
    "\n",
    "- Early modern spelling (e.g., *Tibalt*) doesn't hinder embedding-based retrieval — a strength of semantic models.\n",
    "- No chunk contains a complete \"question + answer\" sentence, but together they establish who killed whom, why, and what happened next.\n",
    "- The system retrieves scenes with narrative and legal resolution, not just the killing itself.\n",
    "\n",
    "This result demonstrates how chunk-level RAG with sentence-transformer embeddings can surface relevant evidence across spelling and stylistic variation, even when chunk boundaries split key action and dialogue.\n",
    "\n",
    "### Run a few additional queries & report top-ranked chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c77413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few factual queries and inspect the top-ranked chunks\n",
    "factual_questions = [\n",
    "    \"Who kills Mercutio?\", # Tybalt\n",
    "    \"Where does Romeo meet Juliet?\", # Capulet's masquerade ball (party), which takes place at the Capulet family home in Verona\n",
    "    \"What punishment does the Prince give Romeo?\" # exile / banishment\n",
    "]\n",
    "\n",
    "for q in factual_questions:\n",
    "    print(f\"\\n=== Query: {q} ===\")\n",
    "    results = retrieve_relevant_chunks(model, q, chunks, embeddings, top_n=1)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\n--- CHUNK {i} (Score: {score:.4f}) ---\")\n",
    "        print(chunk[:800])  # print first ~800 chars for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c697b",
   "metadata": {},
   "source": [
    "=== Query: Who kills Mercutio? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.4397) ---\n",
    "    , he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    \n",
    "       Prin. Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "       Cap. Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "       Prin. And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest\n",
    "    \n",
    "    === Query: Where does Romeo meet Juliet? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.6070) ---\n",
    "    ,\n",
    "    He swong about his head, and cut the windes,\n",
    "    Who nothing hurt withall, hist him in scorne.\n",
    "    While we were enterchanging thrusts and blowes,\n",
    "    Came more and more, and fought on part and part,\n",
    "    Till the Prince came, who parted either part\n",
    "    \n",
    "       Wife. O where is Romeo, saw you him to day?\n",
    "    Right glad am I, he was not at this fray\n",
    "    \n",
    "       Ben. Madam, an houre before the worshipt Sun\n",
    "    Peer'd forth the golden window of the East,\n",
    "    A troubled mind draue me to walke abroad,\n",
    "    Where vnderneath the groue \n",
    "    \n",
    "    === Query: What punishment does the Prince give Romeo? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.6058) ---\n",
    "    , he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    \n",
    "       Prin. Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "       Cap. Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "       Prin. And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest\n",
    "\n",
    "\n",
    "### Improving retrieved chunks\n",
    "\n",
    "Before we move on to having a language model generate answers, we need to take a closer look at the quality of the retrieved content.\n",
    "\n",
    "As we just saw, our current retrieval method brings back passages that are topically related but often miss the actual moment where the answer appears. In some cases, the correct chunk is nearby but not retrieved. In others, key information may be split across multiple chunks or surrounded by distracting dialogue.\n",
    "\n",
    "To address this, we'll focus on a key area of improvement: **refining the chunking strategy**.\n",
    "\n",
    "#### Why chunking matters\n",
    "\n",
    "The current approach uses a simple method such as splitting the text by a fixed word count. While this works for general purposes, it often cuts across meaningful dramatic units:\n",
    "\n",
    "- A character's speech may be interrupted mid-line\n",
    "- A fight scene may be split just before or after a critical action\n",
    "- A conversation between characters may be split across chunks\n",
    "\n",
    "This leads to less coherent retrieval and lowers the chance that a single chunk can fully answer the question.\n",
    "\n",
    "Here are two practical adjustments we can use to improve the retrievals:\n",
    "\n",
    "1. **Group complete speaker turns into chunks**: Instead of arbitrary lengths, we can group text based on who is speaking. This ensures each chunk preserves the flow and tone of the conversation.\n",
    "2. **Use scene- or event-aware chunking**: By chunking based on scene boundaries or key events (e.g. \"Romeo kills Tybalt\"), we improve the chance that retrieved content captures complete dramatic moments, not just pieces of them.\n",
    "\n",
    "These changes don't require a new model—they just help the existing model work with more meaningful input.\n",
    "\n",
    "Next, we'll apply dialogue-aware chunking and rerun one of our earlier factual queries to see whether the results improve.\n",
    "\n",
    "### Refining chunking strategy\n",
    "Our current chunks are only based on word length. Instead, we can create chunks that are more tuned to the dataset and potential questions we might ask by defining a chunk as a \"dialogue block\", i.e.,  as a group of N full speaker turns (e.g., JULIET. + her lines, ROMEO. + his lines, etc.).\n",
    "\n",
    "Let's give this a shot to see how it impacts retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80262ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def chunk_by_speaker_blocks(text, block_size=4):\n",
    "    # This regex matches short speaker tags at the beginning of lines, e.g., \"Ben.\" or \"Rom.\"\n",
    "    # Followed by speech text (either same line or indented on next)\n",
    "    speaker_line_pattern = re.compile(r'^\\s{0,3}([A-Z][a-z]+)\\.\\s+(.*)', re.MULTILINE)\n",
    "\n",
    "    dialogue_blocks = []\n",
    "    current_speaker = None\n",
    "    current_lines = []\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        match = speaker_line_pattern.match(line)\n",
    "        if match:\n",
    "            # Save previous speaker block if one was accumulating\n",
    "            if current_speaker:\n",
    "                dialogue_blocks.append(f\"{current_speaker}.\\n\" + \"\\n\".join(current_lines).strip())\n",
    "            current_speaker = match.group(1)\n",
    "            current_lines = [match.group(2)]\n",
    "        elif current_speaker and line.strip():\n",
    "            # Indented continuation of the same speaker\n",
    "            current_lines.append(line)\n",
    "        else:\n",
    "            # Blank line or noise: treat as boundary\n",
    "            if current_speaker and current_lines:\n",
    "                dialogue_blocks.append(f\"{current_speaker}.\\n\" + \"\\n\".join(current_lines).strip())\n",
    "                current_speaker = None\n",
    "                current_lines = []\n",
    "\n",
    "    # Add last block if exists\n",
    "    if current_speaker and current_lines:\n",
    "        dialogue_blocks.append(f\"{current_speaker}.\\n\" + \"\\n\".join(current_lines).strip())\n",
    "\n",
    "    # Chunk into groups of speaker turns\n",
    "    grouped_chunks = []\n",
    "    for i in range(0, len(dialogue_blocks), block_size):\n",
    "        chunk = \"\\n\\n\".join(dialogue_blocks[i:i + block_size])\n",
    "        grouped_chunks.append(chunk.strip())\n",
    "\n",
    "    return grouped_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41159a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_chunks = chunk_by_speaker_blocks(file_contents, block_size=4)\n",
    "print(f\"Total speaker_chunks: {len(speaker_chunks)}\")\n",
    "print(f\"Preview of first chunk:\\n\\n{speaker_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27484108",
   "metadata": {},
   "source": [
    "Total speaker_chunks: 206\n",
    "    Preview of first chunk:\n",
    "    \n",
    "    Barnardo.\n",
    "    Who's there?\n",
    "    \n",
    "    Fran.\n",
    "    Nay answer me: Stand & vnfold\n",
    "    your selfe\n",
    "    \n",
    "    Bar.\n",
    "    Long liue the King\n",
    "    \n",
    "    So.\n",
    "    . .with this caveat. . .we have NOT changed the canon errors,\n",
    "    here is the Project Gutenberg Etext of Shakespeare's The first\n",
    "    Part of Henry the Sixt.\n",
    "\n",
    "\n",
    "Our chunks have now been improved so that we aren't cutting off any diagloue mid-sentence, and each chunk contains a few turns between speakers -- allowing us to better capture the overall semantics of short passages from *Romeo and Juliet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_embeddings = model.encode(speaker_chunks, device=device)\n",
    "\n",
    "print(f\"Shape of dialogue_embeddings matrix: {np.array(dialogue_embeddings).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b0e9a",
   "metadata": {},
   "source": [
    "Shape of dialogue_embeddings matrix: (206, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a281086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few factual queries and inspect the top-ranked chunks\n",
    "factual_questions = [\n",
    "    \"Who kills Mercutio?\", # Tybalt\n",
    "    \"Where does Romeo meet Juliet?\", # Capulet's masquerade ball (party), which takes place at the Capulet family home in Verona\n",
    "    \"What punishment does the Prince give Romeo?\" # exile / banishment\n",
    "]\n",
    "\n",
    "for q in factual_questions:\n",
    "    print(f\"\\n=== Query: {q} ===\")\n",
    "    results = retrieve_relevant_chunks(model, q, speaker_chunks, dialogue_embeddings, top_n=1)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\n--- CHUNK {i} (Score: {score:.4f}) ---\")\n",
    "        print(chunk)  # print first ~800 chars for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017a581",
   "metadata": {},
   "source": [
    "=== Query: Who kills Mercutio? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.5159) ---\n",
    "    Mer.\n",
    "    Come sir, your Passado\n",
    "    \n",
    "    Rom.\n",
    "    Draw Benuolio, beat downe their weapons:\n",
    "    Gentlemen, for shame forbeare this outrage,\n",
    "    Tibalt, Mercutio, the Prince expresly hath\n",
    "    Forbidden bandying in Verona streetes.\n",
    "    Hold Tybalt, good Mercutio.\n",
    "    \n",
    "    Mer.\n",
    "    I am hurt.\n",
    "    A plague a both the Houses, I am sped:\n",
    "    Is he gone and hath nothing?\n",
    "    \n",
    "    Ben.\n",
    "    What art thou hurt?\n",
    "    \n",
    "    === Query: Where does Romeo meet Juliet? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.6061) ---\n",
    "    Watch.\n",
    "    Lead Boy, which way?\n",
    "    \n",
    "    Iul.\n",
    "    Yea noise?\n",
    "    Then ile be briefe. O happy Dagger.\n",
    "    'Tis in thy sheath, there rust and let me die.\n",
    "    \n",
    "    Boy.\n",
    "    This is the place,\n",
    "    There where the Torch doth burne\n",
    "    \n",
    "    Watch.\n",
    "    The ground is bloody,\n",
    "    Search about the Churchyard.\n",
    "    Go some of you, who ere you find attach.\n",
    "    Pittifull sight, here lies the Countie slaine,\n",
    "    And Iuliet bleeding, warme and newly dead\n",
    "    Who here hath laine these two dayes buried.\n",
    "    Go tell the Prince, runne to the Capulets,\n",
    "    Raise vp the Mountagues, some others search,\n",
    "    We see the ground whereon these woes do lye,\n",
    "    But the true ground of all these piteous woes,\n",
    "    We cannot without circumstance descry.\n",
    "    Enter Romeo's man.\n",
    "    \n",
    "    === Query: What punishment does the Prince give Romeo? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.6221) ---\n",
    "    Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "Refining our chunking strategy to preserve full speaker turns—and grouping several turns together—has already improved the relevance of the chunks retrieved. The content is more coherent, more complete, and better aligned with the structure of a play. This shows how much retrieval quality depends not just on the model, but on the way we prepare and represent the source material.\n",
    "\n",
    "That said, even with better chunks, retrieval doesn't always land on the exact moment that answers the question. Sometimes it gets close but stops short; other times it picks up a scene with similar characters or themes, but not the one we need.\n",
    "\n",
    "This points to a deeper challenge: *semantic similarity alone doesn't always capture answer relevance*. The chunk that's closest in meaning isn't always the one that answers the question. One way to address this is through a process called **reranking**.\n",
    "\n",
    "### What is reranking?\n",
    "\n",
    "Reranking means retrieving a small set of candidate chunks—say, the top 5—and then using an additional method to determine which of those is the best fit for the question.\n",
    "\n",
    "That method could be:\n",
    "\n",
    "- A custom scoring function (e.g., based on keyword overlap, speaker identity, or chunk metadata),\n",
    "- Or—more powerfully—a *separate language model*.\n",
    "\n",
    "This separate model can be small or large, depending on your resource availability:\n",
    "\n",
    "- A smaller open-source model (like `mistral`, `falcon`, or `phi`) can often handle basic ranking tasks at low cost.\n",
    "- A larger LLM (like GPT-3.5 or GPT-4) may be better at reasoning through subtleties and weighing relevance when answers are indirect or distributed across lines.\n",
    "\n",
    "You might ask this model something like:\n",
    "\n",
    "> Here are three passages. Which one best answers the question: \"Who kills Mercutio?\"\n",
    "\n",
    "At first, it might feel strange to use one language model to support another—but this layered setup is common in production RAG pipelines. It separates concerns:\n",
    "\n",
    "- The retriever quickly narrows down the universe of text,\n",
    "- The reranker evaluates those chunks more deeply, focusing on which is most likely to be useful.\n",
    "\n",
    "We won't implement this yet, but it's worth introducing now. As we start exploring more ambiguous or emotionally driven questions in later sections, reranking becomes one of the key techniques for bridging the gap between retrieval and meaningful response.\n",
    "\n",
    "For now, we've established a strong foundation: well-structured chunks that carry clear speaker information and preserve narrative flow. That's a critical step toward building a RAG system that doesn't just respond, but interprets.\n",
    "\n",
    "### Upgrading our retrieval model\n",
    "\n",
    "The model we've used so far, [`multi-qa-MiniLM-L6-cos-v1`](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1), is a solid starting point for retrieval-augmented generation (RAG) pipelines, it is relatively lightweight (22M parameters, ~500–800 MB GPU memory), which makes it efficient but less expressive than larger models.\n",
    "\n",
    "However, larger embedding models have more capacity to capture subtle semantic relationships, including indirect phrasing or domain-specific language. This can make a dramatic difference in tasks like matching Shakespearean dialogue to modern questions—something smaller models often struggle with.\n",
    "\n",
    "Let's try a slightly larger model with 109 M parameters, [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f86fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load ~335M params embedding model\n",
    "model_larger = SentenceTransformer(\"BAAI/bge-large-en-v1.5\", device=device)\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "dialogue_embeddings = model_larger.encode(speaker_chunks, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01514b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few factual queries and inspect the top-ranked chunks\n",
    "factual_questions = [\n",
    "    \"Who kills Mercutio?\", # Tybalt\n",
    "    \"Where does Romeo meet Juliet?\", # Capulet's masquerade ball (party), which takes place at the Capulet family home in Verona\n",
    "    \"What punishment does the Prince give Romeo?\" # exile / banishment\n",
    "]\n",
    "\n",
    "for q in factual_questions:\n",
    "    print(f\"\\n=== Query: {q} ===\")\n",
    "    results = retrieve_relevant_chunks(model_larger, q, speaker_chunks, dialogue_embeddings, top_n=1)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\n--- CHUNK {i} (Score: {score:.4f}) ---\")\n",
    "        print(chunk)  # print first ~800 chars for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b73dc",
   "metadata": {},
   "source": [
    "=== Query: Who kills Mercutio? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.7172) ---\n",
    "    Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "    \n",
    "    === Query: Where does Romeo meet Juliet? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.6574) ---\n",
    "    Chorus.\n",
    "    Now old desire doth in his death bed lie,\n",
    "    And yong affection gapes to be his Heire,\n",
    "    That faire, for which Loue gron'd for and would die,\n",
    "    With tender Iuliet matcht, is now not faire.\n",
    "    Now Romeo is beloued, and Loues againe,\n",
    "    A like bewitched by the charme of lookes:\n",
    "    But to his foe suppos'd he must complaine,\n",
    "    And she steale Loues sweet bait from fearefull hookes:\n",
    "    Being held a foe, he may not haue accesse\n",
    "    To breath such vowes as Louers vse to sweare,\n",
    "    And she as much in Loue, her meanes much lesse,\n",
    "    To meete her new Beloued any where:\n",
    "    But passion lends them Power, time, meanes to meete,\n",
    "    Temp'ring extremities with extreame sweete.\n",
    "    Enter Romeo alone.\n",
    "    \n",
    "    Rom.\n",
    "    Can I goe forward when my heart is here?\n",
    "    Turne backe dull earth, and find thy Center out.\n",
    "    Enter Benuolio, with Mercutio.\n",
    "    \n",
    "    Ben.\n",
    "    Romeo, my Cozen Romeo, Romeo\n",
    "    \n",
    "    Merc.\n",
    "    He is wise,\n",
    "    And on my life hath stolne him home to bed\n",
    "    \n",
    "    === Query: What punishment does the Prince give Romeo? ===\n",
    "    \n",
    "    --- CHUNK 1 (Score: 0.7197) ---\n",
    "    Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "\n",
    "\n",
    "**Note:** We didn't use FAISS in this notebook, since our dataset is small enough for brute-force similarity search. But once you move to larger models or bigger corpora, FAISS becomes essential for scalable and efficient retrieval.\n",
    "\n",
    "## Step 5: Generate answer using retrieved context\n",
    "\n",
    "### Putting it all together: Answering a question with a language model\n",
    "\n",
    "Now that we've improved our chunking and retrieval process, we're ready to pass the retrieved content to *yet another* language model and generate an answer.\n",
    "\n",
    "This step completes the typical RAG (Retrieval-Augmented Generation) workflow:\n",
    "\n",
    "1. Retrieve the top-ranked passage(s) using a retrieval language model to embed the corpus into a Q&A semantic space\n",
    "2. Concatenate retrieved results them into a structured prompt\n",
    "3. Ask a (generative) language model to answer the user's question using only that retrieved context\n",
    "\n",
    "This approach grounds the model's answer in specific evidence from the text, making it more trustworthy than asking the model to \"hallucinate\" an answer from general pretraining.\n",
    "\n",
    "\n",
    "#### The prompt format\n",
    "\n",
    "We use a basic prompt like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use only the following passage to answer this question.\n",
    "BEGIN_PASSAGE: [Top retrieved chunk(s) go here] END_PASSAGE \n",
    "QUESTION: [your question]\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79264adf",
   "metadata": {},
   "source": [
    "By framing the input this way, we signal to the model that it should focus only on the retrieved content. We're not asking it to draw from general knowledge of the play—just from the selected passages. \n",
    "\n",
    "Let's begin assembling the full prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who killed Mercutio?\" # Tybalt/Tibalt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3765cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dialgoue_chunks = retrieve_relevant_chunks(model_larger, question, speaker_chunks, dialogue_embeddings, top_n=5)\n",
    "\n",
    "# Extract only the chunk text from (chunk, score) tuples\n",
    "context = \"\\n\".join(chunk for chunk, score in top_dialgoue_chunks)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f611ed3",
   "metadata": {},
   "source": [
    "Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "    Mer.\n",
    "    Helpe me into some house Benuolio,\n",
    "    Or I shall faint: a plague a both your houses.\n",
    "    They haue made wormesmeat of me,\n",
    "    I haue it, and soundly to your Houses.\n",
    "    Enter.\n",
    "    \n",
    "    Rom.\n",
    "    This Gentleman the Princes neere Alie,\n",
    "    My very Friend hath got his mortall hurt\n",
    "    In my behalfe, my reputation stain'd\n",
    "    With Tibalts slaunder, Tybalt that an houre\n",
    "    Hath beene my Cozin: O Sweet Iuliet,\n",
    "    Thy Beauty hath made me Effeminate,\n",
    "    And in my temper softned Valours steele.\n",
    "    Enter Benuolio.\n",
    "    \n",
    "    Ben.\n",
    "    O Romeo, Romeo, braue Mercutio's is dead,\n",
    "    That Gallant spirit hath aspir'd the Cloudes,\n",
    "    Which too vntimely here did scorne the earth\n",
    "    \n",
    "    Rom.\n",
    "    This daies blacke Fate, on mo daies depend,\n",
    "    This but begins, the wo others must end.\n",
    "    Enter Tybalt.\n",
    "    Mer.\n",
    "    Come sir, your Passado\n",
    "    \n",
    "    Rom.\n",
    "    Draw Benuolio, beat downe their weapons:\n",
    "    Gentlemen, for shame forbeare this outrage,\n",
    "    Tibalt, Mercutio, the Prince expresly hath\n",
    "    Forbidden bandying in Verona streetes.\n",
    "    Hold Tybalt, good Mercutio.\n",
    "    \n",
    "    Mer.\n",
    "    I am hurt.\n",
    "    A plague a both the Houses, I am sped:\n",
    "    Is he gone and hath nothing?\n",
    "    \n",
    "    Ben.\n",
    "    What art thou hurt?\n",
    "    Cap.\n",
    "    Wi. Tybalt, my Cozin? O my Brothers Child,\n",
    "    O Prince, O Cozin, Husband, O the blood is spild\n",
    "    Of my deare kinsman. Prince as thou art true,\n",
    "    For bloud of ours, shed bloud of Mountague.\n",
    "    O Cozin, Cozin\n",
    "    \n",
    "    Prin.\n",
    "    Benuolio, who began this Fray?\n",
    "    \n",
    "    Ben.\n",
    "    Tybalt here slaine, whom Romeo's hand did slay,\n",
    "    Romeo that spoke him faire, bid him bethinke\n",
    "    How nice the Quarrell was, and vrg'd withall\n",
    "    Your high displeasure: all this vttered,\n",
    "    With gentle breath, calme looke, knees humbly bow'd\n",
    "    Could not take truce with the vnruly spleene\n",
    "    Of Tybalts deafe to peace, but that he Tilts\n",
    "    With Peircing steele at bold Mercutio's breast,\n",
    "    Who all as hot, turnes deadly point to point,\n",
    "    And with a Martiall scorne, with one hand beates\n",
    "    Cold death aside, and with the other sends\n",
    "    It back to Tybalt, whose dexterity\n",
    "    Retorts it: Romeo he cries aloud,\n",
    "    Hold Friends, Friends part, and swifter then his tongue,\n",
    "    His aged arme, beats downe their fatall points,\n",
    "    And twixt them rushes, vnderneath whose arme,\n",
    "    An enuious thrust from Tybalt, hit the life\n",
    "    Of stout Mercutio, and then Tybalt fled.\n",
    "    But by and by comes backe to Romeo,\n",
    "    Who had but newly entertained Reuenge,\n",
    "    And too't they goe like lightning, for ere I\n",
    "    Could draw to part them, was stout Tybalt slaine:\n",
    "    And as he fell, did Romeo turne and flie:\n",
    "    This is the truth, or let Benuolio die\n",
    "    \n",
    "    Cap.\n",
    "    Wi. He is a kinsman to the Mountague,\n",
    "    Affection makes him false, he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    Ben.\n",
    "    Here comes the Furious Tybalt backe againe\n",
    "    \n",
    "    Rom.\n",
    "    He gon in triumph, and Mercutio slaine?\n",
    "    Away to heauen respectiue Lenitie,\n",
    "    And fire and Fury, be my conduct now.\n",
    "    Now Tybalt take the Villaine backe againe\n",
    "    That late thou gau'st me, for Mercutios soule\n",
    "    Is but a little way aboue our heads,\n",
    "    Staying for thine to keepe him companie:\n",
    "    Either thou or I, or both, must goe with him\n",
    "    \n",
    "    Tib.\n",
    "    Thou wretched Boy that didst consort him here,\n",
    "    Shalt with him hence\n",
    "    \n",
    "    Rom.\n",
    "    This shall determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"Use the following passage to answer this question.\\nBEGIN_PASSAGE:\\n{context}\\nEND_PASSAGE\\nQUESTION: {question}\\nANSWER:\"\n",
    "\n",
    "prompt = f\"\"\"You are a strict reading comprehension assistant. You will be given a question and several passages from Romeo and Juliet.\n",
    "Use ONLY the information in the passages to answer the question. If the answer is not directly stated, reply exactly with: \"Not found in context\".\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "ANSWER:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521cdbf",
   "metadata": {},
   "source": [
    "You are a strict reading comprehension assistant. You will be given a question and several passages from Romeo and Juliet.\n",
    "    Use ONLY the information in the passages to answer the question. If the answer is not directly stated, reply exactly with: \"Not found in context\".\n",
    "    \n",
    "    CONTEXT:\n",
    "    Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "    Mer.\n",
    "    Helpe me into some house Benuolio,\n",
    "    Or I shall faint: a plague a both your houses.\n",
    "    They haue made wormesmeat of me,\n",
    "    I haue it, and soundly to your Houses.\n",
    "    Enter.\n",
    "    \n",
    "    Rom.\n",
    "    This Gentleman the Princes neere Alie,\n",
    "    My very Friend hath got his mortall hurt\n",
    "    In my behalfe, my reputation stain'd\n",
    "    With Tibalts slaunder, Tybalt that an houre\n",
    "    Hath beene my Cozin: O Sweet Iuliet,\n",
    "    Thy Beauty hath made me Effeminate,\n",
    "    And in my temper softned Valours steele.\n",
    "    Enter Benuolio.\n",
    "    \n",
    "    Ben.\n",
    "    O Romeo, Romeo, braue Mercutio's is dead,\n",
    "    That Gallant spirit hath aspir'd the Cloudes,\n",
    "    Which too vntimely here did scorne the earth\n",
    "    \n",
    "    Rom.\n",
    "    This daies blacke Fate, on mo daies depend,\n",
    "    This but begins, the wo others must end.\n",
    "    Enter Tybalt.\n",
    "    Mer.\n",
    "    Come sir, your Passado\n",
    "    \n",
    "    Rom.\n",
    "    Draw Benuolio, beat downe their weapons:\n",
    "    Gentlemen, for shame forbeare this outrage,\n",
    "    Tibalt, Mercutio, the Prince expresly hath\n",
    "    Forbidden bandying in Verona streetes.\n",
    "    Hold Tybalt, good Mercutio.\n",
    "    \n",
    "    Mer.\n",
    "    I am hurt.\n",
    "    A plague a both the Houses, I am sped:\n",
    "    Is he gone and hath nothing?\n",
    "    \n",
    "    Ben.\n",
    "    What art thou hurt?\n",
    "    Cap.\n",
    "    Wi. Tybalt, my Cozin? O my Brothers Child,\n",
    "    O Prince, O Cozin, Husband, O the blood is spild\n",
    "    Of my deare kinsman. Prince as thou art true,\n",
    "    For bloud of ours, shed bloud of Mountague.\n",
    "    O Cozin, Cozin\n",
    "    \n",
    "    Prin.\n",
    "    Benuolio, who began this Fray?\n",
    "    \n",
    "    Ben.\n",
    "    Tybalt here slaine, whom Romeo's hand did slay,\n",
    "    Romeo that spoke him faire, bid him bethinke\n",
    "    How nice the Quarrell was, and vrg'd withall\n",
    "    Your high displeasure: all this vttered,\n",
    "    With gentle breath, calme looke, knees humbly bow'd\n",
    "    Could not take truce with the vnruly spleene\n",
    "    Of Tybalts deafe to peace, but that he Tilts\n",
    "    With Peircing steele at bold Mercutio's breast,\n",
    "    Who all as hot, turnes deadly point to point,\n",
    "    And with a Martiall scorne, with one hand beates\n",
    "    Cold death aside, and with the other sends\n",
    "    It back to Tybalt, whose dexterity\n",
    "    Retorts it: Romeo he cries aloud,\n",
    "    Hold Friends, Friends part, and swifter then his tongue,\n",
    "    His aged arme, beats downe their fatall points,\n",
    "    And twixt them rushes, vnderneath whose arme,\n",
    "    An enuious thrust from Tybalt, hit the life\n",
    "    Of stout Mercutio, and then Tybalt fled.\n",
    "    But by and by comes backe to Romeo,\n",
    "    Who had but newly entertained Reuenge,\n",
    "    And too't they goe like lightning, for ere I\n",
    "    Could draw to part them, was stout Tybalt slaine:\n",
    "    And as he fell, did Romeo turne and flie:\n",
    "    This is the truth, or let Benuolio die\n",
    "    \n",
    "    Cap.\n",
    "    Wi. He is a kinsman to the Mountague,\n",
    "    Affection makes him false, he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    Ben.\n",
    "    Here comes the Furious Tybalt backe againe\n",
    "    \n",
    "    Rom.\n",
    "    He gon in triumph, and Mercutio slaine?\n",
    "    Away to heauen respectiue Lenitie,\n",
    "    And fire and Fury, be my conduct now.\n",
    "    Now Tybalt take the Villaine backe againe\n",
    "    That late thou gau'st me, for Mercutios soule\n",
    "    Is but a little way aboue our heads,\n",
    "    Staying for thine to keepe him companie:\n",
    "    Either thou or I, or both, must goe with him\n",
    "    \n",
    "    Tib.\n",
    "    Thou wretched Boy that didst consort him here,\n",
    "    Shalt with him hence\n",
    "    \n",
    "    Rom.\n",
    "    This shall determine that.\n",
    "    \n",
    "    QUESTION: Who killed Mercutio?\n",
    "    ANSWER:\n",
    "\n",
    "\n",
    "### Language model for generation\n",
    "\n",
    "For this section, we're using [`tiiuae/falcon-rw-1b`](https://huggingface.co/tiiuae/falcon-rw-1b), a small 1.3B parameter decoder-only model trained on the RefinedWeb dataset. It's designed for general-purpose text continuation, not for answering questions or following instructions.\n",
    "\n",
    "This makes it a good baseline for testing how much a generative model can do with only retrieved context and minimal guidance. As we'll see, its output often reflects surface-level patterns or recent tokens, rather than accurate reasoning grounded in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=\"tiiuae/falcon-rw-1b\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61295f18",
   "metadata": {},
   "source": [
    "Device set to use cuda:0\n",
    "\n",
    "\n",
    "#### Model parameters and generation behavior\n",
    "\n",
    "When we call the language model, we specify parameters like:\n",
    "\n",
    "- `max_new_tokens`: Limits how much it can generate (e.g., 100 tokens)\n",
    "- `do_sample=True`: Enables creative variation rather than deterministic output. For the purposes of getting a reproducible result, we'll set this to `False`\n",
    "\n",
    "These parameters influence not just length, but also how literal or speculative the answer might be. Sampling increases variety but can also introduce tangents or continuation artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm(prompt, max_new_tokens=10, do_sample=False)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65062083",
   "metadata": {},
   "source": [
    "Token indices sequence length is longer than the specified maximum sequence length for this model (1714 > 1024). Running this sequence through the model will result in indexing errors\n",
    "    Setting `pad_token_id` to `eos_token_id`:2 for open-end generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e07a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125e216",
   "metadata": {},
   "source": [
    "You are a strict reading comprehension assistant. You will be given a question and several passages from Romeo and Juliet.\n",
    "    Use ONLY the information in the passages to answer the question. If the answer is not directly stated, reply exactly with: \"Not found in context\".\n",
    "    \n",
    "    CONTEXT:\n",
    "    Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "    Mer.\n",
    "    Helpe me into some house Benuolio,\n",
    "    Or I shall faint: a plague a both your houses.\n",
    "    They haue made wormesmeat of me,\n",
    "    I haue it, and soundly to your Houses.\n",
    "    Enter.\n",
    "    \n",
    "    Rom.\n",
    "    This Gentleman the Princes neere Alie,\n",
    "    My very Friend hath got his mortall hurt\n",
    "    In my behalfe, my reputation stain'd\n",
    "    With Tibalts slaunder, Tybalt that an houre\n",
    "    Hath beene my Cozin: O Sweet Iuliet,\n",
    "    Thy Beauty hath made me Effeminate,\n",
    "    And in my temper softned Valours steele.\n",
    "    Enter Benuolio.\n",
    "    \n",
    "    Ben.\n",
    "    O Romeo, Romeo, braue Mercutio's is dead,\n",
    "    That Gallant spirit hath aspir'd the Cloudes,\n",
    "    Which too vntimely here did scorne the earth\n",
    "    \n",
    "    Rom.\n",
    "    This daies blacke Fate, on mo daies depend,\n",
    "    This but begins, the wo others must end.\n",
    "    Enter Tybalt.\n",
    "    Mer.\n",
    "    Come sir, your Passado\n",
    "    \n",
    "    Rom.\n",
    "    Draw Benuolio, beat downe their weapons:\n",
    "    Gentlemen, for shame forbeare this outrage,\n",
    "    Tibalt, Mercutio, the Prince expresly hath\n",
    "    Forbidden bandying in Verona streetes.\n",
    "    Hold Tybalt, good Mercutio.\n",
    "    \n",
    "    Mer.\n",
    "    I am hurt.\n",
    "    A plague a both the Houses, I am sped:\n",
    "    Is he gone and hath nothing?\n",
    "    \n",
    "    Ben.\n",
    "    What art thou hurt?\n",
    "    Cap.\n",
    "    Wi. Tybalt, my Cozin? O my Brothers Child,\n",
    "    O Prince, O Cozin, Husband, O the blood is spild\n",
    "    Of my deare kinsman. Prince as thou art true,\n",
    "    For bloud of ours, shed bloud of Mountague.\n",
    "    O Cozin, Cozin\n",
    "    \n",
    "    Prin.\n",
    "    Benuolio, who began this Fray?\n",
    "    \n",
    "    Ben.\n",
    "    Tybalt here slaine, whom Romeo's hand did slay,\n",
    "    Romeo that spoke him faire, bid him bethinke\n",
    "    How nice the Quarrell was, and vrg'd withall\n",
    "    Your high displeasure: all this vttered,\n",
    "    With gentle breath, calme looke, knees humbly bow'd\n",
    "    Could not take truce with the vnruly spleene\n",
    "    Of Tybalts deafe to peace, but that he Tilts\n",
    "    With Peircing steele at bold Mercutio's breast,\n",
    "    Who all as hot, turnes deadly point to point,\n",
    "    And with a Martiall scorne, with one hand beates\n",
    "    Cold death aside, and with the other sends\n",
    "    It back to Tybalt, whose dexterity\n",
    "    Retorts it: Romeo he cries aloud,\n",
    "    Hold Friends, Friends part, and swifter then his tongue,\n",
    "    His aged arme, beats downe their fatall points,\n",
    "    And twixt them rushes, vnderneath whose arme,\n",
    "    An enuious thrust from Tybalt, hit the life\n",
    "    Of stout Mercutio, and then Tybalt fled.\n",
    "    But by and by comes backe to Romeo,\n",
    "    Who had but newly entertained Reuenge,\n",
    "    And too't they goe like lightning, for ere I\n",
    "    Could draw to part them, was stout Tybalt slaine:\n",
    "    And as he fell, did Romeo turne and flie:\n",
    "    This is the truth, or let Benuolio die\n",
    "    \n",
    "    Cap.\n",
    "    Wi. He is a kinsman to the Mountague,\n",
    "    Affection makes him false, he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    Ben.\n",
    "    Here comes the Furious Tybalt backe againe\n",
    "    \n",
    "    Rom.\n",
    "    He gon in triumph, and Mercutio slaine?\n",
    "    Away to heauen respectiue Lenitie,\n",
    "    And fire and Fury, be my conduct now.\n",
    "    Now Tybalt take the Villaine backe againe\n",
    "    That late thou gau'st me, for Mercutios soule\n",
    "    Is but a little way aboue our heads,\n",
    "    Staying for thine to keepe him companie:\n",
    "    Either thou or I, or both, must goe with him\n",
    "    \n",
    "    Tib.\n",
    "    Thou wretched Boy that didst consort him here,\n",
    "    Shalt with him hence\n",
    "    \n",
    "    Rom.\n",
    "    This shall determine that.\n",
    "    \n",
    "    QUESTION: Who killed Mercutio?\n",
    "    ANSWER: Romeo\n",
    "    QUESTION: Who killed Tybalt\n",
    "\n",
    "\n",
    "### Why the model output inludes the prompt\n",
    "\n",
    "When using a decoder-only language model (like Falcon or GPT) with the Hugging Face `pipeline(\"text-generation\")`, the output will include the entire input prompt followed by the model's generated continuation.\n",
    "\n",
    "This happens because decoder-only models are trained to predict the *next token given all previous tokens*, not to separate a prompt from a response. So when you pass in a prompt, the model simply continues generating text — it doesn't know where \"input\" ends and \"output\" begins.\n",
    "\n",
    "As a result, the `pipeline` will return a string that contains both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f64dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "[prompt] + [generated text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ddebc",
   "metadata": {},
   "source": [
    "If you're only interested in the generated part (e.g., the model's answer), you'll need to remove the prompt manually after generation.\n",
    "\n",
    "We can strip off the final answer / generated result with the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_answer = result[len(prompt):].strip()\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b231a",
   "metadata": {},
   "source": [
    "Romeo\n",
    "    QUESTION: Who killed Tybalt\n",
    "\n",
    "\n",
    "#### Why the output might drift or repeat\n",
    "\n",
    "Even though we ask just one question, you might see the model:\n",
    "\n",
    "- Answer multiple questions in a row\n",
    "- Invent follow-up questions and answers\n",
    "- Continue in a Q&A or list format beyond what was asked\n",
    "\n",
    "This usually happens when:\n",
    "\n",
    "- The passage is long or covers multiple narrative beats\n",
    "- The model detects a repeated pattern (e.g., “Question: … Answer: …”) and keeps going\n",
    "\n",
    "For example, with a passage that includes both a fight and a romantic scene, the model might output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question: Who kills Mercutio?\n",
    "Answer: Romeo.\n",
    "Question: What does Juliet say about fate?\n",
    "Answer: She curses fortune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32bff22",
   "metadata": {},
   "source": [
    "Even though we only asked the first question.\n",
    "\n",
    "To limit this behavior, you can:\n",
    "\n",
    "- Set a lower `max_new_tokens`\n",
    "- Add a `stop` sequence after the first answer (if supported)\n",
    "- Use a tighter or more explicit prompt style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa39f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm(prompt, max_new_tokens=1, do_sample=False)[0][\"generated_text\"] # adjust to inlcude max of 1 new tokens\n",
    "generated_answer = result[len(prompt):].strip()\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14935fc4",
   "metadata": {},
   "source": [
    "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
    "\n",
    "\n",
    "    Romeo\n",
    "\n",
    "\n",
    "### Note on model accuracy and hallucination\n",
    "\n",
    "Smaller decoder-only models like `tiiuae/falcon-rw-1b` are fast and lightweight, but they can make factual errors, especially when summarizing events from structured texts like plays or historical records. For example, when asked \"Who killed Mercutio?\", the model incorrectly responded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Romeo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d2c0d",
   "metadata": {},
   "source": [
    "This is not correct. Mercutio is killed by Tybalt during a street duel. Romeo kills Tybalt afterward in retaliation.\n",
    "\n",
    "Interestingly, the correct information was present in the top retrieved chunk, but the phrasing may have confused the model:\n",
    "\n",
    "> Mer.  \n",
    "> I am hurt.  \n",
    "> A plague a both the Houses, I am sped:  \n",
    "> Is he gone and hath nothing?\n",
    "\n",
    "> Ben.  \n",
    "> What art thou hurt?\n",
    "\n",
    "> Prin.  \n",
    "> Romeo slew him, he slew Mercutio,  \n",
    "> Who now the price of his deare blood doth owe\n",
    "\n",
    "> Cap.  \n",
    "> Not Romeo Prince, he was Mercutio’s Friend,  \n",
    "> His fault concludes, but what the law should end,  \n",
    "> The life of Tybalt\n",
    "\n",
    "#### Instruction tuning improves perfomance\n",
    "To improve factual accuracy in your RAG pipeline, it's helpful to use an **instruction-tuned** model rather than a base language model. You've been using `falcon-rw-1b` (where \"rw\" stands for “Refined Web”), which is trained only to continue text — not to follow specific question-and-answer instructions. That's why it often hallucinates factual events.\n",
    "\n",
    "A lightweight upgrade is to instead use `tiiuae/Falcon3-1B-Instruct`, an instruction-tuned version of Falcon. It still runs on modest hardware but is trained to follow prompts and answer questions in a focused way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tiiuae/falcon3-1b-instruct\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",  # optional, helps with GPU memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533f86c",
   "metadata": {},
   "source": [
    "Device set to use cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We use max_new_tokens=3 here because words like \"Tybalt\" may be split into multiple tokens (e.g., \"Ty\", \"b\", \"alt\").\n",
    "# It's often tricky to get exactly one word due to subword tokenization.\n",
    "result = llm(prompt, max_new_tokens=3, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "# extract answer from full result, as before\n",
    "generated_answer = result[len(prompt):].strip()\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e2cba",
   "metadata": {},
   "source": [
    "Tybalt\n",
    "\n",
    "\n",
    "If all else fails, we can start to try larger models to handle the answer generation step. Other models you could substitute here depending on your resources include:\n",
    "\n",
    "- `mistralai/Mistral-7B-Instruct-v0.1` — for stronger instruction-following\n",
    "- `Qwen/Qwen2.5-7B-Instruct` — for stronger instruction-following\n",
    "- `openai, claude, gemini foundation models` — via Bedrock (covered in next episodes)\n",
    "\n",
    "For most open-source models, using `transformers` + `pipeline()` allows easy swapping once your retrieval system is set up.\n",
    "\n",
    "Keep in mind:\n",
    "\n",
    "- Larger models require more memory (ideally a 12–16GB GPU)\n",
    "- Instruction-tuned models typically follow prompts more reliably than base models\n",
    "- You may still need to post-process outputs to extract just the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes accelerate transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f780ba",
   "metadata": {},
   "source": [
    "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "    To disable this warning, you can either:\n",
    "    \t- Avoid using `tokenizers` before the fork if possible\n",
    "    \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "\n",
    "\n",
    "    Requirement already satisfied: bitsandbytes in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.48.2)\n",
    "    Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.12.0)\n",
    "    Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.57.1)\n",
    "    Requirement already satisfied: torch<3,>=2.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (2.6.0+cu124)\n",
    "    Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
    "    Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (24.2)\n",
    "    Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
    "    Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
    "    Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.4.2)\n",
    "    Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
    "    Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
    "    Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
    "    Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
    "    Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
    "    Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\n",
    "    Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\n",
    "    Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\n",
    "    Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\n",
    "    Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\n",
    "    Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\n",
    "    Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (0.6.2)\n",
    "    Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\n",
    "    Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
    "    Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
    "    Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.2.0)\n",
    "    Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n",
    "    Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
    "    Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
    "    Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
    "    Requirement already satisfied: huggingface_hub>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
    "    Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.7.0)\n",
    "    Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
    "    Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
    "    Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
    "    Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
    "    Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
    "    Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
    "    Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
    "    Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.11)\n",
    "    Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
    "    Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2025.10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",            # automatically loads on T4\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd896c6",
   "metadata": {},
   "source": [
    "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
    "\n",
    "\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "\n",
    "    OutOfMemoryError                          Traceback (most recent call last)\n",
    "\n",
    "    Cell In[53], line 19\n",
    "         10 bnb_config = BitsAndBytesConfig(\n",
    "         11     load_in_4bit=True,\n",
    "         12     bnb_4bit_quant_type=\"nf4\",\n",
    "         13     bnb_4bit_compute_dtype=\"float16\",\n",
    "         14     bnb_4bit_use_double_quant=True,\n",
    "         15 )\n",
    "         17 tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    ---> 19 model = AutoModelForCausalLM.from_pretrained(\n",
    "         20     model_id,\n",
    "         21     device_map=\"auto\",            # automatically loads on T4\n",
    "         22     quantization_config=bnb_config\n",
    "         23 )\n",
    "         25 llm = pipeline(\n",
    "         26     \"text-generation\",\n",
    "         27     model=model,\n",
    "         28     tokenizer=tokenizer,\n",
    "         29     max_new_tokens=200,\n",
    "         30 )\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:604, in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\n",
    "        602     if model_class.config_class == config.sub_configs.get(\"text_config\", None):\n",
    "        603         config = config.get_text_config()\n",
    "    --> 604     return model_class.from_pretrained(\n",
    "        605         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n",
    "        606     )\n",
    "        607 raise ValueError(\n",
    "        608     f\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\n",
    "        609     f\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping)}.\"\n",
    "        610 )\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:277, in restore_default_dtype.<locals>._wrapper(*args, **kwargs)\n",
    "        275 old_dtype = torch.get_default_dtype()\n",
    "        276 try:\n",
    "    --> 277     return func(*args, **kwargs)\n",
    "        278 finally:\n",
    "        279     torch.set_default_dtype(old_dtype)\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:5048, in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\n",
    "       5038     if dtype_orig is not None:\n",
    "       5039         torch.set_default_dtype(dtype_orig)\n",
    "       5041     (\n",
    "       5042         model,\n",
    "       5043         missing_keys,\n",
    "       5044         unexpected_keys,\n",
    "       5045         mismatched_keys,\n",
    "       5046         offload_index,\n",
    "       5047         error_msgs,\n",
    "    -> 5048     ) = cls._load_pretrained_model(\n",
    "       5049         model,\n",
    "       5050         state_dict,\n",
    "       5051         checkpoint_files,\n",
    "       5052         pretrained_model_name_or_path,\n",
    "       5053         ignore_mismatched_sizes=ignore_mismatched_sizes,\n",
    "       5054         sharded_metadata=sharded_metadata,\n",
    "       5055         device_map=device_map,\n",
    "       5056         disk_offload_folder=offload_folder,\n",
    "       5057         dtype=dtype,\n",
    "       5058         hf_quantizer=hf_quantizer,\n",
    "       5059         keep_in_fp32_regex=keep_in_fp32_regex,\n",
    "       5060         device_mesh=device_mesh,\n",
    "       5061         key_mapping=key_mapping,\n",
    "       5062         weights_only=weights_only,\n",
    "       5063     )\n",
    "       5064 # make sure token embedding weights are still tied if needed\n",
    "       5065 model.tie_weights()\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:5468, in PreTrainedModel._load_pretrained_model(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\n",
    "       5465         args_list = logging.tqdm(args_list, desc=\"Loading checkpoint shards\")\n",
    "       5467     for args in args_list:\n",
    "    -> 5468         _error_msgs, disk_offload_index = load_shard_file(args)\n",
    "       5469         error_msgs += _error_msgs\n",
    "       5471 # Save offloaded index if needed\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:843, in load_shard_file(args)\n",
    "        841 # Skip it with fsdp on ranks other than 0\n",
    "        842 elif not (is_fsdp_enabled() and not is_local_dist_rank_0() and not is_quantized):\n",
    "    --> 843     disk_offload_index = _load_state_dict_into_meta_model(\n",
    "        844         model,\n",
    "        845         state_dict,\n",
    "        846         shard_file,\n",
    "        847         reverse_key_renaming_mapping,\n",
    "        848         device_map=device_map,\n",
    "        849         disk_offload_folder=disk_offload_folder,\n",
    "        850         disk_offload_index=disk_offload_index,\n",
    "        851         hf_quantizer=hf_quantizer,\n",
    "        852         keep_in_fp32_regex=keep_in_fp32_regex,\n",
    "        853         device_mesh=device_mesh,\n",
    "        854     )\n",
    "        856 return error_msgs, disk_offload_index\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/_contextlib.py:116, in context_decorator.<locals>.decorate_context(*args, **kwargs)\n",
    "        113 @functools.wraps(func)\n",
    "        114 def decorate_context(*args, **kwargs):\n",
    "        115     with ctx_factory():\n",
    "    --> 116         return func(*args, **kwargs)\n",
    "\n",
    "\n",
    "    File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:748, in _load_state_dict_into_meta_model(model, state_dict, shard_file, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, hf_quantizer, keep_in_fp32_regex, device_mesh)\n",
    "        740         hf_quantizer.create_quantized_param(\n",
    "        741             model,\n",
    "        742             param,\n",
    "       (...)\n",
    "        745             **sharding_kwargs,\n",
    "        746         )\n",
    "        747 else:\n",
    "    --> 748     param = param[...]\n",
    "        749     if casting_dtype is not None:\n",
    "        750         param = param.to(casting_dtype)\n",
    "\n",
    "\n",
    "    OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 14.56 GiB of which 898.81 MiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.23 GiB is allocated by PyTorch, and 337.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
    "\n",
    "\n",
    "**You will likely get out of memory error**. See [Instances for ML](https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html) to select an instance with more memory and re-run this code! Swapping instances can be tedious. In the next episode, we'll discuss how to do RAG more elegantly in AWS to avoid paying for idle GPU time in notebooks. The next episode will launch more resource intensive jobs on demand for (a) embedding corpus and (b) lookup and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91457671",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b712e",
   "metadata": {},
   "source": [
    "You are a strict reading comprehension assistant. You will be given a question and several passages from Romeo and Juliet.\n",
    "    Use ONLY the information in the passages to answer the question. If the answer is not directly stated, reply exactly with: \"Not found in context\".\n",
    "    \n",
    "    CONTEXT:\n",
    "    Prin.\n",
    "    Romeo slew him, he slew Mercutio,\n",
    "    Who now the price of his deare blood doth owe\n",
    "    \n",
    "    Cap.\n",
    "    Not Romeo Prince, he was Mercutios Friend,\n",
    "    His fault concludes, but what the law should end,\n",
    "    The life of Tybalt\n",
    "    \n",
    "    Prin.\n",
    "    And for that offence,\n",
    "    Immediately we doe exile him hence:\n",
    "    I haue an interest in your hearts proceeding:\n",
    "    My bloud for your rude brawles doth lie a bleeding.\n",
    "    But Ile Amerce you with so strong a fine,\n",
    "    That you shall all repent the losse of mine.\n",
    "    It will be deafe to pleading and excuses,\n",
    "    Nor teares, nor prayers shall purchase our abuses.\n",
    "    Therefore vse none, let Romeo hence in hast,\n",
    "    Else when he is found, that houre is his last.\n",
    "    Beare hence his body, and attend our will:\n",
    "    Mercy not Murders, pardoning those that kill.\n",
    "    \n",
    "    Iul.\n",
    "    Gallop apace, you fiery footed steedes,\n",
    "    Towards Phoebus lodging, such a Wagoner\n",
    "    As Phaeton would whip you to the west,\n",
    "    And bring in Cloudie night immediately.\n",
    "    Spred thy close Curtaine Loue-performing night,\n",
    "    That run-awayes eyes may wincke, and Romeo\n",
    "    Leape to these armes, vntalkt of and vnseene,\n",
    "    Louers can see to doe their Amorous rights,\n",
    "    And by their owne Beauties: or if Loue be blind,\n",
    "    It best agrees with night: come ciuill night,\n",
    "    Thou sober suted Matron all in blacke,\n",
    "    And learne me how to loose a winning match,\n",
    "    Plaid for a paire of stainlesse Maidenhoods,\n",
    "    Hood my vnman'd blood bayting in my Cheekes,\n",
    "    With thy Blacke mantle, till strange Loue grow bold,\n",
    "    Thinke true Loue acted simple modestie:\n",
    "    Come night, come Romeo, come thou day in night,\n",
    "    For thou wilt lie vpon the wings of night\n",
    "    Whiter then new Snow vpon a Rauens backe:\n",
    "    Come gentle night, come louing blackebrow'd night.\n",
    "    Giue me my Romeo, and when I shall die,\n",
    "    Take him and cut him out in little starres,\n",
    "    And he will make the Face of heauen so fine,\n",
    "    That all the world will be in Loue with night,\n",
    "    And pay no worship to the Garish Sun.\n",
    "    O I haue bought the Mansion of a Loue,\n",
    "    But not possest it, and though I am sold,\n",
    "    Not yet enioy'd, so tedious is this day,\n",
    "    As is the night before some Festiuall,\n",
    "    To an impatient child that hath new robes\n",
    "    And may not weare them, O here comes my Nurse:\n",
    "    Enter Nurse with cords.\n",
    "    Mer.\n",
    "    Helpe me into some house Benuolio,\n",
    "    Or I shall faint: a plague a both your houses.\n",
    "    They haue made wormesmeat of me,\n",
    "    I haue it, and soundly to your Houses.\n",
    "    Enter.\n",
    "    \n",
    "    Rom.\n",
    "    This Gentleman the Princes neere Alie,\n",
    "    My very Friend hath got his mortall hurt\n",
    "    In my behalfe, my reputation stain'd\n",
    "    With Tibalts slaunder, Tybalt that an houre\n",
    "    Hath beene my Cozin: O Sweet Iuliet,\n",
    "    Thy Beauty hath made me Effeminate,\n",
    "    And in my temper softned Valours steele.\n",
    "    Enter Benuolio.\n",
    "    \n",
    "    Ben.\n",
    "    O Romeo, Romeo, braue Mercutio's is dead,\n",
    "    That Gallant spirit hath aspir'd the Cloudes,\n",
    "    Which too vntimely here did scorne the earth\n",
    "    \n",
    "    Rom.\n",
    "    This daies blacke Fate, on mo daies depend,\n",
    "    This but begins, the wo others must end.\n",
    "    Enter Tybalt.\n",
    "    Mer.\n",
    "    Come sir, your Passado\n",
    "    \n",
    "    Rom.\n",
    "    Draw Benuolio, beat downe their weapons:\n",
    "    Gentlemen, for shame forbeare this outrage,\n",
    "    Tibalt, Mercutio, the Prince expresly hath\n",
    "    Forbidden bandying in Verona streetes.\n",
    "    Hold Tybalt, good Mercutio.\n",
    "    \n",
    "    Mer.\n",
    "    I am hurt.\n",
    "    A plague a both the Houses, I am sped:\n",
    "    Is he gone and hath nothing?\n",
    "    \n",
    "    Ben.\n",
    "    What art thou hurt?\n",
    "    Cap.\n",
    "    Wi. Tybalt, my Cozin? O my Brothers Child,\n",
    "    O Prince, O Cozin, Husband, O the blood is spild\n",
    "    Of my deare kinsman. Prince as thou art true,\n",
    "    For bloud of ours, shed bloud of Mountague.\n",
    "    O Cozin, Cozin\n",
    "    \n",
    "    Prin.\n",
    "    Benuolio, who began this Fray?\n",
    "    \n",
    "    Ben.\n",
    "    Tybalt here slaine, whom Romeo's hand did slay,\n",
    "    Romeo that spoke him faire, bid him bethinke\n",
    "    How nice the Quarrell was, and vrg'd withall\n",
    "    Your high displeasure: all this vttered,\n",
    "    With gentle breath, calme looke, knees humbly bow'd\n",
    "    Could not take truce with the vnruly spleene\n",
    "    Of Tybalts deafe to peace, but that he Tilts\n",
    "    With Peircing steele at bold Mercutio's breast,\n",
    "    Who all as hot, turnes deadly point to point,\n",
    "    And with a Martiall scorne, with one hand beates\n",
    "    Cold death aside, and with the other sends\n",
    "    It back to Tybalt, whose dexterity\n",
    "    Retorts it: Romeo he cries aloud,\n",
    "    Hold Friends, Friends part, and swifter then his tongue,\n",
    "    His aged arme, beats downe their fatall points,\n",
    "    And twixt them rushes, vnderneath whose arme,\n",
    "    An enuious thrust from Tybalt, hit the life\n",
    "    Of stout Mercutio, and then Tybalt fled.\n",
    "    But by and by comes backe to Romeo,\n",
    "    Who had but newly entertained Reuenge,\n",
    "    And too't they goe like lightning, for ere I\n",
    "    Could draw to part them, was stout Tybalt slaine:\n",
    "    And as he fell, did Romeo turne and flie:\n",
    "    This is the truth, or let Benuolio die\n",
    "    \n",
    "    Cap.\n",
    "    Wi. He is a kinsman to the Mountague,\n",
    "    Affection makes him false, he speakes not true:\n",
    "    Some twenty of them fought in this blacke strife,\n",
    "    And all those twenty could but kill one life.\n",
    "    I beg for Iustice, which thou Prince must giue:\n",
    "    Romeo slew Tybalt, Romeo must not liue\n",
    "    Ben.\n",
    "    Here comes the Furious Tybalt backe againe\n",
    "    \n",
    "    Rom.\n",
    "    He gon in triumph, and Mercutio slaine?\n",
    "    Away to heauen respectiue Lenitie,\n",
    "    And fire and Fury, be my conduct now.\n",
    "    Now Tybalt take the Villaine backe againe\n",
    "    That late thou gau'st me, for Mercutios soule\n",
    "    Is but a little way aboue our heads,\n",
    "    Staying for thine to keepe him companie:\n",
    "    Either thou or I, or both, must goe with him\n",
    "    \n",
    "    Tib.\n",
    "    Thou wretched Boy that didst consort him here,\n",
    "    Shalt with him hence\n",
    "    \n",
    "    Rom.\n",
    "    This shall determine that.\n",
    "    \n",
    "    QUESTION: Who killed Mercutio?\n",
    "    ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We use max_new_tokens=3 here because words like \"Tybalt\" may be split into multiple tokens (e.g., \"Ty\", \"b\", \"alt\").\n",
    "# It's often tricky to get exactly one word due to subword tokenization.\n",
    "result = llm(prompt, max_new_tokens=5, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "# extract answer from full result, as before\n",
    "generated_answer = result[len(prompt):].strip()\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334fb0e",
   "metadata": {},
   "source": [
    "Tybalt\n",
    "\n",
    "\n",
    "If you're working in Colab, consider using quantized models (e.g., via `bitsandbytes`) or calling the model via Hugging Face's hosted Inference API.\n",
    "\n",
    "## Concluding remarks\n",
    "\n",
    "This notebook introduced a basic Retrieval-Augmented Generation (RAG) pipeline for factual question answering using *Romeo and Juliet*. The goal was to build a simple but functioning system and surface practical lessons about how to improve performance.\n",
    "\n",
    "**For retrieval**, we explored and discussed improvements such as:\n",
    "\n",
    "- Using stronger embedding models (e.g., upgrading from `MiniLM` to `all-mpnet-base-v2`).\n",
    "- Adopting a question-aligned chunking strategy, where chunks were grouped by speaker turns to better match the structure of expected queries.\n",
    "- Implementing cosine similarity retrieval, which better handles variation in chunk lengths and embedding magnitudes.\n",
    "- Briefly mentioning reranking as a next step, though not yet implemented.\n",
    "\n",
    "**For generation**, we found that:\n",
    "\n",
    "- Instruction-tuned language models yield more precise and context-sensitive answers.\n",
    "- Prompt formatting significantly affects the clarity and relevance of the generated output.\n",
    "- Post-processing may be necessary for trimming or cleaning model responses, especially in short-form QA tasks.\n",
    "\n",
    "While larger models consistently improve both retrieval and generation, thoughtful design choices—such as aligning chunk structure to question types, using the right embedding normalization, and writing effective prompts—can yield substantial gains, even in smaller pipelines.\n",
    "\n",
    "This notebook serves as a first step in a broader RAG workflow. Future notebooks will experiment with more flexible chunking, incorporate reranking, and test the system’s ability to handle interpretive or subjective questions.\n",
    "\n",
    "\n",
    "## See also\n",
    "- [**Kaggle RAG Challenge**: WattBot](https://www.kaggle.com/competitions/WattBot2025/overview): Put your RAG methods to the test in this ML+X hosted Kaggle challenge (featured in [MLM25](https://ml-marathon.wisc.edu/)).\n",
    "- [**Workshop**:Intro to Natural Language Processing (NLP)](https://uw-madison-datascience.github.io/ML-X-Nexus/Learn/Workshops/Intro-Deeplearning_PyTorch.html): Brush up on NLP basics before diving head-first into RAG pipelines."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
