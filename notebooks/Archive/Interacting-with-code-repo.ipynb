{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73490f8-73bb-4036-a1a9-6599f59f168e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Using a GitHub Personal Access Token (PAT) to Push/Pull from a SageMaker Notebook\"\n",
    "teaching: 25\n",
    "exercises: 10\n",
    "---\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::: questions \n",
    "\n",
    "- How can I securely push/pull code to and from GitHub within a SageMaker notebook?\n",
    "- What steps are necessary to set up a GitHub PAT for authentication in SageMaker?\n",
    "- How can I convert notebooks to `.py` files and ignore `.ipynb` files in version control?\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: objectives\n",
    "\n",
    "- Configure Git in a SageMaker notebook to use a GitHub Personal Access Token (PAT) for HTTPS-based authentication.\n",
    "- Securely handle credentials in a notebook environment using `getpass`.\n",
    "- Convert `.ipynb` files to `.py` files for better version control practices in collaborative projects.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1c494-af7a-41d1-830e-f39ca0ce8052",
   "metadata": {},
   "source": [
    "# Using a GitHub Personal Access Token (PAT) to Push/Pull from a SageMaker Notebook\n",
    "\n",
    "When working in SageMaker notebooks, you may often need to push code updates to GitHub repositories. However, SageMaker notebooks are typically launched with temporary instances that don’t persist configurations, including SSH keys, across sessions. This makes HTTPS-based authentication, secured with a GitHub Personal Access Token (PAT), a practical solution. PATs provide flexibility for authentication and enable seamless interaction with both public and private repositories directly from your notebook. \n",
    "\n",
    "> **Important Note**: Personal access tokens are powerful credentials that grant specific permissions to your GitHub account. To ensure security, only select the minimum necessary permissions and handle the token carefully.\n",
    "\n",
    "\n",
    "## Step 1: Generate a Personal Access Token (PAT) on GitHub\n",
    "\n",
    "1. Go to **Settings > Developer settings > Personal access tokens** on GitHub.\n",
    "2. Click **Generate new token**, select **Classic**.\n",
    "3. Give your token a descriptive name (e.g., \"SageMaker Access Token\") and set an expiration date if desired for added security.\n",
    "4. **Select the minimum permissions needed**:\n",
    "   - **For public repositories**: Choose only **`public_repo`**.\n",
    "   - **For private repositories**: Choose **`repo`** (full control of private repositories).\n",
    "   - Optional permissions, if needed:\n",
    "     - **`repo:status`**: Access commit status (if checking status checks).\n",
    "     - **`workflow`**: Update GitHub Actions workflows (only if working with GitHub Actions).\n",
    "5. Generate the token and **copy it** (you won’t be able to see it again).\n",
    "\n",
    "> **Caution**: Treat your PAT like a password. Avoid sharing it or exposing it in your code. Store it securely (e.g., via a password manager like LastPass) and consider rotating it regularly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519df3b-a610-45bd-bc97-89d202f08f0f",
   "metadata": {},
   "source": [
    "## Step 2: Configure Git `user.name` and `user.email`\n",
    "In your SageMaker or Jupyter notebook environment, run the following commands to set up your Git user information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc178178-66f5-4787-bf22-f10163be29c8",
   "metadata": {},
   "source": [
    "#### Directory setup\n",
    "Let's make sure we're starting at the same directory. Cd to the root directory of this instance before going further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47497f6e-18ce-4463-84d4-feade72564dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n",
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170bc5ec-70b2-4266-824d-0835828fcdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!git config --global user.name \"Chris Endemann\"\n",
    "!git config --global user.email endeman@wisc.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b1e89-6625-403b-a746-e88fc3e4c703",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- **`user.name`**: This is your GitHub username, which will appear in the commit history as the author of the changes.\n",
    "- **`user.email`**: This should match the email associated with your GitHub account so that commits are properly linked to your profile.\n",
    "\n",
    "Setting this globally (`--global`) will ensure the configuration persists across all repositories in the environment. If you’re working in a temporary environment, you may need to re-run this configuration after a restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f1b11-e43b-45ab-8315-a429805452f0",
   "metadata": {},
   "source": [
    "## Step 3: Use `getpass` to Prompt for Username and PAT\n",
    "\n",
    "The `getpass` library allows you to input your GitHub username and PAT without exposing them in the notebook. This approach ensures you’re not hardcoding sensitive information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b41eaac5-69eb-4e88-8bda-1ba7e25a0beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Prompt for GitHub username and PAT securely\n",
    "github_url = 'github.com/UW-Madison-DataScience/test_AWS.git' # found under Code -> Clone -> HTTPS (remote the https:// before the rest of the address)\n",
    "username = input(\"GitHub Username: \")\n",
    "token = getpass.getpass(\"GitHub Personal Access Token (PAT): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1856be-09fe-4010-94d0-02666b2b6a28",
   "metadata": {},
   "source": [
    "**Note**: After running, you may want to comment out the above code so that you don't have to enter in your login every time you run your whole notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795dac33-3a26-40cd-b517-59b8600f68f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Explanation\n",
    "\n",
    "- **`input(\"GitHub Username: \")`**: Prompts you to enter your GitHub username.\n",
    "- **`getpass.getpass(\"GitHub Personal Access Token (PAT): \")`**: Prompts you to securely enter the PAT, keeping it hidden on the screen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5fe80-bc91-46ff-827e-257736d3f46c",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Add, Commit, and Push Changes with Manual Authentication\n",
    "### 1. Navigate to the Repository Directory (adjust the path if needed):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633b7da6-05aa-4c0d-b9ad-1677100fb994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n",
      "/home/ec2-user/SageMaker/test_AWS\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd test_AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f37fc-2df2-4ddf-b910-abd4b744c01a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Preview changes: You may see elaborate changes if you are tracking ipynb files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00dda9ff-513c-451c-8881-46e0aee4eeb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbdiff /tmp/git-blob-PLwmtf/04_Interacting-with-code-repo.ipynb 04_Interacting-with-code-repo.ipynb\n",
      "--- /tmp/git-blob-PLwmtf/04_Interacting-with-code-repo.ipynb  2024-11-01 21:19:40.081619\n",
      "+++ 04_Interacting-with-code-repo.ipynb  2024-11-01 21:19:30.253573\n",
      "\u001b[34m\u001b[1m## replaced /cells/20/execution_count:\u001b[0m\n",
      "\u001b[31m-  55\n",
      "\u001b[32m+  79\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## inserted before /cells/20/outputs/0:\u001b[0m\n",
      "\u001b[32m+  output:\n",
      "\u001b[32m+    output_type: stream\n",
      "\u001b[32m+    name: stdout\n",
      "\u001b[32m+    text:\n",
      "\u001b[32m+      [main bc28ce1] Updates from Jupyter notebooks\n",
      "\u001b[32m+       1 file changed, 875 insertions(+), 56 deletions(-)\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## deleted /cells/20/outputs/0:\u001b[0m\n",
      "\u001b[31m-  output:\n",
      "\u001b[31m-    output_type: stream\n",
      "\u001b[31m-    name: stdout\n",
      "\u001b[31m-    text:\n",
      "\u001b[31m-      [main 0363cc2] Added updates from Jupyter notebook\n",
      "\u001b[31m-       7 files changed, 416 insertions(+), 91 deletions(-)\n",
      "\u001b[31m-       delete mode 100644 00_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[31m-       create mode 100644 01_Setting-up-S3-bucket.md\n",
      "\u001b[31m-       create mode 100644 02_Setting-up-notebook-environment.md\n",
      "\u001b[31m-       create mode 100644 03_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[31m-       rename push-git-updates.ipynb => 04_Interacting-with-code-repo.ipynb (77%)\n",
      "\u001b[31m-       rename 01_Intro-train-models.ipynb => 05_Intro-train-models.ipynb (100%)\n",
      "\u001b[31m-       rename 02_Hyperparameter-tuning.ipynb => 06_Hyperparameter-tuning.ipynb (100%)\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/22/execution_count:\u001b[0m\n",
      "\u001b[31m-  56\n",
      "\u001b[32m+  80\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/22/outputs/0/text:\u001b[0m\n",
      "\u001b[36m@@ -1,4 +1,4 @@\u001b[m\n",
      " From https://github.com/UW-Madison-DataScience/test_AWS\u001b[m\n",
      "  * branch            main       -> FETCH_HEAD\u001b[m\n",
      "\u001b[31m-   adfe7b1..637d64c  main       -> origin/main\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m   637d64c..0363cc2  main       -> origin/main\u001b[m\n",
      " Already up to date.\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/26/execution_count:\u001b[0m\n",
      "\u001b[31m-  57\n",
      "\u001b[32m+  81\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/26/outputs/0/text:\u001b[0m\n",
      "\u001b[36m@@ -1,9 +1,9 @@\u001b[m\n",
      "\u001b[31m-Enumerating objects: 7, done.\u001b[m\n",
      "\u001b[31m-Counting objects: 100% (7/7), done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mEnumerating objects: 5, done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mCounting objects: 100% (5/5), done.\u001b[m\n",
      " Delta compression using up to 2 threads\u001b[m\n",
      "\u001b[31m-Compressing objects: 100% (6/6), done.\u001b[m\n",
      "\u001b[31m-Writing objects: 100% (6/6), 11.22 KiB | 5.61 MiB/s, done.\u001b[m\n",
      "\u001b[31m-Total 6 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mCompressing objects: 100% (3/3), done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mWriting objects: 100% (3/3), 10.51 KiB | 5.25 MiB/s, done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mTotal 3 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[m\n",
      " remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\u001b[m\n",
      " To https://github.com/UW-Madison-DataScience/test_AWS.git\u001b[m\n",
      "\u001b[31m-   637d64c..0363cc2  main -> main\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m   0363cc2..bc28ce1  main -> main\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## inserted before /cells/29:\u001b[0m\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: f86a6d55-5279-423f-864a-7810dd414def\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      import subprocess\n",
      "\u001b[32m+      import os\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      # List all .py files in the directory\n",
      "\u001b[32m+      scripts = [f for f in os.listdir() if f.endswith('.py')]\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      # Convert each .py file to .ipynb using jupytext\n",
      "\u001b[32m+      for script in scripts:\n",
      "\u001b[32m+          output_file = script.replace('.py', '.ipynb')\n",
      "\u001b[32m+          subprocess.run([\"jupytext\", \"--to\", \"notebook\", script, \"--output\", output_file])\n",
      "\u001b[32m+          print(f\"Converted {script} to {output_file}\")\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git diff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f534e-4947-4078-80ab-6f21af394826",
   "metadata": {},
   "source": [
    "### 3. Convert json ipynb files to .py\n",
    "\n",
    "To avoid tracking ipynb files directly, which are formatted as json, we may want to convert our notebook to .py first (plain text). This will make it easier to see our code edits across commits. Otherwise, each small edit will have massive changes associated with it.\n",
    "\n",
    "#### Benefits of converting to `.py` before Committing\n",
    "\n",
    "- **Cleaner Version Control**: `.py` files have cleaner diffs and are easier to review and merge in Git.\n",
    "- **Script Compatibility**: Python files are more compatible with other environments and can run easily from the command line.\n",
    "- **Reduced Repository Size**: `.py` files are generally lighter than `.ipynb` files since they don’t store outputs or metadata.\n",
    "\n",
    "Converting notebooks to `.py` files helps streamline the workflow for both collaborative projects and deployments. This approach also maintains code readability and minimizes potential issues with notebook-specific metadata in Git history. Here’s how to convert `.ipynb` files to `.py` in SageMaker without needing to export or download files:\n",
    "\n",
    "#### Method 1: Using JupyText\n",
    "\n",
    "1. **Install Jupytext** (if you haven’t already):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb6345d-16b7-44af-b026-98abe4a060a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupytext\n",
      "  Downloading jupytext-1.16.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (3.0.0)\n",
      "Collecting mdit-py-plugins (from jupytext)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: nbformat in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (5.10.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (6.0.2)\n",
      "Requirement already satisfied: tomli in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (2.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (5.14.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->jupytext) (3.1.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.6)\n",
      "Downloading jupytext-1.16.4-py3-none-any.whl (153 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: mdit-py-plugins, jupytext\n",
      "Successfully installed jupytext-1.16.4 mdit-py-plugins-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install jupytext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb184d37-9aed-45e2-b6ee-b575695be87e",
   "metadata": {},
   "source": [
    "1. **Run the following command** in a notebook cell to convert the current notebook to a `.py` file:\n",
    "\n",
    "This command will create a `.py` file in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6be6b34e-945b-4458-9c13-20be0c24e07b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets.py\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_notebook.ipynb' with your actual notebook filename\n",
    "!jupytext --to py Data-storage-and-access-via-buckets.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c40ca-6471-4ede-8962-f37d9fb9cf93",
   "metadata": {},
   "source": [
    "#### Method 2: Automated Script for Converting All Notebooks in a Directory\n",
    "\n",
    "If you have multiple notebooks to convert, you can automate the conversion process by running this script, which converts all `.ipynb` files in the current directory to `.py` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac899c70-e387-492d-b8eb-64c759faef9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 05_Intro-train-models.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 05_Intro-train-models.py\n",
      "Converted 05_Intro-train-models.ipynb to 05_Intro-train-models.py\n",
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets.py\n",
      "Converted 03_Data-storage-and-access-via-buckets.ipynb to 03_Data-storage-and-access-via-buckets.py\n",
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets-test.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets-test.py\n",
      "Converted 03_Data-storage-and-access-via-buckets-test.ipynb to 03_Data-storage-and-access-via-buckets-test.py\n",
      "[jupytext] Reading 06_Hyperparameter-tuning.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 06_Hyperparameter-tuning.py\n",
      "Converted 06_Hyperparameter-tuning.ipynb to 06_Hyperparameter-tuning.py\n",
      "[jupytext] Reading create_large_data.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of create_large_data.py\n",
      "Converted create_large_data.ipynb to create_large_data.py\n",
      "[jupytext] Reading 04_Interacting-with-code-repo.ipynb in format ipynb\n",
      "[jupytext] Writing 04_Interacting-with-code-repo.py (destination file replaced)\n",
      "Converted 04_Interacting-with-code-repo.ipynb to 04_Interacting-with-code-repo.py\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# List all .ipynb files in the directory\n",
    "notebooks = [f for f in os.listdir() if f.endswith('.ipynb')]\n",
    "\n",
    "# Convert each notebook to .py using jupytext\n",
    "for notebook in notebooks:\n",
    "    output_file = notebook.replace('.ipynb', '.py')\n",
    "    subprocess.run([\"jupytext\", \"--to\", \"py\", notebook, \"--output\", output_file])\n",
    "    print(f\"Converted {notebook} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6408a-7501-4239-abdb-d45da78472b7",
   "metadata": {},
   "source": [
    "### 4. Adding .ipynb to gitigore\n",
    "\n",
    "Adding `.ipynb` files to `.gitignore` is a good practice if you plan to only commit `.py` scripts. This will prevent accidental commits of Jupyter Notebook files across all subfolders in the repository.\n",
    "\n",
    "Here’s how to add `.ipynb` files to `.gitignore` to ignore them project-wide:\n",
    "\n",
    "1. **Open or Create the `.gitignore` File**:\n",
    "\n",
    "    ```python\n",
    "    !ls -a # check for existing .gitignore file\n",
    "    ```\n",
    "    \n",
    "   - If you don’t already have a `.gitignore` file in the repository root (use '!ls -a' to check, you can create one by running:\n",
    "   \n",
    "     ```python\n",
    "     !touch .gitignore\n",
    "     ```\n",
    "\n",
    "\n",
    "2. **Add `.ipynb` Files to `.gitignore`**:\n",
    "\n",
    "   - Append the following line to your `.gitignore` file to ignore all `.ipynb` files in all folders:\n",
    "\n",
    "     ```plaintext\n",
    "     *.ipynb # Ignore all Jupyter Notebook files\n",
    "     ```\n",
    "\n",
    "   - You can add this line using a command within your notebook:\n",
    "   \n",
    "     ```python\n",
    "     with open(\".gitignore\", \"a\") as gitignore:\n",
    "         gitignore.write(\"\\n# Ignore all Jupyter Notebook files\\n*.ipynb\\n\")\n",
    "     ```\n",
    "\n",
    "\n",
    "\n",
    "3. **Verify and Commit the `.gitignore` File**:\n",
    "\n",
    "   - Add and commit the updated `.gitignore` file to ensure it’s applied across the repository.\n",
    "\n",
    "     ```python\n",
    "     !git add .gitignore\n",
    "     !git commit -m \"Add .ipynb files to .gitignore to ignore notebooks\"\n",
    "     !git push origin main\n",
    "     ```\n",
    "\n",
    "This setup will:\n",
    "- Prevent all `.ipynb` files from being tracked by Git.\n",
    "- Keep your repository cleaner, containing only `.py` scripts for easier version control and reduced repository size. \n",
    "\n",
    "Now any new or existing notebooks won’t show up as untracked files in Git, ensuring your commits stay focused on the converted `.py` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87d7e0-e14e-4b04-a5a2-5ac742e6b467",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "2. **Add and Commit Changes**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1681c48e-9d03-490a-ae4c-2ae84275c7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main f4b268e] Updates from Jupyter notebooks\n",
      " 10 files changed, 3163 insertions(+), 256 deletions(-)\n",
      " delete mode 100644 01_Setting-up-S3-bucket.md\n",
      " delete mode 100644 02_Setting-up-notebook-environment.md\n",
      " rename 03_Data-storage-and-access-via-buckets.ipynb => Accessing-S3-via-SageMaker-notebooks.ipynb (72%)\n",
      " create mode 100644 Accessing-S3-via-SageMaker-notebooks.md\n",
      " rename 04_Interacting-with-code-repo.ipynb => Interacting-with-code-repo.ipynb (93%)\n"
     ]
    }
   ],
   "source": [
    "!git add . # you may also add files one at a time, for further specificity over the associated commit message\n",
    "!git commit -m \"Updates from Jupyter notebooks\" # in general, your commit message should be more specific!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebecd0-9f39-43c6-8efa-070c7748c52c",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. **Pull the Latest Changes from the Main Branch**: Pull the latest changes from the remote main branch to ensure your local branch is up-to-date.\n",
    "\n",
    "    Recommended: Set the Pull Strategy for this Repository (Merge by Default)\n",
    "\n",
    "    All options:\n",
    "\n",
    "    * Merge (pull.rebase false): Combines the remote changes into your local branch as a merge commit.\n",
    "    * Rebase (pull.rebase true): Replays your local changes on top of the updated main branch, resulting in a linear history.\n",
    "    * Fast-forward only (pull.ff only): Only pulls if the local branch can fast-forward to the remote without diverging (no new commits locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144840f8-9733-4888-99d4-3b04c12458ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 6 (delta 2), reused 6 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (6/6), 152.14 KiB | 2.67 MiB/s, done.\n",
      "From https://github.com/UW-Madison-DataScience/test_AWS\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   1602325..b2a59c3  main       -> origin/main\n",
      "hint: Waiting for your editor to close the file... \u001b7\u001b[?47h\u001b[>4;2m\u001b[?1h\u001b=\u001b[?2004h\u001b[?1004h\u001b[1;24r\u001b[?12h\u001b[?12l\u001b[22;2t\u001b[22;1t\u001b[29m\u001b[m\u001b[H\u001b[2J\u001b[?25l\u001b[24;1H\"~/SageMaker/test_AWS/.git/MERGE_MSG\" 6L, 300B\u001b[2;1H▽\u001b[6n\u001b[2;1H  \u001b[3;1H\u001bPzz\u001b\\\u001b[0%m\u001b[6n\u001b[3;1H           \u001b[1;1H\u001b[>c\u001b]10;?\u0007\u001b]11;?\u0007\u001b[1;1H\u001b[33mMerge branch 'main' of https://github.com/UW-Madis\u001b[mon-DataScience/test_AWS\n",
      "\u001b[34m# Please enter a commit message to explain why this merge is necessary,\u001b[m\u001b[2;72H\u001b[K\u001b[3;1H\u001b[34m# especially if it merges an updated upstream into a topic branch.\u001b[m\u001b[3;67H\u001b[K\u001b[4;1H\u001b[34m#\n",
      "# Lines starting with '#' will be ignored, and an empty message aborts\n",
      "# the commit.\u001b[m\n",
      "\u001b[1m\u001b[34m~                                                                               \u001b[8;1H~                                                                               \u001b[9;1H~                                                                               \u001b[10;1H~                                                                               \u001b[11;1H~                                                                               \u001b[12;1H~                                                                               \u001b[13;1H~                                                                               \u001b[14;1H~                                                                               \u001b[15;1H~                                                                               \u001b[16;1H~                                                                               \u001b[17;1H~                                                                               \u001b[18;1H~                                                                               \u001b[19;1H~                                                                               \u001b[20;1H~                                                                               \u001b[21;1H~                                                                               \u001b[22;1H~                                                                               \u001b[23;1H~                                                                               \u001b[m\u001b[24;63H1,1\u001b[11CAll\u001b[1;1H\u001b[?25h\u001b[?4m\u001b[?25l\u001b[24;1HType  :qa  and press <Enter> to exit Vim\u001b[24;41H\u001b[K\u0007\u001b[24;63H1,1\u001b[11CAll\u001b[1;1H\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!git config pull.rebase false # Combines the remote changes into your local branch as a merge commit.\n",
    "\n",
    "!git pull origin main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ad564-df9f-4484-b39f-771f57e99123",
   "metadata": {},
   "source": [
    "If you get merge conflicts, be sure to resolve those before moving forward (e.g., use git checkout -> add -> commit). You can skip the below code if you don't have any conflicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31ed04f1-6a2d-4d04-bda9-cdd9dc8f84ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep your local changes in one conflicting file\n",
    "# !git checkout --ours train_nn.py\n",
    "\n",
    "# Keep remote version for the other conflicting file\n",
    "# !git checkout --theirs train_xgboost.py\n",
    "\n",
    "# # Stage the files to mark the conflicts as resolved\n",
    "# !git add train_nn.py\n",
    "# !git add train_xgboost.py\n",
    "\n",
    "# # Commit the merge result\n",
    "# !git commit -m \"Resolved merge conflicts by keeping local changes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfce6eb-ee29-48bd-9895-56b0abf4b3e7",
   "metadata": {},
   "source": [
    "4. **Push Changes and Enter Credentials**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86cd209c-9b93-488e-a159-f6f65f94511c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: unable to access 'https://{github_url}/': URL rejected: Bad hostname\n"
     ]
    }
   ],
   "source": [
    "# Push with embedded credentials from getpass (avoids interactive prompt)\n",
    "!git push https://{username}:{token}@{github_url} main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43658069-6085-4680-aacc-c91155625e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5: Pulling .py files and converting back to notebook format\n",
    "\n",
    "Let's assume you've taken a short break from your work, and you would like to start again by pulling in your code repo. If you'd like to work with notebook files again, you can again use jupytext to convert your `.py` files back to `.ipynb`\n",
    "\n",
    "This command will create `03_Data-storage-and-access-via-buckets-test.ipynb` in the current directory, converting the Python script to a Jupyter Notebook format. Jupytext handles the conversion gracefully without expecting the `.py` file to be in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48e812c7-45f4-4adf-9bd3-1dcbc59e9052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets.py in format py\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/bin/jupytext\", line 8, in <module>\n",
      "    sys.exit(jupytext())\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/jupytext/cli.py\", line 497, in jupytext\n",
      "    exit_code += jupytext_single_file(nb_file, args, log)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/jupytext/cli.py\", line 561, in jupytext_single_file\n",
      "    notebook = read(nb_file, fmt=fmt, config=config)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/jupytext/jupytext.py\", line 431, in read\n",
      "    with open(fp, encoding=\"utf-8\") as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '03_Data-storage-and-access-via-buckets.py'\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_script.py' with your actual filename\n",
    "!jupytext --to notebook Data-storage-and-access-via-buckets.py --output Data-storage-and-access-via-buckets-test.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb709996-e2c8-4f38-9f3b-0dc0953acf15",
   "metadata": {},
   "source": [
    "### Applying to all .py files\n",
    "To convert all of your .py files to notebooks, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f86a6d55-5279-423f-864a-7810dd414def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading train_xgboost.py in format py\n",
      "[jupytext] Writing train_xgboost.ipynb\n",
      "Converted train_xgboost.py to train_xgboost.ipynb\n",
      "[jupytext] Reading train_nn.py in format py\n",
      "[jupytext] Writing train_nn.ipynb\n",
      "Converted train_nn.py to train_nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# List all .py files in the directory\n",
    "scripts = [f for f in os.listdir() if f.endswith('.py')]\n",
    "\n",
    "# Convert each .py file to .ipynb using jupytext\n",
    "for script in scripts:\n",
    "    output_file = script.replace('.py', '.ipynb')\n",
    "    subprocess.run([\"jupytext\", \"--to\", \"notebook\", script, \"--output\", output_file])\n",
    "    print(f\"Converted {script} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c6f294-0fb1-41f3-b9ef-797b4bf9bad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/test_AWS\n",
      "[NbConvertApp] Converting notebook Interacting-with-code-repo.ipynb to markdown\n",
      "[NbConvertApp] Writing 25648 bytes to Interacting-with-code-repo.md\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!jupyter nbconvert --to markdown Interacting-with-code-repo.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b87bfb-1781-4dd9-a823-0af26154565b",
   "metadata": {},
   "source": [
    ":::::::::::::::::::::::::::::::::::::: keypoints \n",
    "\n",
    "- Use a GitHub PAT for HTTPS-based authentication in temporary SageMaker notebook instances.\n",
    "- Securely enter sensitive information in notebooks using `getpass`.\n",
    "- Converting `.ipynb` files to `.py` files helps with cleaner version control and easier review of changes.\n",
    "- Adding `.ipynb` files to `.gitignore` keeps your repository organized and reduces storage.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
