<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Intro to AWS SageMaker for Predictive ML/AI: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Learn how to run predictive AI/ML procedures (train, tune, etc.) using AWS SageMaker. These examples focus on narrow &amp;quot;predictive ML/AI&amp;quot; cases, where models are trained to perform a single function (contrasing with &amp;quot;foundation&amp;quot; model use via AWS Bedrock). These materials are directed towards participants of the 2024 Machine Learning Marathon, and some instructions may pertain only to that group. A more general purpose version of this workshop will be made available in future months." src="assets/images/incubator-logo.svg"><span class="badge text-bg-warning">
          <abbr title="This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-triangle" style="border-radius: 5px"></i>
              Alpha
            </a>
            <span class="visually-hidden">This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Learn how to run predictive AI/ML procedures (train, tune, etc.) using AWS SageMaker. These examples focus on narrow &amp;quot;predictive ML/AI&amp;quot; cases, where models are trained to perform a single function (contrasing with &amp;quot;foundation&amp;quot; model use via AWS Bedrock). These materials are directed towards participants of the 2024 Machine Learning Marathon, and some instructions may pertain only to that group. A more general purpose version of this workshop will be made available in future months." src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Intro to AWS SageMaker for Predictive ML/AI
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Intro to AWS SageMaker for Predictive ML/AI
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
<li><a class="dropdown-item" href="instances-for-ML.html">Instances for ML</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Intro to AWS SageMaker for Predictive ML/AI
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="SageMaker-overview.html">1. Overview of Amazon SageMaker</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="Data-storage-setting-up-S3.html">2. Data Storage: Setting up S3</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="SageMaker-notebooks-as-controllers.html">3. Notebooks as Controllers</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="Accessing-S3-via-SageMaker-notebooks.html">4. Accessing and Managing Data in S3 with SageMaker Notebooks</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="Interacting-with-code-repo.html">5. Using a GitHub Personal Access Token (PAT) to Push/Pull from a SageMaker Notebook</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="Training-models-in-SageMaker-notebooks.html">6. Training Models in SageMaker: Intro</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="Training-models-in-SageMaker-notebooks-part2.html">7. Training Models in SageMaker: PyTorch Example</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="Hyperparameter-tuning.html">8. Hyperparameter Tuning in SageMaker: Neural Network Example</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="00_Overview-RAG-on-AWS.html">9. Overview of RAG Workflows on AWS</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="01_RAG_WattBot_GPU-instance.html">10. RAG with a Notebook GPU</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush12">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading12">
        <a href="02_RAG_WattBot_Processing_Jobs.html">11. RAG with Processing Jobs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush13">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading13">
        <a href="03_RAG_WattBot_Bedrock.html">12. RAG with Bedrock</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush14">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading14">
        <a href="Resource-management-cleanup.html">13. Resource Management and Monitoring</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Glossary</a></li>
<li><a href="instances-for-ML.html">Instances for ML</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-SageMaker-overview"><p>Content from <a href="SageMaker-overview.html">Overview of Amazon SageMaker</a></p>
<hr>
<p>Last updated on 2025-11-07 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/SageMaker-overview.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Why use SageMaker for machine learning?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Introduce SageMaker</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Amazon SageMaker is a comprehensive machine learning (ML) platform
that empowers users to build, train, tune, and deploy models at scale.
Designed to streamline the ML workflow, SageMaker supports data
scientists and researchers in tackling complex machine learning problems
without needing to manage underlying infrastructure. This allows you to
focus on developing and refining your models while leveraging AWS’s
robust computing resources for efficient training and deployment.</p>
<div class="section level3">
<h3 id="why-use-sagemaker-for-machine-learning">Why use SageMaker for machine learning?<a class="anchor" aria-label="anchor" href="#why-use-sagemaker-for-machine-learning"></a>
</h3>
<p>SageMaker provides several features that make it an ideal choice for
researchers and ML practitioners:</p>
<ul>
<li><p><strong>High-performance compute only when needed</strong>:
SageMaker lets you develop interactively in lightweight, inexpensive
notebook environments (or your own laptop) and then launch training,
tuning, or inference jobs on more powerful <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/reference.html#cloud-compute-essentials" class="external-link">instance
types</a> only when necessary. This approach keeps costs low during
development and ensures you only pay for expensive compute when you’re
actively using it.</p></li>
<li><p><strong>Support for custom scripts</strong>: Most training and
inference scripts can be run using pre-configured <em>estimators</em> or
<em>containers</em> that come with popular ML frameworks such as
scikit-learn, PyTorch, TensorFlow, and Hugging Face already installed.
In many cases, you can simply include a <code>requirements.txt</code>
file to add any additional dependencies you need. When you need more
control, SageMaker also supports fully custom Docker containers, so you
can bring your own code, dependencies, and environments for training,
tuning, and inference — all deployed on scalable AWS
infrastructure.</p></li>
<li>
<p><strong>Flexible compute options</strong>: SageMaker lets you
easily select instance types tailored to your project needs. For
exploratory analysis, use a lightweight CPU (e.g., ml.m5.large). For
compute-intensive tasks, such as training deep learning models, you can
switch to GPU instances for faster processing. We’ll cover instances
more in-depth throughout the lesson (and how to select them), but here’s
a preview of the the different types:</p>
<ul>
<li>
<strong>CPU instances (e.g., ml.m5.large — $0.12/hour)</strong>:
Suitable for general ML workloads, feature engineering, and inference
tasks.</li>
<li>
<strong>Memory-optimized instances (e.g., ml.r5.2xlarge —
$0.65/hour)</strong>: Best for handling large datasets in memory.</li>
<li>
<strong>GPU instances (e.g., ml.p3.2xlarge — $3.83/hour)</strong>:
Optimized for compute-intensive tasks like deep learning training,
offering accelerated processing.</li>
<li>For more details, check out the supplemental “<a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">Instances
for ML</a>” page. We’ll discuss this topic more throughout the
lesson.</li>
</ul>
</li>
<li><p><strong>Parallelized training and tuning</strong>: SageMaker
enables parallelized training across multiple instances, reducing
training time for large datasets and complex models. It also supports
parallelized hyperparameter tuning, allowing efficient exploration of
model configurations with minimal code while maintaining fine-grained
control over the process.</p></li>
<li><p><strong>Ease of orchestration / Simplified ML pipelines</strong>:
Traditional high-performance computing (HPC) or high-throughput
computing (HTC) environments often require researchers to break ML
workflows into separate batch jobs, manually orchestrating each step
(e.g., submitting preprocessing, training, cross-validation, and
evaluation as distinct tasks and stitching the results together later).
This can be time-consuming and cumbersome, as it requires converting
standard ML code into complex Directed Acyclic Graphs (DAGs) and job
dependencies. By eliminating the need to manually coordinate compute
jobs, SageMaker dramatically reduces ML pipeline complexity, making it
easier for researchers to quickly develop and iterate on models
efficiently.</p></li>
<li><p><strong>Cost management and monitoring</strong>: SageMaker
includes built-in monitoring tools to help you track and manage costs,
ensuring you can scale up efficiently without unnecessary expenses. For
many common use cases of ML/AI, SageMaker can be very affordable. For
example, training roughly 100 small to medium-sized models (e.g.,
logistic regression, random forests, or lightweight deep learning models
with a few million parameters) on a small dataset (under 10GB) can cost
under $20, making it accessible for many research projects.</p></li>
</ul>
<p>In summary, Amazon SageMaker is a fully managed machine learning
platform that simplifies building, training, tuning, and deploying
models at scale. Unlike traditional research computing environments,
which often require manual job orchestration and complex dependency
management, SageMaker provides an integrated and automated workflow,
allowing users to focus on model development rather than infrastructure.
With support for on-demand compute resources, parallelized training and
hyperparameter tuning, and flexible model deployment options, SageMaker
enables researchers to scale experiments efficiently. Built-in cost
tracking and monitoring tools also help keep expenses manageable, making
SageMaker a practical choice for both small-scale research projects and
large-scale ML pipelines. By combining preconfigured machine learning
algorithms, support for custom scripts, and robust computing power,
SageMaker reduces the complexity of ML development, empowering
researchers to iterate faster and bring models to production more
seamlessly.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>SageMaker simplifies ML workflows by eliminating the need for manual
job orchestration.</li>
<li>Flexible compute options allow users to choose CPU, GPU, or
memory-optimized instances based on workload needs.</li>
<li>Parallelized training and hyperparameter tuning accelerate model
development.</li>
<li>SageMaker supports both built-in ML algorithms and custom scripts
via Docker containers.</li>
<li>Cost monitoring tools help track and optimize spending on AWS
resources.</li>
<li>SageMaker streamlines scaling from experimentation to deployment,
making it suitable for both research and production.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div></section><section id="aio-Data-storage-setting-up-S3"><p>Content from <a href="Data-storage-setting-up-S3.html">Data Storage: Setting up S3</a></p>
<hr>
<p>Last updated on 2025-10-15 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Data-storage-setting-up-S3.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I store and manage data effectively in AWS for SageMaker
workflows?</li>
<li>What are the best practices for using S3 versus EC2 storage for
machine learning projects?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain data storage options in AWS for machine learning
projects.</li>
<li>Describe the advantages of S3 for large datasets and multi-user
workflows.</li>
<li>Outline steps to set up an S3 bucket and manage data within
SageMaker.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="storing-data-on-aws">Storing data on AWS<a class="anchor" aria-label="anchor" href="#storing-data-on-aws"></a>
</h2>
<hr class="half-width">
<p>Machine learning and AI projects rely on data, making efficient
storage and management essential. AWS provides several options for
storing data, each with different use cases and trade-offs.</p>
<blockquote>
<h4 id="consult-your-institutions-it-before-handling-sensitive-data-in-aws">Consult
your institution’s IT before handling sensitive data in AWS</h4>
<p>When using AWS for research, <strong>ensure that no restricted or
sensitive data is uploaded to S3 or any other AWS service <em>unless
explicitly approved by your institution’s IT or cloud security
team</em></strong>. For projects involving sensitive or regulated data
(e.g., HIPAA, FERPA, or proprietary research data), consult your
institution’s cloud security or compliance team to explore approved
solutions. This may include encryption, restricted-access storage, or
dedicated secure environments. If unsure about data &gt; classification,
review your institution’s data security policies before uploading.</p>
</blockquote>
</section><section><h2 class="section-heading" id="options-for-storage-ec2-instance-or-s3">Options for storage: EC2 Instance or S3<a class="anchor" aria-label="anchor" href="#options-for-storage-ec2-instance-or-s3"></a>
</h2>
<hr class="half-width">
<p>When working with SageMaker and other AWS services, you have options
for data storage, primarily <strong>EC2 instances</strong> or
<strong>S3</strong>.</p>
<div class="section level3">
<h3 id="what-is-an-ec2-instance">What is an EC2 instance?<a class="anchor" aria-label="anchor" href="#what-is-an-ec2-instance"></a>
</h3>
<p>An Amazon EC2 (Elastic Compute Cloud) instance is a virtual server
environment where you can run applications, process data, and store data
temporarily. EC2 instances come in various types and sizes to meet
different computing and memory needs, making them versatile for tasks
ranging from light web servers to intensive machine learning workloads.
For example, when you launch a new Jupyter notebook from Sagemaker, this
notebook is run on an an EC2 instance configured to run Jupyter
notebooks, enabling direct data processing.</p>
</div>
<div class="section level3">
<h3 id="when-to-store-data-directly-on-ec2">When to store data directly on EC2<a class="anchor" aria-label="anchor" href="#when-to-store-data-directly-on-ec2"></a>
</h3>
<p>Using an EC2 instance for data storage can be useful for temporary or
small datasets, especially during processing within a Jupyter notebook.
However, this storage is not persistent; if the instance is stopped or
terminated, the data is erased. Therefore, EC2 is ideal for one-off
experiments or intermediate steps in data processing.</p>
<div id="limitations-of-ec2-storage" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="limitations-of-ec2-storage" class="callout-inner">
<h3 class="callout-title">Limitations of EC2 storage</h3>
<div class="callout-content">
<ul>
<li>
<strong>Scalability</strong>: EC2 storage is limited to the
instance’s disk capacity, so it may not be ideal for very large
datasets.</li>
<li>
<strong>Cost</strong>: EC2 storage can be more costly for long-term
use compared to S3.</li>
<li>
<strong>Data Persistence</strong>: EC2 data may be lost if the
instance is stopped or terminated, unless using Elastic Block Store
(EBS) for persistent storage.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="what-is-an-s3-bucket">What is an S3 bucket?<a class="anchor" aria-label="anchor" href="#what-is-an-s3-bucket"></a>
</h3>
<p>Storing data in an <strong>S3 bucket</strong> is generally preferred
for machine learning workflows on AWS, especially when using SageMaker.
An S3 bucket is a container in Amazon S3 (Simple Storage Service) where
you can store, organize, and manage data files. Buckets act as the
top-level directory within S3 and can hold a virtually unlimited number
of files and folders, making them ideal for storing large datasets,
backups, logs, or any files needed for your project. You access objects
in a bucket via a unique <strong>S3 URI</strong> (e.g.,
<code>s3://your-bucket-name/your-file.csv</code>), which you can use to
reference data across various AWS services like EC2 and SageMaker.</p>
<div id="benefits-of-using-s3-recommended-for-sagemaker-and-ml-workflows" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="benefits-of-using-s3-recommended-for-sagemaker-and-ml-workflows" class="callout-inner">
<h3 class="callout-title">Benefits of using S3 (recommended for
SageMaker and ML workflows)</h3>
<div class="callout-content">
<p>For flexibility, scalability, and cost efficiency, store data in S3
and load it into EC2 as needed. This setup allows:</p>
<ul>
<li>
<strong>Separation of storage and compute</strong>: The most
essential advantage. Data in S3 remains accessible even when EC2
instances are stopped or terminated, reducing costs and improving
workflow flexibility.</li>
<li>
<strong>Easy data sharing</strong>: Datasets in S3 are easier to
share with team members or across projects compared to EC2
storage.<br>
</li>
<li>
<strong>Integration with AWS services</strong>: SageMaker, Lambda,
and other AWS services can read directly from and write back to S3,
streamlining ML workflows.<br>
</li>
<li>
<strong>Scalability</strong>: S3 handles large datasets efficiently,
enabling storage beyond the limits of an EC2 instance’s disk
space.<br>
</li>
<li>
<strong>Cost efficiency</strong>: S3 storage is generally lower cost
than expanding EC2 disk volumes, and you only pay for the storage you
use.<br>
</li>
<li>
<strong>Data persistence</strong>: Unlike EC2 storage, which can be
lost if an instance is terminated, S3 ensures long-term data
availability.</li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="recommended-approach-s3-buckets">Recommended approach: S3 buckets<a class="anchor" aria-label="anchor" href="#recommended-approach-s3-buckets"></a>
</h2>
<hr class="half-width">
<p>In order to upload our titanic dataset to an S3 bucket on AWS, we’ll
follow the below summary procedure (details follow):</p>
<ol style="list-style-type: decimal">
<li>Log in to AWS Console and navigate to S3.</li>
<li>Create a new bucket or use an existing one.</li>
<li>Upload your dataset files.</li>
<li>Use the object URL to reference your data in future
experiments.</li>
</ol>
<div class="section level3">
<h3 id="detailed-procedure">Detailed procedure<a class="anchor" aria-label="anchor" href="#detailed-procedure"></a>
</h3>
<div class="section level5">
<h5 id="sign-in-to-the-aws-management-console">1. Sign in to the AWS Management Console<a class="anchor" aria-label="anchor" href="#sign-in-to-the-aws-management-console"></a>
</h5>
<ul>
<li>Log in to AWS Console using your credentials.</li>
</ul>
</div>
<div class="section level5">
<h5 id="navigate-to-s3">2. Navigate to S3<a class="anchor" aria-label="anchor" href="#navigate-to-s3"></a>
</h5>
<ul>
<li>Type “S3” in the search bar</li>
<li>Recommended: Select the star icon to save S3 as a bookmark in your
AWS toolbar</li>
<li>Select <strong>S3 - Scalable Storage in the Cloud</strong>
</li>
</ul>
</div>
<div class="section level5">
<h5 id="create-a-new-bucket">3. Create a new bucket<a class="anchor" aria-label="anchor" href="#create-a-new-bucket"></a>
</h5>
<ul>
<li>Click <strong>Create Bucket</strong> and enter a unique name, and
note that bucket name must not contain uppercase characters. To easily
find this bucket later in our shared AWS account, please use the
following naming convention: <code>teamname-yourname-dataname</code>
(e.g., sinkorswim-doejohn-titanic).</li>
<li>
<strong>Access Control (ACLs)</strong>: Disable ACLs (recommended).
<ul>
<li>
<strong>What are ACLs?</strong> Access Control Lists (ACLs) define
fine-grained permissions at the object level, allowing you to grant
specific users or AWS accounts access to individual files in your
bucket.<br>
</li>
<li>
<strong>Why disable them?</strong> AWS now recommends managing
access through bucket policies and IAM roles, which offer better
security and are easier to manage at scale. Unless you have a specific
need for ACLs, disabling them is the best practice.</li>
</ul>
</li>
<li>
<strong>Public Access</strong>: Turn on “Block all public access”
(recommended). This setting prevents unauthorized access and accidental
data exposure. If you need external access, use IAM policies or signed
URLs instead.</li>
<li>
<strong>Versioning</strong>: Disable unless you need multiple
versions of objects (unnecessary for ML Marathon). Enable only if
needed, as versioning increases storage costs. Useful when tracking
changes to datasets over time but unnecessary for static datasets.<br>
</li>
<li>
<strong>Tags</strong>: Adding tags to your S3 buckets is a great way
to track project-specific costs and usage over time, especially as data
and resources scale up. To easily track costs associated with your
bucket in our shared AWS account, add the following fields:
<ul>
<li>
<strong>Project</strong>: teamname (if participating in ML
Marathon)</li>
<li>
<strong>Name</strong>: yourname
<ul>
<li>
<strong>Purpose</strong>: Bucket-titanic</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/UW-Madison-DataScience/ml-with-aws-sagemaker/main/images/bucket_tags2.png" alt="Screenshot showing required tags for an S3 bucket" class="figure mx-auto d-block"><div class="figcaption">Example of Tags for an S3 Bucket</div>
</figure><ul>
<li>Click <strong>Create Bucket</strong> at the bottom once everything
above has been configured</li>
</ul>
</div>
<div class="section level5">
<h5 id="edit-bucket-policy">4. Edit bucket policy<a class="anchor" aria-label="anchor" href="#edit-bucket-policy"></a>
</h5>
<p>Once the bucket is created, you’ll be brought to a page that shows
all of your current buckets (and those on our shared account). We’ll
have to edit our bucket’s policy to allow ourselves proper access to any
files stored there (e.g., read from bucket, write to bucket). To set
these permissions…</p>
<ol style="list-style-type: decimal">
<li>Click on the name of your bucket to bring up additional options and
settings.</li>
<li>Click the Permissions tab</li>
<li>Scroll down to Bucket policy and click Edit. Paste the following
policy, <strong>editing the bucket name
“sinkorswim-doejohn-titanic”</strong> to reflect your bucket’s name</li>
</ol>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">JSON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode json" tabindex="0"><code class="sourceCode json"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>	<span class="dt">"Version"</span><span class="fu">:</span> <span class="st">"2012-10-17"</span><span class="fu">,</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>	<span class="dt">"Statement"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>		<span class="fu">{</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>			<span class="dt">"Effect"</span><span class="fu">:</span> <span class="st">"Allow"</span><span class="fu">,</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>			<span class="dt">"Principal"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>				<span class="dt">"AWS"</span><span class="fu">:</span> <span class="st">"arn:aws:iam::183295408236:role/ml-sagemaker-use"</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>			<span class="fu">},</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>			<span class="dt">"Action"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>				<span class="st">"s3:GetObject"</span><span class="ot">,</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>				<span class="st">"s3:PutObject"</span><span class="ot">,</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>				<span class="st">"s3:DeleteObject"</span><span class="ot">,</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>				<span class="st">"s3:ListMultipartUploadParts"</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>			<span class="ot">]</span><span class="fu">,</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>			<span class="dt">"Resource"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>				<span class="st">"arn:aws:s3:::sinkorswim-doejohn-titanic"</span><span class="ot">,</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>				<span class="st">"arn:aws:s3:::sinkorswim-doejohn-titanic/*"</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>			<span class="ot">]</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>		<span class="fu">}</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>	<span class="ot">]</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a><span class="fu">}</span></span></code></pre>
</div>
<p>For workshop attendees, this policy grants the
<code>ml-sagemaker-use</code> IAM role access to specific S3 bucket
actions, ensuring they can use the bucket for reading, writing,
deleting, and listing parts during multipart uploads. Attendees should
apply this policy to their buckets to enable SageMaker to operate on
stored data.</p>
<div id="general-guidance-for-setting-up-permissions-outside-of-this-workshop" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="general-guidance-for-setting-up-permissions-outside-of-this-workshop" class="callout-inner">
<h3 class="callout-title">General guidance for setting up permissions
outside of this workshop</h3>
<div class="callout-content">
<p>When setting up a bucket outside of this workshop, it’s essential to
create a similar IAM role (such as <code>ml-sagemaker-use</code>) with
policies that provide controlled access to S3 resources, ensuring only
the necessary actions are permitted for security and
cost-efficiency.</p>
<ol style="list-style-type: lower-alpha">
<li><p><strong>Create an IAM role</strong>: Set up an IAM role for
SageMaker to assume, with necessary S3 access permissions, such as
<code>s3:GetObject</code>, <code>s3:PutObject</code>,
<code>s3:DeleteObject</code>, and
<code>s3:ListMultipartUploadParts</code>, as shown in the policy
above.</p></li>
<li><p><strong>Attach permissions to S3 buckets</strong>: Attach bucket
policies that specify this role as the principal, as in our bucket
policy above</p></li>
<li><p><strong>More information</strong>: For a detailed guide on
setting up roles and policies for SageMaker, refer to the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html" class="external-link">AWS
SageMaker documentation on IAM roles and policies</a>. This resource
explains role creation, permission setups, and policy best practices
tailored for SageMaker’s operations with S3 and other AWS
services.</p></li>
</ol>
<p>This setup ensures that your SageMaker operations will have the
access needed without exposing the bucket to unnecessary permissions or
external accounts.</p>
</div>
</div>
</div>
</div>
<div class="section level5">
<h5 id="upload-files-to-the-bucket">5. Upload files to the bucket<a class="anchor" aria-label="anchor" href="#upload-files-to-the-bucket"></a>
</h5>
<ul>
<li>If you haven’t downloaded these files yet (part of workshop setup),
download the data for this workshop: <a href="https://raw.githubusercontent.com/UW-Madison-DataScience/ml-with-aws-sagemaker/main/data/data.zip" class="external-link">data.zip</a>
<ul>
<li>Extract the zip folder contents (Right-click -&gt; Extract all on
Windows; Double-click on mac)</li>
<li>Save the two data files (train and test) to a location where they
can easily be accessed. E.g., …
<ul>
<li><code>~/Downloads/data/titanic_train.csv</code></li>
<li><code>~/Downloads/data/titanic_test.csv</code></li>
</ul>
</li>
</ul>
</li>
<li>Navigate to the Objects tab of your bucket, then
<strong>Upload</strong>.</li>
<li>
<strong>Add Files</strong> (<code>titanic_train.csv</code>,
<code>titanic_test.csv</code>) and click <strong>Upload</strong> to
complete.</li>
</ul>
</div>
<div class="section level5">
<h5 id="take-note-of-s3-uri-for-your-data">6. Take note of S3 URI for your data<a class="anchor" aria-label="anchor" href="#take-note-of-s3-uri-for-your-data"></a>
</h5>
<ul>
<li>After uploading a file to S3, click on the file to locate its
<strong>Object URI</strong> (e.g.,
s3://doejohn-titanic-s3/titanic_train.csv). The Uniform Resource
Identifier (URI) is a unique address that specifies the location of the
file within S3. This URI is essential for referencing data in AWS
services like SageMaker, where it will be used to load data for
processing and model training.</li>
</ul>
</div>
</div>
</section><section><h2 class="section-heading" id="s3-bucket-costs">S3 bucket costs<a class="anchor" aria-label="anchor" href="#s3-bucket-costs"></a>
</h2>
<hr class="half-width">
<p>S3 bucket storage incurs costs based on data storage, data transfer,
and request counts.</p>
<div class="section level3">
<h3 id="storage-costs">Storage costs<a class="anchor" aria-label="anchor" href="#storage-costs"></a>
</h3>
<ul>
<li>Storage is charged per GB per month. Typical: Storing 10 GB costs
approximately $0.23/month in S3 Standard (us-east-1).</li>
<li>Pricing Tiers: S3 offers multiple storage classes (Standard,
Intelligent-Tiering, Glacier, etc.), with different costs based on
access frequency and retrieval times. Standard S3 fits most
purposes.</li>
</ul>
</div>
<div class="section level3">
<h3 id="data-transfer-costs">Data transfer costs<a class="anchor" aria-label="anchor" href="#data-transfer-costs"></a>
</h3>
<ul>
<li>
<strong>Uploading</strong> data to S3 is free.</li>
<li>
<strong>Downloading</strong> data (out of S3) incurs charges
(~$0.09/GB). Be sure to take note of this fee, as it can add up fast for
large datasets.</li>
<li>
<strong>In-region transfer</strong> (e.g., S3 to EC2) is free, while
cross-region data transfer is charged (~$0.02/GB).</li>
</ul>
</div>
<div class="section level3">
<h3 id="request-costs">Request costs<a class="anchor" aria-label="anchor" href="#request-costs"></a>
</h3>
<ul>
<li>GET requests are $0.0004 per 1,000 requests. In the context of
Amazon S3, “GET” requests refer to the action of retrieving or
downloading data from an S3 bucket. Each time a file or object is
accessed in S3, it incurs a small cost per request. This means that if
you have code that reads data from S3 frequently, such as loading
datasets repeatedly, each read operation counts as a GET request.</li>
</ul>
<p><strong><em>To calculate specific costs based on your needs, storage
class, and region, refer to AWS’s <a href="https://aws.amazon.com/s3/pricing/" class="external-link">S3 Pricing
Information</a>.</em></strong></p>
<div id="challenge-estimating-storage-costs" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="challenge-estimating-storage-costs" class="callout-inner">
<h3 class="callout-title">Challenge: Estimating Storage Costs</h3>
<div class="callout-content">
<p><strong>1. Estimate the total cost of storing 1 GB in S3 for one
month assuming:</strong></p>
<ul>
<li>Storage duration: 1 month</li>
<li>Storage region: us-east-1</li>
<li>Storage class: S3 Standard</li>
<li>Data will be retrieved 100 times for model training and tuning
(<code>GET</code> requests)</li>
<li>Data will be deleted after the project concludes, incurring data
retrieval and deletion costs</li>
</ul>
<p><strong>Hints</strong></p>
<ul>
<li>S3 storage cost: $0.023 per GB per month (us-east-1)</li>
<li>Data transfer cost (retrieval/deletion): $0.09 per GB (us-east-1 out
to internet)</li>
<li>
<code>GET</code> requests cost: $0.0004 per 1,000 requests (each
model training will incur one <code>GET</code> request)</li>
<li>Check the <a href="https://aws.amazon.com/s3/pricing/" class="external-link">AWS S3
Pricing</a> page for more details.</li>
</ul>
<p><strong>2. Repeat the above calculation using the following dataset
sizes: 10 GB, 100 GB, 1 TB (1024 GB)</strong></p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Using the S3 Standard rate in us-east-1:</p>
<ol style="list-style-type: decimal">
<li>
<strong>1 GB</strong>:
<ul>
<li>
<strong>Storage</strong>: 1 GB * $0.023 = $0.023</li>
<li>
<strong>Retrieval/Deletion</strong>: 1 GB * $0.09 = $0.09<br>
</li>
<li>
<strong>GET Requests</strong>: 100 requests * $0.0004 per 1,000 =
$0.00004<br>
</li>
<li>
<strong>Total Cost</strong>: <strong>$0.11304</strong>
</li>
</ul>
</li>
<li>
<strong>10 GB</strong>:
<ul>
<li>
<strong>Storage</strong>: 10 GB * $0.023 = $0.23</li>
<li>
<strong>Retrieval/Deletion</strong>: 10 GB * $0.09 = $0.90<br>
</li>
<li>
<strong>GET Requests</strong>: 100 requests * $0.0004 per 1,000 =
$0.00004<br>
</li>
<li>
<strong>Total Cost</strong>: <strong>$1.13004</strong>
</li>
</ul>
</li>
<li>
<strong>100 GB</strong>:
<ul>
<li>
<strong>Storage</strong>: 100 GB * $0.023 = $2.30</li>
<li>
<strong>Retrieval/Deletion</strong>: 100 GB * $0.09 = $9.00<br>
</li>
<li>
<strong>GET Requests</strong>: 100 requests * $0.0004 per 1,000 =
$0.00004<br>
</li>
<li>
<strong>Total Cost</strong>: <strong>$11.30004</strong>
</li>
</ul>
</li>
<li>
<strong>1 TB (1024 GB)</strong>:
<ul>
<li>
<strong>Storage</strong>: 1024 GB * $0.023 = $23.55</li>
<li>
<strong>Retrieval/Deletion</strong>: 1024 GB * $0.09 = $92.16<br>
</li>
<li>
<strong>GET Requests</strong>: 100 requests * $0.0004 per 1,000 =
$0.00004<br>
</li>
<li>
<strong>Total Cost</strong>: <strong>$115.71004</strong>
</li>
</ul>
</li>
</ol>
<p>These costs assume no additional request charges beyond those for
retrieval, storage, and <code>GET</code> requests for training.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="removing-unused-data-complete-after-the-workshop">Removing unused data (complete <em>after</em> the workshop)<a class="anchor" aria-label="anchor" href="#removing-unused-data-complete-after-the-workshop"></a>
</h2>
<hr class="half-width">
<p>After you are done using your data, it’s important to practice good
resource stewardship and remove the unneeded files/buckets.</p>
<p><strong>Option 1: Delete data only (if you plan to reuse bucket for
other datasets)</strong></p>
<ul>
<li>Go to S3, navigate to the bucket.</li>
<li>Select files to delete, then <strong>Actions &gt;
Delete</strong>.</li>
</ul>
<p><strong>Option 2: Delete the S3 bucket entirely (you no longer need
the bucket or data)</strong></p>
<ul>
<li>Select the bucket, click <strong>Actions &gt; Delete</strong>.</li>
<li>Type the bucket name to confirm deletion.</li>
</ul>
<p><strong><em>Please complete option 2 following this
workshop</em></strong>. Deleting the bucket stops all costs associated
with storage, requests, and data transfer.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use S3 for scalable, cost-effective, and flexible storage.</li>
<li>EC2 storage is fairly uncommon, but may be suitable for small,
temporary datasets.</li>
<li>Track your S3 storage costs, data transfer, and requests to manage
expenses.</li>
<li>Regularly delete unused data or buckets to avoid ongoing costs.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-SageMaker-notebooks-as-controllers"><p>Content from <a href="SageMaker-notebooks-as-controllers.html">Notebooks as Controllers</a></p>
<hr>
<p>Last updated on 2025-10-09 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/SageMaker-notebooks-as-controllers.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do you set up and use SageMaker notebooks for machine learning
tasks?</li>
<li>How can you manage compute resources efficiently using SageMaker’s
controller notebook approach?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Describe how to use SageMaker notebooks for ML workflows.</li>
<li>Set up a Jupyter notebook instance as a controller to manage compute
tasks.</li>
<li>Use SageMaker SDK to launch training and tuning jobs on scalable
instances.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="setting-up-our-notebook-environment">Setting up our notebook environment<a class="anchor" aria-label="anchor" href="#setting-up-our-notebook-environment"></a>
</h2>
<hr class="half-width">
<p>Amazon SageMaker provides a managed environment to simplify the
process of building, training, and deploying machine learning models. In
this episode, we’ll set up a <strong>SageMaker notebook
instance</strong>—a Jupyter notebook hosted on AWS for managing
SageMaker workflows.</p>
<div class="section level3">
<h3 id="using-the-notebook-as-a-controller">Using the notebook as a controller<a class="anchor" aria-label="anchor" href="#using-the-notebook-as-a-controller"></a>
</h3>
<p>In this setup, the notebook instance functions as a
<em>controller</em> to manage more resource-intensive compute tasks. By
selecting a minimal instance (e.g., <code>ml.t3.medium</code>), you can
perform lightweight operations while leveraging the <strong>SageMaker
Python SDK</strong> to launch scalable compute instances for model
training, batch processing, and hyperparameter tuning. This approach
minimizes costs while accessing the full power of SageMaker for
demanding tasks.</p>
<p>We’ll follow these steps to create our first “SageMaker notebook
instance”.</p>
<div class="section level4">
<h4 id="navigate-to-sagemaker">1. Navigate to SageMaker<a class="anchor" aria-label="anchor" href="#navigate-to-sagemaker"></a>
</h4>
<ul>
<li>In the AWS Console, search for <strong>SageMaker</strong>.</li>
<li>Recommended: Select the star icon next to <strong>Amazon SageMaker
AI</strong> to save SageMaker as a bookmark in your AWS toolbar</li>
<li>Select <strong>Amazon SageMaker AI</strong>
</li>
</ul>
</div>
<div class="section level4">
<h4 id="create-a-new-notebook-instance">2. Create a new notebook instance<a class="anchor" aria-label="anchor" href="#create-a-new-notebook-instance"></a>
</h4>
<ul>
<li>In the SageMaker left-side menu, click on
<strong>Notebooks</strong>, then click <strong>Create notebook
instance</strong>.</li>
<li>
<strong>Notebook name</strong>: To easily track this resource in our
shared account, please use the following naming convention:
“TeamName-LastnameFirstname-NotebookPurpose”. For example,
“sinkorswin-DoeJohn-TrainClassifier”. Can include hyphens, but not
spaces.</li>
<li>
<strong>Instance type</strong>: SageMaker notebooks run on AWS EC2
instances. The instance type determines the compute resources allocated
to the notebook. Since our notebook will act as a <strong>low-resource
“controller”</strong>, we’ll select a small instance such as
<code>ml.t3.medium</code> (4 GB RAM, $0.04/hour)
<ul>
<li>This keeps costs low while allowing us to launch separate
training/tuning jobs on more powerful instances when needed.<br>
</li>
<li>For guidance on common instances for ML procedures, refer to our
supplemental <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">Instances
for ML webpage</a>.<br>
</li>
</ul>
</li>
<li>
<strong>Platform identifier</strong>: This is an internal AWS
setting related to the environment version and underlying platform. You
can leave this as the default.</li>
<li>
<strong>Permissions and encryption</strong>:
<ul>
<li>
<strong>IAM role</strong>: For this workshop, we have pre-configured
the “ml-sagemmaker-use” role to enable access to AWS services like
SageMaker, with some restrictions to prevent overuse/misuse of
resources. Select the “ml-sagemmaker-use” role. Outside of the workshop,
you create/select a role that includes the
<code>AmazonSageMakerFullAccess</code> policy.</li>
<li>
<strong>Root access</strong>: Determines whether the user can run
administrative commands within the notebook instance. You should
<strong>Enable root access</strong> to allow installing additional
packages if/when needed.<br>
</li>
<li>
<strong>Encryption key (skip)</strong>: While we won’t use this
feature for the workshop, it is possible to specify a KMS key for
encrypting data at rest if needed.</li>
</ul>
</li>
<li>
<strong>Network (skip)</strong>: Networking settings are optional.
Configure them if you’re working within a specific VPC or need network
customization.</li>
<li>
<strong>Git repositories configuration (skip)</strong>: You don’t
need to complete this configuration. Instead, we’ll run a clone command
from our notebook later to get our repo setup. This approach is a common
strategy (allowing some flexiblity in which repo you use for the
notebook).</li>
<li>
<strong>Tags (NOT OPTIONAL)</strong>: Adding tags helps track and
organize resources for billing and management. This is particularly
useful when you need to break down expenses by project, task, or team.
To help track costs on our shared account, please use the tags found in
the below image.</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/UW-Madison-DataScience/ml-with-aws-sagemaker/main/images/notebook_tags.PNG" alt="Tag Setup Example" class="figure mx-auto d-block"><div class="figcaption">Tag Setup Example</div>
</figure><ul>
<li>Click <strong>Create notebook instance</strong>. It may take a few
minutes for the instance to start. Once its status is
<strong>InService</strong>, you can open the notebook instance and start
coding.</li>
</ul>
</div>
</div>
<div class="section level3">
<h3 id="load-pre-filled-jupyter-notebooks">Load pre-filled Jupyter notebooks<a class="anchor" aria-label="anchor" href="#load-pre-filled-jupyter-notebooks"></a>
</h3>
<p>Once your newly created <em>instance</em> shows as
<code>InService</code>, open the instance in Jupyter Lab. From there, we
can create as many Jupyter notebooks as we would like within the
instance environment.</p>
<p>We will then select the standard python3 environment (conda_python3)
to start our first .ipynb notebook (Jupyter notebook). We can use the
standard conda_python3 environment since we aren’t doing any
training/tuning just yet.</p>
<div class="section level5">
<h5 id="load-pre-filled-jupyter-notebooks-1">Load pre-filled Jupyter notebooks<a class="anchor" aria-label="anchor" href="#load-pre-filled-jupyter-notebooks-1"></a>
</h5>
<p>Within the Jupyter notebook, run the following command to clone the
lesson repo into our Jupyter environment:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">!git</span> clone https://github.com/carpentries-incubator/ML_with_AWS_SageMaker.git</span></code></pre>
</div>
<p>Then, navigate to
<code>/ML_with_AWS_SageMaker/notebooks/Accessing-S3-via-SageMaker-notebooks.ipynb</code>
to begin the first notebook.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use a minimal SageMaker notebook instance as a controller to manage
larger, resource-intensive tasks.</li>
<li>Launch training and tuning jobs on scalable instances using the
SageMaker SDK.</li>
<li>Tags can help track costs effectively, especially in multi-project
or team settings.</li>
<li>Use the SageMaker SDK documentation to explore additional options
for managing compute resources in AWS.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</section></section><section id="aio-Accessing-S3-via-SageMaker-notebooks"><p>Content from <a href="Accessing-S3-via-SageMaker-notebooks.html">Accessing and Managing Data in S3 with SageMaker Notebooks</a></p>
<hr>
<p>Last updated on 2025-10-09 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Accessing-S3-via-SageMaker-notebooks.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I load data from S3 into a SageMaker notebook?</li>
<li>How do I monitor storage usage and costs for my S3 bucket?</li>
<li>What steps are involved in pushing new data back to S3 from a
notebook?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Read data directly from an S3 bucket into memory in a SageMaker
notebook.</li>
<li>Check storage usage and estimate costs for data in an S3
bucket.</li>
<li>Upload new files from the SageMaker environment back to the S3
bucket.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level4">
<h4 id="set-up-aws-environment">Set up AWS environment<a class="anchor" aria-label="anchor" href="#set-up-aws-environment"></a>
</h4>
<p>To begin each notebook, it’s important to set up an AWS environment
that will allow seamless access to the necessary cloud resources. Here’s
what we’ll do to get started:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Define the Role</strong>: We’ll use
<code>get_execution_role()</code> to retrieve the IAM role associated
with the SageMaker instance. This role specifies the permissions needed
for interacting with AWS services like S3, which allows SageMaker to
securely read from and write to storage buckets.</p></li>
<li><p><strong>Initialize the SageMaker Session</strong>: Next, we’ll
create a <code>sagemaker.Session()</code> object, which will help manage
and track the resources and operations we use in SageMaker, such as
training jobs and model artifacts. The session acts as a bridge between
the SageMaker SDK commands in our notebook and AWS services.</p></li>
<li><p><strong>Set Up an S3 Client using boto3</strong>: Using
<code>boto3</code>, we’ll initialize an S3 client for accessing S3
buckets directly. Boto3 is the official AWS SDK for Python, allowing
developers to interact programmatically with AWS services like S3, EC2,
and Lambda.</p></li>
</ol>
<p>Starting with these initializations prepares our notebook environment
to efficiently interact with AWS resources for model development, data
management, and deployment.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># Initialize the SageMaker role, session, and s3 client</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>role <span class="op">=</span> sagemaker.get_execution_role() <span class="co"># specifies your permissions to use AWS tools</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session() </span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>s3 <span class="op">=</span> boto3.client(<span class="st">'s3'</span>)</span></code></pre>
</div>
<p>Preview variable details.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Print relevant details </span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Execution Role: </span><span class="sc">{</span>role<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Displays the IAM role being used</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>bucket_names <span class="op">=</span> [bucket[<span class="st">"Name"</span>] <span class="cf">for</span> bucket <span class="kw">in</span> s3.list_buckets()[<span class="st">"Buckets"</span>]]</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Available S3 Buckets: </span><span class="sc">{</span>bucket_names<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Shows the default S3 bucket assigned to SageMaker</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AWS Region: </span><span class="sc">{</span>session<span class="sc">.</span>boto_region_name<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Prints the region where the SageMaker session is running</span></span></code></pre>
</div>
</div>
<section><h2 class="section-heading" id="reading-data-from-s3">Reading data from S3<a class="anchor" aria-label="anchor" href="#reading-data-from-s3"></a>
</h2>
<hr class="half-width">
<p>You can either (A) read data from S3 into memory or (B) download a
copy of your S3 data into your notebook instance. Since we are using
SageMaker notebooks as controllers—rather than performing training or
tuning directly in the notebook—the best practice is to <strong>read
data directly from S3</strong> whenever possible. However, there are
cases where downloading a local copy may be useful. We’ll show you both
strategies.</p>
<div class="section level3">
<h3 id="a-reading-data-directly-from-s3-into-memory">A) Reading data directly from S3 into memory<a class="anchor" aria-label="anchor" href="#a-reading-data-directly-from-s3-into-memory"></a>
</h3>
<p>This is the recommended approach for most workflows. By keeping data
in S3 and reading it into memory when needed, we avoid local storage
constraints and ensure that our data remains accessible for SageMaker
training and tuning jobs.</p>
<p><strong>Pros</strong>:</p>
<ul>
<li>
<strong>Scalability</strong>: Data remains in S3, allowing multiple
training/tuning jobs to access it without duplication.</li>
<li>
<strong>Efficiency</strong>: No need to manage local copies or
manually clean up storage.</li>
<li>
<strong>Cost-effective</strong>: Avoids unnecessary instance storage
usage.</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>
<strong>Network dependency</strong>: Requires internet access to
S3.</li>
<li>
<strong>Potential latency</strong>: Reading large datasets
repeatedly from S3 may introduce small delays. This approach works best
if you only need to load data once or infrequently.</li>
</ul>
<div class="section level4">
<h4 id="example-reading-data-from-s3-into-memory">Example: Reading data from S3 into memory<a class="anchor" aria-label="anchor" href="#example-reading-data-from-s3-into-memory"></a>
</h4>
<p>Our data is stored on an S3 bucket called ‘teamname-name-dataname’
(e.g., sinkorswim-doejohn-titanic). We can use the following code to
read data directly from S3 into memory in the Jupyter notebook
environment, without actually downloading a copy of train.csv as a local
file.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co"># Define the S3 bucket and object key</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">'sinkorswim-doejohn-titanic'</span>  <span class="co"># replace with your S3 bucket name</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># Read the train data from S3</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>key <span class="op">=</span> <span class="st">'titanic_train.csv'</span>  <span class="co"># replace with your object key</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>response <span class="op">=</span> s3.get_object(Bucket<span class="op">=</span>bucket_name, Key<span class="op">=</span>key)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>train_data <span class="op">=</span> pd.read_csv(response[<span class="st">'Body'</span>])</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co"># Read the test data from S3</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>key <span class="op">=</span> <span class="st">'titanic_test.csv'</span>  <span class="co"># replace with your object key</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>response <span class="op">=</span> s3.get_object(Bucket<span class="op">=</span>bucket_name, Key<span class="op">=</span>key)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>test_data <span class="op">=</span> pd.read_csv(response[<span class="st">'Body'</span>])</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co"># check shape</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="bu">print</span>(train_data.shape)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="bu">print</span>(test_data.shape)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co"># Inspect the first few rows of the DataFrame</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>train_data.head()</span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="b-download-copy-into-notebook-environment">B) Download copy into notebook environment<a class="anchor" aria-label="anchor" href="#b-download-copy-into-notebook-environment"></a>
</h3>
<p>In some cases, downloading a local copy of the dataset may be useful,
such as when performing repeated reads in an interactive notebook
session.</p>
<p><strong>Pros</strong>:</p>
<ul>
<li>
<strong>Faster access for repeated operations</strong>: Avoids
repeated S3 requests.</li>
<li>
<strong>Works offline</strong>: Useful if running in an environment
with limited network access.</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>
<strong>Consumes instance storage</strong>: Notebook instances have
limited space.</li>
<li>
<strong>Requires manual cleanup</strong>: Downloaded files remain
until deleted.</li>
</ul>
<div class="section level4">
<h4 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h4>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="op">!</span>pwd</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Define the S3 bucket and file location</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>key <span class="op">=</span> <span class="st">"titanic_train.csv"</span>  <span class="co"># Path to your file in the S3 bucket</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>local_file_path <span class="op">=</span> <span class="st">"/home/ec2-user/SageMaker/titanic_train.csv"</span>  <span class="co"># Local path to save the file</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co"># Initialize the S3 client and download the file</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>s3.download_file(bucket_name, key, local_file_path)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="op">!</span>ls</span></code></pre>
</div>
<p><strong>Note</strong>: You may need to hit refresh on the file
explorer panel to the left to see this file. If you get any permission
issues…</p>
<ul>
<li>check that you have selected the appropriate policy for this
notebook</li>
<li>check that your bucket has the appropriate policy permissions</li>
</ul>
</div>
<div class="section level4">
<h4 id="check-the-current-size-and-storage-costs-of-bucket">Check the current size and storage costs of bucket<a class="anchor" aria-label="anchor" href="#check-the-current-size-and-storage-costs-of-bucket"></a>
</h4>
<p>It’s a good idea to periodically check how much storage you have used
in your bucket. You can do this from a Jupyter notebook in SageMaker by
using the <strong>Boto3</strong> library, which is the AWS SDK for
Python. This will allow you to calculate the total size of objects
within a specified bucket.</p>
<p>The code below will calculate your bucket size for you. Here is a
breakdown of the important pieces in the next code section:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Paginator</strong>: Since S3 buckets can contain many
objects, we use a paginator to handle large listings.</li>
<li>
<strong>Size calculation</strong>: We sum the <code>Size</code>
attribute of each object in the bucket.</li>
<li>
<strong>Unit conversion</strong>: The size is given in bytes, so
dividing by <code>1024 ** 2</code> converts it to megabytes (MB).</li>
</ol>
<blockquote>
<p><strong>Note</strong>: If your bucket has very large objects or you
want to check specific folders within a bucket, you may want to refine
this code to only fetch certain objects or folders.</p>
</blockquote>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Initialize the total size counter (bytes)</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>total_size_bytes <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># Use a paginator to handle large bucket listings</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># This ensures that even if the bucket contains many objects, we can retrieve all of them</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>paginator <span class="op">=</span> s3.get_paginator(<span class="st">"list_objects_v2"</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co"># Iterate through all pages of object listings</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="cf">for</span> page <span class="kw">in</span> paginator.paginate(Bucket<span class="op">=</span>bucket_name):</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    <span class="co"># 'Contents' contains the list of objects in the current page, if available</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    <span class="cf">for</span> obj <span class="kw">in</span> page.get(<span class="st">"Contents"</span>, []):  </span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>        total_size_bytes <span class="op">+=</span> obj[<span class="st">"Size"</span>]  <span class="co"># Add each object's size to the total</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co"># Convert the total size to gigabytes for cost estimation</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>total_size_gb <span class="op">=</span> total_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">3</span>)</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="co"># Convert the total size to megabytes for easier readability</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>total_size_mb <span class="op">=</span> total_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a><span class="co"># Print the total size in MB</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total size of bucket '</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>total_size_mb<span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a><span class="co"># Print the total size in GB</span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a><span class="co">#print(f"Total size of bucket '{bucket_name}': {total_size_gb:.2f} GB")</span></span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="using-helper-functions-from-github">Using helper functions from GitHub<a class="anchor" aria-label="anchor" href="#using-helper-functions-from-github"></a>
</h3>
<p>We have added code to calculate bucket size to a helper function
called <code>get_s3_bucket_size(bucket_name)</code> for your
convenience. There are also some other helper functions in the
AWS_helpers repo to assist you with common AWS/SageMaker workflows.
We’ll show you how to clone this code into your notebook
environment.</p>
<div class="section level4">
<h4 id="directory-setup">Directory setup<a class="anchor" aria-label="anchor" href="#directory-setup"></a>
</h4>
<p>Let’s make sure we’re starting in the root directory of this
instance, so that we all have our AWS_helpers.py file located in the
same path (/test_AWS/scripts/AWS_helpers.py)</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span></span></code></pre>
</div>
<p>To clone the repo to our Jupyter notebook, use the following
code.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>UW<span class="op">-</span>Madison<span class="op">-</span>DataScience<span class="op">/</span>AWS_helpers.git <span class="co"># downloads AWS_helpers folder/repo (refresh file explorer to see)</span></span></code></pre>
</div>
<p>Our AWS_helpers.py file can be found in
<code>AWS_helpers/helpers.py</code>. With this file downloaded, you can
call this function via…</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> AWS_helpers.helpers <span class="im">as</span> helpers</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>helpers.get_s3_bucket_size(bucket_name)</span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="check-storage-costs-of-bucket">Check storage costs of bucket<a class="anchor" aria-label="anchor" href="#check-storage-costs-of-bucket"></a>
</h3>
<p>To estimate the storage cost of your Amazon S3 bucket directly from a
Jupyter notebook in SageMaker, you can use the following approach. This
method calculates the total size of the bucket and estimates the monthly
storage cost based on AWS S3 pricing.</p>
<p><strong>Note</strong>: AWS S3 pricing varies by region and storage
class. The example below uses the S3 Standard storage class pricing for
the US East (N. Virginia) region as of November 1, 2024. Please verify
the current pricing for your specific region and storage class on the <a href="https://aws.amazon.com/s3/pricing/" class="external-link">AWS S3 Pricing page</a>.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># AWS S3 Standard Storage pricing for US East (N. Virginia) region</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># Pricing tiers as of November 1, 2024</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>first_50_tb_price_per_gb <span class="op">=</span> <span class="fl">0.023</span>  <span class="co"># per GB for the first 50 TB</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>next_450_tb_price_per_gb <span class="op">=</span> <span class="fl">0.022</span>  <span class="co"># per GB for the next 450 TB</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>over_500_tb_price_per_gb <span class="op">=</span> <span class="fl">0.021</span>  <span class="co"># per GB for storage over 500 TB</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co"># Calculate the cost based on the size</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="cf">if</span> total_size_gb <span class="op">&lt;=</span> <span class="dv">50</span> <span class="op">*</span> <span class="dv">1024</span>:</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    <span class="co"># Total size is within the first 50 TB</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    cost <span class="op">=</span> total_size_gb <span class="op">*</span> first_50_tb_price_per_gb</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="cf">elif</span> total_size_gb <span class="op">&lt;=</span> <span class="dv">500</span> <span class="op">*</span> <span class="dv">1024</span>:</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    <span class="co"># Total size is within the next 450 TB</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    cost <span class="op">=</span> (<span class="dv">50</span> <span class="op">*</span> <span class="dv">1024</span> <span class="op">*</span> first_50_tb_price_per_gb) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>           ((total_size_gb <span class="op">-</span> <span class="dv">50</span> <span class="op">*</span> <span class="dv">1024</span>) <span class="op">*</span> next_450_tb_price_per_gb)</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    <span class="co"># Total size is over 500 TB</span></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    cost <span class="op">=</span> (<span class="dv">50</span> <span class="op">*</span> <span class="dv">1024</span> <span class="op">*</span> first_50_tb_price_per_gb) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>           (<span class="dv">450</span> <span class="op">*</span> <span class="dv">1024</span> <span class="op">*</span> next_450_tb_price_per_gb) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>           ((total_size_gb <span class="op">-</span> <span class="dv">500</span> <span class="op">*</span> <span class="dv">1024</span>) <span class="op">*</span> over_500_tb_price_per_gb)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated monthly storage cost: $</span><span class="sc">{</span>cost<span class="sc">:.5f}</span><span class="ss">"</span>)</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated annual storage cost: $</span><span class="sc">{</span>cost<span class="op">*</span><span class="dv">12</span><span class="sc">:.5f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>For your convenience, we have also added this code to a helper
function.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>monthly_cost, storage_size_gb <span class="op">=</span> helpers.calculate_s3_storage_cost(bucket_name)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated monthly cost (</span><span class="sc">{</span>storage_size_gb<span class="sc">:.4f}</span><span class="ss"> GB): $</span><span class="sc">{</span>monthly_cost<span class="sc">:.5f}</span><span class="ss">"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated annual cost (</span><span class="sc">{</span>storage_size_gb<span class="sc">:.4f}</span><span class="ss"> GB): $</span><span class="sc">{</span>monthly_cost<span class="op">*</span><span class="dv">12</span><span class="sc">:.5f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p><strong>Important Considerations</strong>:</p>
<ul>
<li>
<strong>Pricing Tiers</strong>: AWS S3 pricing is tiered. The first
50 TB per month is priced at <code>$0.023 per GB</code>, the next 450 TB
at <code>$0.022 per GB</code>, and storage over 500 TB at
<code>$0.021 per GB</code>. Ensure you apply the correct pricing tier
based on your total storage size.</li>
<li>
<strong>Region and Storage Class</strong>: Pricing varies by AWS
region and storage class. The example above uses the S3 Standard storage
class pricing for the US East (N. Virginia) region. Adjust the pricing
variables if your bucket is in a different region or uses a different
storage class.</li>
<li>
<strong>Additional Costs</strong>: This estimation covers storage
costs only. AWS S3 may have additional charges for requests, data
retrievals, and data transfers. For a comprehensive cost analysis,
consider these factors as well.</li>
</ul>
<p>For detailed and up-to-date information on AWS S3 pricing, please
refer to the <a href="https://aws.amazon.com/s3/pricing/" class="external-link">AWS S3 Pricing
page</a>.</p>
</div>
</section><section><h2 class="section-heading" id="writing-output-files-to-s3">Writing output files to S3<a class="anchor" aria-label="anchor" href="#writing-output-files-to-s3"></a>
</h2>
<hr class="half-width">
<p>As your analysis generates new files or demands additional
documentation, you can upload files to your bucket as demonstrated
below. For this demo, you can create a blank <code>Notes.txt</code> file
to upload to your bucket. To do so, go to <strong>File</strong> -&gt;
<strong>New</strong> -&gt; <strong>Text file</strong>, and save it out
as <code>Notes.txt</code>.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Define the S3 bucket name and the file paths</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>notes_file_path <span class="op">=</span> <span class="st">"Notes.txt"</span> <span class="co"># assuming your file is in root directory of jupyter notebook (check file explorer tab)</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co"># Upload the training file to a new folder called "docs". You can also just place it in the bucket's root directory if you prefer (remove docs/ in code below).</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>s3.upload_file(notes_file_path, bucket_name, <span class="st">"docs/Notes.txt"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Files uploaded successfully."</span>)</span></code></pre>
</div>
<p>After uploading, we can view the objects/files available on our
bucket using…</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># List and print all objects in the bucket</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>response <span class="op">=</span> s3.list_objects_v2(Bucket<span class="op">=</span>bucket_name)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co"># Check if there are objects in the bucket</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="cf">if</span> <span class="st">'Contents'</span> <span class="kw">in</span> response:</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>    <span class="cf">for</span> obj <span class="kw">in</span> response[<span class="st">'Contents'</span>]:</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>        <span class="bu">print</span>(obj[<span class="st">'Key'</span>])  <span class="co"># Print the object's key (its path in the bucket)</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"The bucket is empty or does not exist."</span>)</span></code></pre>
</div>
<p>Alternatively, we can substitute this for a helper function call as
well.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>file_list <span class="op">=</span> helpers.list_S3_objects(bucket_name)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>file_list</span></code></pre>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Load data from S3 into memory for efficient storage and
processing.</li>
<li>Periodically check storage usage and costs to manage S3
budgets.</li>
<li>Use SageMaker to upload analysis results and maintain an organized
workflow.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-Interacting-with-code-repo"><p>Content from <a href="Interacting-with-code-repo.html">Using a GitHub Personal Access Token (PAT) to Push/Pull from a SageMaker Notebook</a></p>
<hr>
<p>Last updated on 2025-11-24 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Interacting-with-code-repo.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I securely push/pull code to and from GitHub within a
SageMaker notebook?</li>
<li>What steps are necessary to set up a GitHub PAT for authentication
in SageMaker?</li>
<li>How can I convert notebooks to <code>.py</code> files and ignore
<code>.ipynb</code> files in version control?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Configure Git in a SageMaker notebook to use a GitHub Personal
Access Token (PAT) for HTTPS-based authentication.</li>
<li>Securely handle credentials in a notebook environment using
<code>getpass</code>.</li>
<li>Convert <code>.ipynb</code> files to <code>.py</code> files for
better version control practices in collaborative projects.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="open-prefilled--ipynb-notebook">Open prefilled .ipynb notebook<a class="anchor" aria-label="anchor" href="#open-prefilled--ipynb-notebook"></a>
</h2>
<hr class="half-width">
<p>Open the notebook from:
<code>/ML_with_AWS_SageMaker/notebooks/Interacting-with-code-repo.ipynb</code>.</p>
</section><section><h2 class="section-heading" id="step-0-initial-setup">Step 0: Initial setup<a class="anchor" aria-label="anchor" href="#step-0-initial-setup"></a>
</h2>
<hr class="half-width">
<p>In this episode, we’ll demonstrate how to push code to GitHub from a
SageMaker Jupyter Notebook.</p>
<p>To begin, we will first create a GitHub repo that we have read/write
access to. Feel free to supplement the instructions below with your own
personal GitHub repo if you have one ou want to use with SageMaker
already. Else, we can simply create a fork of AWS_helpers repo. You may
have completed this step already if you completed all workshop setup
steps.</p>
<ol style="list-style-type: decimal">
<li>Navigate to <a href="https://github.com/UW-Madison-DataScience/AWS_helpers" class="external-link">https://github.com/UW-Madison-DataScience/AWS_helpers</a>
</li>
<li>Click the fork button</li>
<li>Select yourself as the owner of the fork, and “Copy the main branch
only” selected. You will only need the main branch.</li>
</ol>
<p>Next, let’s make sure we’re starting at the same directory. Back in
our SageMaker Jupyter Lab notebook, change directory to the root
directory of this instance before going further.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span></span></code></pre>
</div>
<p>Then, clone the fork. Replace “USERNAME” below with your GitHub
username.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>USERNAME<span class="op">/</span>AWS_helpers.git <span class="co"># replace username with your GitHub username</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-1-using-a-github-personal-access-token-pat-to-pushpull-from-a-sagemaker-notebook">Step 1: Using a GitHub personal access token (PAT) to push/pull from
a SageMaker notebook<a class="anchor" aria-label="anchor" href="#step-1-using-a-github-personal-access-token-pat-to-pushpull-from-a-sagemaker-notebook"></a>
</h2>
<hr class="half-width">
<p>When working in SageMaker notebooks, you may often need to push code
updates to GitHub repositories. However, SageMaker notebooks are
typically launched with temporary instances that don’t persist
configurations, including SSH keys, across sessions. This makes
HTTPS-based authentication, secured with a GitHub Personal Access Token
(PAT), a practical solution. PATs provide flexibility for authentication
and enable seamless interaction with both public and private
repositories directly from your notebook.</p>
<blockquote>
<p><strong>Important Note</strong>: Personal access tokens are powerful
credentials that grant specific permissions to your GitHub account. To
ensure security, only select the minimum necessary permissions and
handle the token carefully.</p>
</blockquote>
<div class="section level4">
<h4 id="generate-a-personal-access-token-pat-on-github">Generate a personal access token (PAT) on GitHub<a class="anchor" aria-label="anchor" href="#generate-a-personal-access-token-pat-on-github"></a>
</h4>
<ol style="list-style-type: decimal">
<li>Go to <strong>Settings</strong> by clicking on your profile picture
in the upper-right corner of GitHub.</li>
<li>Click <strong>Developer settings</strong> at the very bottom of the
left sidebar.</li>
<li>Select <strong>Personal access tokens</strong>, then click
<strong>Tokens (classic)</strong>.</li>
<li>Click <strong>Generate new token (classic)</strong>.</li>
<li>Give your token a descriptive name (e.g., “SageMaker Access Token”)
and set an expiration date if desired for added security.</li>
<li>
<strong>Select the minimum permissions needed</strong>:
<ul>
<li>
<strong>For public repositories</strong>: Choose only
<strong><code>public_repo</code></strong>.</li>
<li>
<strong>For private repositories</strong>: Choose
<strong><code>repo</code></strong> (full control of private
repositories).</li>
<li>Optional permissions, if needed:
<ul>
<li>
<strong><code>repo:status</code></strong>: Access commit status (if
checking status checks).</li>
<li>
<strong><code>workflow</code></strong>: Update GitHub Actions
workflows (only if working with GitHub Actions).</li>
</ul>
</li>
</ul>
</li>
<li>Click <strong>Generate token</strong> and <strong>copy it
immediately</strong>—you won’t be able to see it again once you leave
the page.</li>
</ol>
<blockquote>
<p><strong>Caution</strong>: Treat your PAT like a password. Avoid
sharing it or exposing it in your code. Store it securely (e.g., via a
password manager like LastPass) and consider rotating it regularly.</p>
</blockquote>
</div>
<div class="section level4">
<h4 id="use-getpass-to-prompt-for-username-and-pat">Use <code>getpass</code> to prompt for username and PAT<a class="anchor" aria-label="anchor" href="#use-getpass-to-prompt-for-username-and-pat"></a>
</h4>
<p>The <code>getpass</code> library allows you to input your GitHub
username and PAT without exposing them in the notebook. This approach
ensures you’re not hardcoding sensitive information.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> getpass</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># Prompt for GitHub username and PAT securely</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>username <span class="op">=</span> <span class="bu">input</span>(<span class="st">"GitHub Username: "</span>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>token <span class="op">=</span> getpass.getpass(<span class="st">"GitHub Personal Access Token (PAT): "</span>)</span></code></pre>
</div>
<p><strong>Note</strong>: After running, you may want to comment out the
above code so that you don’t have to enter in your login every time you
run your whole notebook</p>
</div>
</section><section><h2 class="section-heading" id="step-2-configure-git-settings">Step 2: Configure Git settings<a class="anchor" aria-label="anchor" href="#step-2-configure-git-settings"></a>
</h2>
<hr class="half-width">
<p>In your SageMaker or Jupyter notebook environment, run the following
commands to set up your Git user information.</p>
<p>Setting this globally (<code>--global</code>) will ensure the
configuration persists across all repositories in the environment. If
you’re working in a temporary environment, you may need to re-run this
configuration after a restart.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="op">!</span>git config <span class="op">--</span><span class="kw">global</span> user.name <span class="st">"Your name"</span> <span class="co"># This is your GitHub username (or just your name), which will appear in the commit history as the author of the changes.</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="op">!</span>git config <span class="op">--</span><span class="kw">global</span> user.email your_email<span class="op">@</span>wisc.edu <span class="co"># This should match the email associated with your GitHub account so that commits are properly linked to your profile.</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-3-convert-json--ipynb-files-to--py">Step 3: Convert json .ipynb files to .py<a class="anchor" aria-label="anchor" href="#step-3-convert-json--ipynb-files-to--py"></a>
</h2>
<hr class="half-width">
<p>We’d like to track our notebook files within our repo fork. However,
to avoid tracking ipynb files directly, which are formatted as json, we
may want to convert our notebook to .py first (plain text). Converting
notebooks to <code>.py</code> files helps maintain code (and
version-control) readability and minimizes potential issues with
notebook-specific metadata in Git history.</p>
<div class="section level4">
<h4 id="benefits-of-converting-to--py-before-committing">Benefits of converting to <code>.py</code> before Committing<a class="anchor" aria-label="anchor" href="#benefits-of-converting-to--py-before-committing"></a>
</h4>
<ul>
<li>
<strong>Cleaner version control</strong>: <code>.py</code> files
have cleaner diffs and are easier to review and merge in Git.</li>
<li>
<strong>Script compatibility</strong>: Python files are more
compatible with other environments and can run easily from the command
line.</li>
<li>
<strong>Reduced repository size</strong>: <code>.py</code> files are
generally lighter than <code>.ipynb</code> files since they don’t store
outputs or metadata.</li>
</ul>
<p>Here’s how to convert <code>.ipynb</code> files to <code>.py</code>
in SageMaker without needing to export or download files.</p>
<ol style="list-style-type: decimal">
<li>First, install Jupytext.</li>
</ol>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="op">!</span>pip install jupytext</span></code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Then, run the following command in a notebook cell to convert both
of our notebooks to <code>.py</code> files</li>
</ol>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Adjust filename(s) if you used something different</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="op">!</span>jupytext <span class="op">--</span>to py Interacting<span class="op">-</span><span class="cf">with</span><span class="op">-</span>S3.ipynb</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">[jupytext]</span> Reading Interacting-with-S3.ipynb in format ipynb</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="ex">[jupytext]</span> Writing Interacting-with-S3.py</span></code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>If you have multiple notebooks to convert, you can automate the
conversion process by running this code, which converts all
<code>.ipynb</code> files in the current directory to <code>.py</code>
files:</li>
</ol>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co"># List all .ipynb files in the directory</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>notebooks <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> os.listdir() <span class="cf">if</span> f.endswith(<span class="st">'.ipynb'</span>)]</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co"># Convert each notebook to .py using jupytext</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="cf">for</span> notebook <span class="kw">in</span> notebooks:</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>    output_file <span class="op">=</span> notebook.replace(<span class="st">'.ipynb'</span>, <span class="st">'.py'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    subprocess.run([<span class="st">"jupytext"</span>, <span class="st">"--to"</span>, <span class="st">"py"</span>, notebook, <span class="st">"--output"</span>, output_file])</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Converted </span><span class="sc">{</span>notebook<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>output_file<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>For convenience, we have placed this code inside a
<code>convert_files()</code> function in <code>helpers.py</code>.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> AWS_helpers.helpers <span class="im">as</span> helpers</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>helpers.convert_files(direction<span class="op">=</span><span class="st">"notebook_to_python"</span>)</span></code></pre>
</div>
<p><strong>Once converted, move our new .py file to the AWS_helpers
folder using the file explorer panel in Jupyter Lab.</strong></p>
</div>
</section><section><h2 class="section-heading" id="step-4--add-and-commit--py-files">Step 4. Add and commit .py files<a class="anchor" aria-label="anchor" href="#step-4--add-and-commit--py-files"></a>
</h2>
<hr class="half-width">
<ol style="list-style-type: decimal">
<li>Check status of repo. Make sure you’re in the repo folder before
running the next step.</li>
</ol>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span>AWS_helpers</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="op">!</span>git status</span></code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Add and commit changes</li>
</ol>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="op">!</span>git add . <span class="co"># you may also add files one at a time, for further specificity over the associated commit message</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="op">!</span>git commit <span class="op">-</span>m <span class="st">"Updates from Jupyter notebooks"</span> <span class="co"># in general, your commit message should be more specific!</span></span></code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Check status</li>
</ol>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="op">!</span>git status</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-5--adding--ipynb-to-gitigore">Step 5. Adding .ipynb to gitigore<a class="anchor" aria-label="anchor" href="#step-5--adding--ipynb-to-gitigore"></a>
</h2>
<hr class="half-width">
<p>Adding <code>.ipynb</code> files to <code>.gitignore</code> is a good
practice if you plan to only commit <code>.py</code> scripts. This will
prevent accidental commits of Jupyter Notebook files across all
subfolders in the repository.</p>
<p>Here’s how to add <code>.ipynb</code> files to
<code>.gitignore</code> to ignore them project-wide:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Check working directory</strong>: First make sure we’re in
the repo folder</li>
</ol>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="op">!</span>pwd</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co">#%cd AWS_helpers</span></span></code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Create the <code>.gitignore</code> file</strong>: This file
will be hidden in Jupyter (since it starts with “.”), but you can verify
it exists using <code>ls</code>.</li>
</ol>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="op">!</span>touch .gitignore</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="op">!</span>ls <span class="op">-</span>a</span></code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>
<strong>Add <code>.ipynb</code> files to
<code>.gitignore</code></strong>: You can add this line using a command
within your notebook:</li>
</ol>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">".gitignore"</span>, <span class="st">"a"</span>) <span class="im">as</span> gitignore:</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>	gitignore.write(<span class="st">"</span><span class="ch">\n</span><span class="st"># Ignore all Jupyter Notebook files</span><span class="ch">\n</span><span class="st">*.ipynb</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre>
</div>
<p>View file contents</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="op">!</span>cat .gitignore</span></code></pre>
</div>
<ol start="4" style="list-style-type: decimal">
<li>
<strong>Ignore other common temp files</strong> While we’re at it,
let’s ignore other common files that can clutter repos, such as cache
folders and temporary files.</li>
</ol>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">".gitignore"</span>, <span class="st">"a"</span>) <span class="im">as</span> gitignore:</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>	gitignore.write(<span class="st">"</span><span class="ch">\n</span><span class="st"># Ignore cache and temp files</span><span class="ch">\n</span><span class="st">__pycache__/</span><span class="ch">\n</span><span class="st">*.tmp</span><span class="ch">\n</span><span class="st">*.log</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre>
</div>
<p>View file contents</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="op">!</span>cat .gitignore</span></code></pre>
</div>
<ol start="5" style="list-style-type: decimal">
<li>
<strong>Add and commit the <code>.gitignore</code>
file</strong>:</li>
</ol>
<p>Add and commit the updated <code>.gitignore</code> file to ensure
it’s applied across the repository.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="op">!</span>git add .gitignore</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="op">!</span>git commit <span class="op">-</span>m <span class="st">"Add .ipynb files to .gitignore to ignore notebooks"</span></span></code></pre>
</div>
<p>This setup will:</p>
<ul>
<li>Prevent all <code>.ipynb</code> files from being tracked by
Git.</li>
<li>Keep your repository cleaner, containing only <code>.py</code>
scripts for easier version control and reduced repository size.</li>
</ul></section><section><h2 class="section-heading" id="step-6--merging-local-changes-with-remotegithub">Step 6. Merging local changes with remote/GitHub<a class="anchor" aria-label="anchor" href="#step-6--merging-local-changes-with-remotegithub"></a>
</h2>
<hr class="half-width">
<p>Our local changes have now been committed, and we can begin the
process of mergining with the remote main branch. Before we try to push
our changes, it’s good practice to first to a pull. This is critical
when working on a collaborate repo with multiple users, so that you
don’t miss any updates from other team members.</p>
<div class="section level3">
<h3 id="pull-the-latest-changes-from-the-main-branch">1. Pull the latest changes from the main branch<a class="anchor" aria-label="anchor" href="#pull-the-latest-changes-from-the-main-branch"></a>
</h3>
<p>There are a few different options for pulling the remote code into
your local version. The best pull strategy depends on your workflow and
the history structure you want to maintain. Here’s a breakdown to help
you decide:</p>
<ul>
<li>Merge (pull.rebase false): Combines the remote changes into your
local branch as a merge commit.
<ul>
<li>
<strong>Use if</strong>: You’re okay with having merge commits in
your history, which indicate where you pulled in remote changes. This is
the default and is usually the easiest for team collaborations,
especially if conflicts arise.</li>
</ul>
</li>
<li>Rebase (pull.rebase true): Replays your local changes on top of the
updated main branch, resulting in a linear history.
<ul>
<li>
<strong>Use if</strong>: You prefer a clean, linear history without
merge commits. Rebase is useful if you like to keep your branch history
as if all changes happened sequentially.</li>
</ul>
</li>
<li>Fast-forward only (pull.ff only): Only pulls if the local branch can
fast-forward to the remote without diverging (no new commits locally).
<ul>
<li>
<strong>Use if</strong>: You only want to pull updates if no
additional commits have been made locally. This can be helpful to avoid
unintended merges when your branch hasn’t diverged.</li>
</ul>
</li>
</ul>
<div class="section level4">
<h4 id="recommended-for-most-users">Recommended for Most Users<a class="anchor" aria-label="anchor" href="#recommended-for-most-users"></a>
</h4>
<p>If you’re collaborating and want simplicity, <strong>merge
(pull.rebase false)</strong> is often the most practical option. This
will ensure you get remote changes with a merge commit that captures the
history of integration points. For those who prefer a more streamlined
history and are comfortable with Git, <strong>rebase (pull.rebase
true)</strong> can be ideal but may require more careful conflict
handling.</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="op">!</span>git config pull.rebase false <span class="co"># Combines the remote changes into your local branch as a merge commit.</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a><span class="op">!</span>git pull origin main</span></code></pre>
</div>
<p>If you get merge conflicts, be sure to resolve those before moving
forward (e.g., use git checkout -&gt; add -&gt; commit). You can skip
the below code if you don’t have any conflicts.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co"># Keep your local changes in one conflicting file</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="co"># !git checkout --ours Interacting-with-git.py</span></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="co"># Keep remote version for the other conflicting file</span></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="co"># !git checkout --theirs Interacting-with-git.py</span></span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="co"># # Stage the files to mark the conflicts as resolved</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="co"># !git add Interacting-with-git.py</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a><span class="co"># # Commit the merge result</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a><span class="co"># !git commit -m "Resolved merge conflicts by keeping local changes"</span></span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="push-changes-using-pat-creditials">2. Push changes using PAT creditials<a class="anchor" aria-label="anchor" href="#push-changes-using-pat-creditials"></a>
</h3>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># Push with embedded credentials from getpass (avoids interactive prompt)</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>github_url <span class="op">=</span> <span class="ss">f'github.com/</span><span class="sc">{</span>username<span class="sc">}</span><span class="ss">/AWS_helpers.git'</span> <span class="co"># The full address for your fork can be found under Code -&gt; Clone -&gt; HTTPS (remote the https:// before the rest of the address)</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="op">!</span>git push https:<span class="op">//</span>{username}:{token}<span class="op">@</span>{github_url} main</span></code></pre>
</div>
<p>After pushing, you can navigate back to your fork on GitHub to verify
everything worked (e.g., <a href="https://github.com/username/AWS_helpers/tree/main" class="external-link uri">https://github.com/username/AWS_helpers/tree/main</a>)</p>
</div>
</section><section><h2 class="section-heading" id="step-7-pulling--py-files-and-converting-back-to-notebook-format">Step 7: Pulling .py files and converting back to notebook
format<a class="anchor" aria-label="anchor" href="#step-7-pulling--py-files-and-converting-back-to-notebook-format"></a>
</h2>
<hr class="half-width">
<p>Let’s assume you’ve taken a short break from your work, and others on
your team have made updates to your .py files on the remote main branch.
If you’d like to work with notebook files again, you can again use
jupytext to convert your <code>.py</code> files back to
<code>.ipynb</code>.</p>
<ol style="list-style-type: decimal">
<li>First, pull any updates from the remote main branch.</li>
</ol>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="op">!</span>git config pull.rebase false <span class="co"># Combines the remote changes into your local branch as a merge commit.</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="op">!</span>git pull origin main</span></code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>We can then use jupytext again to convert in the other direction
(.py to .ipynb). This command will create
<code>Interacting-with-S3.ipynb</code> in the current directory,
converting the Python script to a Jupyter Notebook format. Jupytext
handles the conversion gracefully without expecting the <code>.py</code>
file to be in JSON format.</li>
</ol>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="op">!</span>jupytext <span class="op">--</span>to notebook Interacting<span class="op">-</span><span class="cf">with</span><span class="op">-</span>S3.py <span class="op">--</span>output Interacting<span class="op">-</span><span class="cf">with</span><span class="op">-</span>S3.ipynb</span></code></pre>
</div>
<div class="section level3">
<h3 id="applying-to-all--py-files">Applying to all .py files<a class="anchor" aria-label="anchor" href="#applying-to-all--py-files"></a>
</h3>
<p>To convert all of your .py files to notebooks, you can use our helper
function as follows</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>helpers.convert_files(direction<span class="op">=</span><span class="st">"python_to_notebook"</span>)</span></code></pre>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use a GitHub PAT for HTTPS-based authentication in temporary
SageMaker notebook instances.</li>
<li>Securely enter sensitive information in notebooks using
<code>getpass</code>.</li>
<li>Converting <code>.ipynb</code> files to <code>.py</code> files helps
with cleaner version control and easier review of changes.</li>
<li>Adding <code>.ipynb</code> files to <code>.gitignore</code> keeps
your repository organized and reduces storage.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></section><section id="aio-Training-models-in-SageMaker-notebooks"><p>Content from <a href="Training-models-in-SageMaker-notebooks.html">Training Models in SageMaker: Intro</a></p>
<hr>
<p>Last updated on 2025-10-09 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Training-models-in-SageMaker-notebooks.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the differences between local training and
SageMaker-managed training?</li>
<li>How do Estimator classes in SageMaker streamline the training
process for various frameworks?</li>
<li>How does SageMaker handle data and model parallelism, and when
should each be considered?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the difference between training locally in a SageMaker
notebook and using SageMaker’s managed infrastructure.</li>
<li>Learn to configure and use SageMaker’s Estimator classes for
different frameworks (e.g., XGBoost, PyTorch, SKLearn).</li>
<li>Understand data and model parallelism options in SageMaker,
including when to use each for efficient training.</li>
<li>Compare performance, cost, and setup between custom scripts and
built-in images in SageMaker.</li>
<li>Conduct training with data stored in S3 and monitor training job
status using the SageMaker console.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="initial-setup">Initial setup<a class="anchor" aria-label="anchor" href="#initial-setup"></a>
</h2>
<hr class="half-width">
<div class="section level4">
<h4 id="open-prefilled--ipynb-notebook">1. Open prefilled .ipynb notebook<a class="anchor" aria-label="anchor" href="#open-prefilled--ipynb-notebook"></a>
</h4>
<p>Open the notebook from:
<code>/ML_with_AWS_SageMaker/notebooks/Training-models-in-SageMaker-notebooks.ipynb</code></p>
</div>
<div class="section level4">
<h4 id="cd-to-instance-home-directory">2. CD to instance home directory<a class="anchor" aria-label="anchor" href="#cd-to-instance-home-directory"></a>
</h4>
<p>So we all can reference the helper functions using the same path, CD
to…</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="initialize-sagemaker-environment">3. Initialize SageMaker environment<a class="anchor" aria-label="anchor" href="#initialize-sagemaker-environment"></a>
</h4>
<p>This code initializes the AWS SageMaker environment by defining the
SageMaker role and S3 client. It also specifies the S3 bucket and key
for accessing the Titanic training dataset stored in an S3 bucket.</p>
</div>
<div class="section level4">
<h4 id="boto3-api">Boto3 API<a class="anchor" aria-label="anchor" href="#boto3-api"></a>
</h4>
<blockquote>
<p>Boto3 is the official AWS SDK for Python, allowing developers to
interact programmatically with AWS services like S3, EC2, and Lambda. It
provides both high-level and low-level APIs, making it easy to manage
AWS resources and automate tasks. With built-in support for paginators,
waiters, and session management, Boto3 simplifies working with AWS
credentials, regions, and IAM permissions. It’s ideal for automating
cloud operations and integrating AWS services into Python
applications.</p>
</blockquote>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co"># Initialize the SageMaker role (will reflect notebook instance's policy)</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>role <span class="op">=</span> sagemaker.get_execution_role()</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'role = </span><span class="sc">{</span>role<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># Initialize an S3 client to interact with Amazon S3, allowing operations like uploading, downloading, and managing objects and buckets.</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>s3 <span class="op">=</span> boto3.client(<span class="st">'s3'</span>)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co"># Define the S3 bucket that we will load from</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">'sinkorswim-doejohn-titanic'</span>  <span class="co"># replace with your S3 bucket name</span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="co"># Define train/test filenames</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>train_filename <span class="op">=</span> <span class="st">'titanic_train.csv'</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>test_filename <span class="op">=</span> <span class="st">'titanic_test.csv'</span></span></code></pre>
</div>
<p>Create a SageMaker session to manage interactions with Amazon
SageMaker, such as training jobs, model deployments, and data
input/output.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span> <span class="co"># United States (Ohio). Make sure this matches what you see near top right of AWS Console menu</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>boto_session <span class="op">=</span> boto3.Session(region_name<span class="op">=</span>region) <span class="co"># Create a Boto3 session that ensures all AWS service calls (including SageMaker) use the specified region</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session(boto_session<span class="op">=</span>boto_session)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="get-code-from-git-repo-skip-if-completed-already-from-earlier-episodes">4. Get code from git repo (skip if completed already from earlier
episodes)<a class="anchor" aria-label="anchor" href="#get-code-from-git-repo-skip-if-completed-already-from-earlier-episodes"></a>
</h4>
<p>If you didn’t complete the earlier episodes, you’ll need to clone our
code repo before moving forward. Check to make sure we’re in our EC2
root folder first (<code>/home/ec2-user/SageMaker</code>).</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># uncomment below line only if you still need to download the code repo (replace username with your GitHub usernanme)</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co">#!git clone https://github.com/username/AWS_helpers.git </span></span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="testing-train-py-on-this-notebooks-instance">Testing train.py on this notebook’s instance<a class="anchor" aria-label="anchor" href="#testing-train-py-on-this-notebooks-instance"></a>
</h2>
<hr class="half-width">
<p>In this next section, we will learn how to take a model training
script that was written/designed to run locally, and deploy it to more
powerful instances (or many instances) using SageMaker. This is helpful
for machine learning jobs that require extra power, GPUs, or benefit
from parallelization. However, before we try exploiting this extra
power, it is essential that we test our code thoroughly! We don’t want
to waste unnecessary compute cycles and resources on jobs that produce
bugs rather than insights.</p>
<div class="section level3">
<h3 id="general-guidelines-for-testing-ml-pipelines-before-scaling">General guidelines for testing ML pipelines before scaling<a class="anchor" aria-label="anchor" href="#general-guidelines-for-testing-ml-pipelines-before-scaling"></a>
</h3>
<ul>
<li>
<strong>Run tests locally first</strong> (if feasible) to avoid
unnecessary AWS charges. Here, we assume that local tests are not
feasible due to limited local resources. Instead, we use our SageMaker
instance to test our script on a minimally sized EC2 instance.</li>
<li>
<strong>Use a small dataset subset</strong> (e.g., 1-5% of data) to
catch issues early and speed up tests.</li>
<li>
<strong>Start with a small/cheap instance</strong> before committing
to larger resources. Visit the <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">Instances
for ML page</a> for guidance.</li>
<li>
<strong>Log everything</strong> to track training times, errors, and
key metrics.</li>
<li>
<strong>Verify correctness first</strong> before optimizing
hyperparameters or scaling.</li>
</ul>
<div id="what-tests-should-we-do-before-scaling" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="what-tests-should-we-do-before-scaling" class="callout-inner">
<h3 class="callout-title">What tests should we do before scaling?</h3>
<div class="callout-content">
<p>Before scaling to mutliple or more powerful instances (e.g., training
on larger/multiple datsets in parallel or tuning hyperparameters in
parallel), it’s important to run a few quick sanity checks to catch
potential issues early. <strong>In your group, discuss:</strong></p>
<ul>
<li>Which checks do you think are most critical before scaling up?<br>
</li>
<li>What potential issues might we miss if we skip this step?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Which checks do you think are most critical before scaling up?</p>
<ul>
<li>
<strong>Data loads correctly</strong> – Ensure the dataset loads
without errors, expected columns exist, and missing values are handled
properly.<br>
</li>
<li>
<strong>Overfitting check</strong> – Train on a small dataset (e.g.,
100 rows). If it doesn’t overfit, there may be a data or model setup
issue.<br>
</li>
<li>
<strong>Loss behavior check</strong> – Verify that training loss
decreases over time and doesn’t diverge.<br>
</li>
<li>
<strong>Training time estimate</strong> – Run on a small subset to
estimate how long full training will take.</li>
<li>
<strong>Memory estimate</strong> - Estimate the memory needs of the
algorithm/model you’re using, and understand how this scales with input
size.</li>
<li>
<strong>Save &amp; reload test</strong> – Ensure the trained model
can be saved, reloaded, and used for inference without errors.</li>
</ul>
<p>What potential issues might we miss if we skip the above checks?</p>
<ul>
<li>
<strong>Silent data issues</strong> – Missing values, unexpected
distributions, or incorrect labels could degrade model
performance.<br>
</li>
<li>
<strong>Code bugs at scale</strong> – Small logic errors might not
break on small tests but could fail with larger datasets.<br>
</li>
<li>
<strong>Inefficient training runs</strong> – Without estimating
runtime, jobs may take far longer than expected, wasting AWS
resources.<br>
</li>
<li>
<strong>Memory or compute failures</strong> – Large datasets might
exceed instance memory limits, causing crashes or slowdowns.<br>
</li>
<li>
<strong>Model performance issues</strong> – If a model doesn’t
overfit a small dataset, there may be problems with features, training
logic, or hyperparameters.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="know-your-data-before-modeling" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="know-your-data-before-modeling" class="callout-inner">
<h3 class="callout-title"><strong>Know Your Data Before
Modeling</strong></h3>
<div class="callout-content">
<p>The sanity checks above focus on validating the code, but a model is
only as good as the data it’s trained on. A deeper look at feature
distributions, correlations, and potential biases is critical before
scaling up. We won’t cover that here, but it’s essential to keep in mind
for any ML/AI practitioner.</p>
</div>
</div>
</div>
<div id="understanding-the-xgboost-training-script" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="understanding-the-xgboost-training-script" class="callout-inner">
<h3 class="callout-title">Understanding the XGBoost Training Script</h3>
<div class="callout-content">
<p>Take a moment to review the <code>AWS_helpers/train_xgboost.py</code>
script we just cloned into our notebook. This script handles
preprocessing, training, and saving an XGBoost model, while also
adapting to both local and SageMaker-managed environments.</p>
<p>Try answering the following questions:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Data Preprocessing</strong>: What transformations are
applied to the dataset before training?</p></li>
<li><p><strong>Training Function</strong>: What does the
<code>train_model()</code> function do? Why do we print the training
time?</p></li>
<li><p><strong>Command-Line Arguments</strong>: What is the purpose of
<code>argparse</code> in this script? How would you modify the script if
you wanted to change the number of training rounds?</p></li>
<li><p><strong>Handling Local vs. SageMaker Runs</strong>: How does the
script determine whether it is running in a SageMaker training job or
locally (within this notebook’s instance)?</p></li>
<li><p><strong>Training and Saving the Model</strong>: What format is
the dataset converted to before training, and why? How is the trained
model saved, and where will it be stored?</p></li>
</ol>
<p>After reviewing, discuss any questions or observations with your
group.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li><p><strong>Data Preprocessing</strong>: The script fills missing
values (<code>Age</code> with median, <code>Embarked</code> with mode),
converts categorical variables (<code>Sex</code> and
<code>Embarked</code>) to numerical values, and removes columns that
don’t contribute to prediction (<code>Name</code>, <code>Ticket</code>,
<code>Cabin</code>).</p></li>
<li><p><strong>Training Function</strong>: The
<code>train_model()</code> function takes the training dataset
(<code>dtrain</code>), applies XGBoost training with the specified
hyperparameters, and prints the training time. Printing training time
helps compare different runs and ensures that scaling decisions are
based on performance metrics.</p></li>
<li><p><strong>Command-Line Arguments</strong>: <code>argparse</code>
allows passing parameters like <code>max_depth</code>, <code>eta</code>,
<code>num_round</code>, etc., at runtime without modifying the script.
To change the number of training rounds, you would update the
<code>--num_round</code> argument when running the script:
<code>python train_xgboost.py --num_round 200</code></p></li>
<li><p><strong>Handling Local vs. SageMaker Runs</strong>: The script
uses <code>os.environ.get("SM_CHANNEL_TRAIN", ".")</code> and
<code>os.environ.get("SM_MODEL_DIR", ".")</code> to detect whether it’s
running in SageMaker. <code>SM_CHANNEL_TRAIN</code> is the directory
where SageMaker stores input training data, and
<code>SM_MODEL_DIR</code> is the directory where trained models should
be saved. If these environment variables are <em>not set</em> (e.g.,
running locally), the script defaults to <code>"."</code> (current
directory).</p></li>
<li><p><strong>Training and Saving the Model</strong>: The dataset is
converted into <strong>XGBoost’s <code>DMatrix</code> format</strong>,
which is optimized for memory and computation efficiency. The trained
model is saved using <code>joblib.dump()</code> to
<code>xgboost-model</code>, stored either in the SageMaker
<code>SM_MODEL_DIR</code> (if running in SageMaker) or in the local
directory.</p></li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="download-data-into-notebook-environment">Download data into notebook environment<a class="anchor" aria-label="anchor" href="#download-data-into-notebook-environment"></a>
</h3>
<p>It can be convenient to have a copy of the data (i.e., one that you
store in your notebook’s instance) to allow us to test our code before
scaling things up.</p>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>While we demonstrate how to download data into the notebook
environment for testing our code (previously setup for local ML
pipelines), keep in mind that S3 is the preferred location for dataset
storage in a scalable ML pipeline.</p>
</div>
</div>
</div>
<p>Run the next code chunk to download data from S3 to notebook
environment. You may need to hit refresh on the file explorer panel to
the left to see this file. If you get any permission issues…</p>
<ul>
<li>check that you have selected the appropriate policy for this
notebook</li>
<li>check that your bucket has the appropriate policy permissions</li>
</ul>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Define the S3 bucket and file location</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>file_key <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>train_filename<span class="sc">}</span><span class="ss">"</span>  <span class="co"># Path to your file in the S3 bucket</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>local_file_path <span class="op">=</span> <span class="ss">f"./</span><span class="sc">{</span>train_filename<span class="sc">}</span><span class="ss">"</span>  <span class="co"># Local path to save the file</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># Download the file using the s3 client variable we initialized earlier</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>s3.download_file(bucket_name, file_key, local_file_path)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"File downloaded:"</span>, local_file_path)</span></code></pre>
</div>
<p>We can do the same for the test set.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Define the S3 bucket and file location</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>file_key <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>test_filename<span class="sc">}</span><span class="ss">"</span>  <span class="co"># Path to your file in the S3 bucket. W</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>local_file_path <span class="op">=</span> <span class="ss">f"./</span><span class="sc">{</span>test_filename<span class="sc">}</span><span class="ss">"</span>  <span class="co"># Local path to save the file</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co"># Initialize the S3 client and download the file</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>s3.download_file(bucket_name, file_key, local_file_path)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"File downloaded:"</span>, local_file_path)</span></code></pre>
</div>
<div class="section level4">
<h4 id="logging-runtime-instance-info">Logging runtime &amp; instance info<a class="anchor" aria-label="anchor" href="#logging-runtime-instance-info"></a>
</h4>
<p>To compare our local runtime with future experiments, we’ll need to
know what instance was used, as this will greatly impact runtime in many
cases. We can extract the instance name for this notebook using…</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Replace with your notebook instance name.</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co"># This does NOT refer to specific ipynb files, but to the SageMaker notebook instance.</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>notebook_instance_name <span class="op">=</span> <span class="st">'sinkorswim-DoeJohn-TrainClassifier'</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co"># Make sure this matches what you see near top right of AWS Console menu</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span> <span class="co"># United States (Ohio)</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># Initialize SageMaker client</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>sagemaker_client <span class="op">=</span> boto3.client(<span class="st">'sagemaker'</span>, region_name<span class="op">=</span>region)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co"># Describe the notebook instance</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>response <span class="op">=</span> sagemaker_client.describe_notebook_instance(NotebookInstanceName<span class="op">=</span>notebook_instance_name)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co"># Display the status and instance type</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Notebook Instance '</span><span class="sc">{</span>notebook_instance_name<span class="sc">}</span><span class="ss">' status: </span><span class="sc">{</span>response[<span class="st">'NotebookInstanceStatus'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>local_instance <span class="op">=</span> response[<span class="st">'InstanceType'</span>]</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Instance Type: </span><span class="sc">{</span>local_instance<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="helper-get_notebook_instance_info">Helper: <code>get_notebook_instance_info()</code>
<a class="anchor" aria-label="anchor" href="#helper-get_notebook_instance_info"></a>
</h4>
<p>You can also use the <code>get_notebook_instance_info()</code>
function found in <code>AWS_helpers.py</code> to retrieve this info for
your own project.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> AWS_helpers.helpers <span class="im">as</span> helpers</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>helpers.get_notebook_instance_info(notebook_instance_name, region)</span></code></pre>
</div>
<p>Test train.py on this notebook’s instance (or when possible, on your
own machine) before doing anything more complicated (e.g.,
hyperparameter tuning on multiple instances)</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="op">!</span>pip install xgboost <span class="co"># need to add this to environment to run train.py</span></span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="local-test">Local test<a class="anchor" aria-label="anchor" href="#local-test"></a>
</h3>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> t <span class="co"># we'll use the time package to measure runtime</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>start_time <span class="op">=</span> t.time()</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co"># Define your parameters. These python vars wil be passed as input args to our train_xgboost.py script using %run</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>max_depth <span class="op">=</span> <span class="dv">3</span> <span class="co"># Sets the maximum depth of each tree in the model to 3. Limiting tree depth helps control model complexity and can reduce overfitting, especially on small datasets.</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>eta <span class="op">=</span> <span class="fl">0.1</span> <span class="co">#  Sets the learning rate to 0.1, which scales the contribution of each tree to the final model. A smaller learning rate often requires more rounds to converge but can lead to better performance.</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>subsample <span class="op">=</span> <span class="fl">0.8</span> <span class="co"># Specifies that 80% of the training data will be randomly sampled to build each tree. Subsampling can help with model robustness by preventing overfitting and increasing variance.</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>colsample_bytree <span class="op">=</span> <span class="fl">0.8</span> <span class="co"># Specifies that 80% of the features will be randomly sampled for each tree, enhancing the model's ability to generalize by reducing feature reliance.</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>num_round <span class="op">=</span> <span class="dv">100</span> <span class="co"># Sets the number of boosting rounds (trees) to 100. More rounds typically allow for a more refined model, but too many rounds can lead to overfitting.</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>train_file <span class="op">=</span> <span class="st">'titanic_train.csv'</span> <span class="co">#  Points to the location of the training data</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="co"># Use f-strings to format the command with your variables</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="op">%</span>run AWS_helpers<span class="op">/</span>train_xgboost.py <span class="op">--</span>max_depth {max_depth} <span class="op">--</span>eta {eta} <span class="op">--</span>subsample {subsample} <span class="op">--</span>colsample_bytree {colsample_bytree} <span class="op">--</span>num_round {num_round} <span class="op">--</span>train {train_file}</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="co"># Measure and print the time taken</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total local runtime: </span><span class="sc">{</span>t<span class="sc">.</span>time() <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type = </span><span class="sc">{</span>local_instance<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>Training on this relatively small dataset should take less than a
minute, but as we scale up with larger datasets and more complex models
in SageMaker, tracking both training time and total runtime becomes
essential for efficient debugging and resource management.</p>
<p><strong>Note</strong>: Our code above includes print statements to
monitor dataset size, training time, and total runtime, which provides
insights into resource usage for model development. We recommend
incorporating similar logging to track not only training time but also
total runtime, which includes additional steps like data loading,
evaluation, and saving results. Tracking both can help you pinpoint
bottlenecks and optimize your workflow as projects grow in size and
complexity, especially when scaling with SageMaker’s distributed
resources.</p>
</div>
<div class="section level3">
<h3 id="sanity-check-quick-evaluation-on-test-set">Sanity check: Quick evaluation on test set<a class="anchor" aria-label="anchor" href="#sanity-check-quick-evaluation-on-test-set"></a>
</h3>
<p>This next section isn’t SageMaker specific, but it does serve as a
good sanity check to ensure our model is training properly. Here’s how
you would apply the outputted model to your test set using your local
notebook instance.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="im">import</span> joblib</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="im">from</span> AWS_helpers.train_xgboost <span class="im">import</span> preprocess_data</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="co"># Load the test data</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>test_data <span class="op">=</span> pd.read_csv(<span class="st">'./titanic_test.csv'</span>)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="co"># Preprocess the test data using the imported preprocess_data function</span></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>X_test, y_test <span class="op">=</span> preprocess_data(test_data)</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a><span class="co"># Convert the test features to DMatrix for XGBoost</span></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(X_test)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a><span class="co"># Load the trained model from the saved file</span></span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>model <span class="op">=</span> joblib.load(<span class="st">'./xgboost-model'</span>)</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>preds <span class="op">=</span> model.predict(dtest)</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>predictions <span class="op">=</span> np.<span class="bu">round</span>(preds)  <span class="co"># Round predictions to 0 or 1 for binary classification</span></span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a><span class="co"># Calculate and print the accuracy of the model on the test data</span></span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, predictions)</span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Set Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>A reasonably high test set accuracy suggests our code/model is
working correctly.</p>
</div>
</section><section><h2 class="section-heading" id="training-via-sagemaker-using-notebook-as-controller---custom-train-py-script">Training via SageMaker (using notebook as controller) - custom
train.py script<a class="anchor" aria-label="anchor" href="#training-via-sagemaker-using-notebook-as-controller---custom-train-py-script"></a>
</h2>
<hr class="half-width">
<p>Unlike “local” training (using this notebook), this next approach
leverages SageMaker’s managed infrastructure to handle resources,
parallelism, and scalability. By specifying instance parameters, such as
instance_count and instance_type, you can control the resources
allocated for training.</p>
<div class="section level3">
<h3 id="which-instance-to-start-with">Which instance to start with?<a class="anchor" aria-label="anchor" href="#which-instance-to-start-with"></a>
</h3>
<p>In this example, we start with one ml.m5.large instance, which is
suitable for small- to medium-sized datasets and simpler models. Using a
single instance is often cost-effective and sufficient for initial
testing, allowing for straightforward scaling up to more powerful
instance types or multiple instances if training takes too long. See
here for further guidance on selecting an appropriate instance for your
data/model: <a href="https://docs.google.com/spreadsheets/d/1uPT4ZAYl_onIl7zIjv5oEAdwy4Hdn6eiA9wVfOBbHmY/edit?usp=sharing" class="external-link">EC2
Instances for ML</a></p>
</div>
<div class="section level3">
<h3 id="overview-of-estimator-classes-in-sagemaker">Overview of Estimator classes in SageMaker<a class="anchor" aria-label="anchor" href="#overview-of-estimator-classes-in-sagemaker"></a>
</h3>
<p>To launch this training “job”, we’ll use the XGBoost “Estimator. In
SageMaker, Estimator classes streamline the configuration and training
of models on managed instances. Each Estimator can work with custom
scripts and be enhanced with additional dependencies by specifying a
<code>requirements.txt</code> file, which is automatically installed at
the start of training. Here’s a breakdown of some commonly used
Estimator classes in SageMaker:</p>
<div class="section level4">
<h4 id="estimator-base-class">1. <strong><code>Estimator</code> (Base Class)</strong>
<a class="anchor" aria-label="anchor" href="#estimator-base-class"></a>
</h4>
<ul>
<li>
<strong>Purpose</strong>: General-purpose for custom Docker
containers or defining an image URI directly.</li>
<li>
<strong>Configuration</strong>: Requires specifying an
<code>image_uri</code> and custom entry points.</li>
<li>
<strong>Dependencies</strong>: You can use
<code>requirements.txt</code> to install Python packages or configure a
custom Docker container with pre-baked dependencies.</li>
<li>
<strong>Ideal Use Cases</strong>: Custom algorithms or models that
need tailored environments not covered by built-in containers.</li>
</ul>
</div>
<div class="section level4">
<h4 id="xgboost-estimator">2. <strong><code>XGBoost</code> Estimator</strong>
<a class="anchor" aria-label="anchor" href="#xgboost-estimator"></a>
</h4>
<ul>
<li>
<strong>Purpose</strong>: Provides an optimized container
specifically for XGBoost models.</li>
<li>
<strong>Configuration</strong>:
<ul>
<li>
<code>entry_point</code>: Path to a custom script, useful for
additional preprocessing or unique training workflows.</li>
<li>
<code>framework_version</code>: Select XGBoost version, e.g.,
<code>"1.5-1"</code>.</li>
<li>
<code>dependencies</code>: Specify additional packages through
<code>requirements.txt</code> to enhance preprocessing capabilities or
incorporate auxiliary libraries.</li>
</ul>
</li>
<li>
<strong>Ideal Use Cases</strong>: Tabular data modeling using
gradient-boosted trees; cases requiring custom preprocessing or tuning
logic.</li>
</ul>
</div>
<div class="section level4">
<h4 id="pytorch-estimator">3. <strong><code>PyTorch</code> Estimator</strong>
<a class="anchor" aria-label="anchor" href="#pytorch-estimator"></a>
</h4>
<ul>
<li>
<strong>Purpose</strong>: Configures training jobs with PyTorch for
deep learning tasks.</li>
<li>
<strong>Configuration</strong>:
<ul>
<li>
<code>entry_point</code>: Training script with model architecture
and training loop.</li>
<li>
<code>instance_type</code>: e.g., <code>ml.p3.2xlarge</code> for GPU
acceleration.</li>
<li>
<code>framework_version</code> and <code>py_version</code>: Define
specific versions.</li>
<li>
<code>dependencies</code>: Install any required packages via
<code>requirements.txt</code> to support advanced data processing, data
augmentation, or custom layer implementations.</li>
</ul>
</li>
<li>
<strong>Ideal Use Cases</strong>: Deep learning models, particularly
complex networks requiring GPUs and custom layers.</li>
</ul>
</div>
<div class="section level4">
<h4 id="sklearn-estimator">4. <strong><code>SKLearn</code> Estimator</strong>
<a class="anchor" aria-label="anchor" href="#sklearn-estimator"></a>
</h4>
<ul>
<li>
<strong>Purpose</strong>: Supports scikit-learn workflows for data
preprocessing and classical machine learning.</li>
<li>
<strong>Configuration</strong>:
<ul>
<li>
<code>entry_point</code>: Python script to handle feature
engineering, preprocessing, or training.</li>
<li>
<code>framework_version</code>: Version of scikit-learn, e.g.,
<code>"1.0-1"</code>.</li>
<li>
<code>dependencies</code>: Use <code>requirements.txt</code> to
install any additional Python packages required by the training
script.</li>
</ul>
</li>
<li>
<strong>Ideal Use Cases</strong>: Classical ML workflows, extensive
preprocessing, or cases where additional libraries (e.g., pandas, numpy)
are essential.</li>
</ul>
</div>
<div class="section level4">
<h4 id="tensorflow-estimator">5. <strong><code>TensorFlow</code> Estimator</strong>
<a class="anchor" aria-label="anchor" href="#tensorflow-estimator"></a>
</h4>
<ul>
<li>
<strong>Purpose</strong>: Designed for training and deploying
TensorFlow models.</li>
<li>
<strong>Configuration</strong>:
<ul>
<li>
<code>entry_point</code>: Script for model definition and training
process.</li>
<li>
<code>instance_type</code>: Select based on dataset size and
computational needs.</li>
<li>
<code>dependencies</code>: Additional dependencies can be listed in
<code>requirements.txt</code> to install TensorFlow add-ons, custom
layers, or preprocessing libraries.</li>
</ul>
</li>
<li>
<strong>Ideal Use Cases</strong>: NLP, computer vision, and transfer
learning applications in TensorFlow.</li>
</ul>
</div>
<div class="section level4">
<h4 id="huggingface-estimator">6. <strong><code>HuggingFace</code> Estimator</strong>
<a class="anchor" aria-label="anchor" href="#huggingface-estimator"></a>
</h4>
<ul>
<li>
<strong>Purpose</strong>: Provides managed containers for running
inference, fine-tuning, and Retrieval-Augmented Generation (RAG)
workflows using the Hugging Face <code>transformers</code>
library.<br>
</li>
<li>
<strong>Configuration</strong>:
<ul>
<li>
<code>entry_point</code>: Custom script for training or inference
(e.g., <code>train.py</code> or <code>rag_inference.py</code>).<br>
</li>
<li>
<code>transformers_version</code>, <code>pytorch_version</code>,
<code>py_version</code>: Define framework versions.<br>
</li>
<li>
<code>dependencies</code>: Optional <code>requirements.txt</code>
for extra libraries.<br>
</li>
</ul>
</li>
<li>
<strong>Ideal Use Cases</strong>: RAG pipelines, LLM inference, NLP,
vision, or multimodal tasks using pretrained Transformer models.</li>
</ul>
<div id="configuring-custom-environments-with-requirements.txt" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="configuring-custom-environments-with-requirements.txt" class="callout-inner">
<h3 class="callout-title">Configuring custom environments with
<code>requirements.txt</code>
</h3>
<div class="callout-content">
<p>For all these Estimators, adding a <code>requirements.txt</code> file
as a <code>dependencies</code> argument ensures that additional packages
are installed before training begins. This approach allows the use of
specific libraries that may be critical for custom preprocessing,
feature engineering, or model modifications. Here’s how to include
it:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># # Customizing estimator using requirements.txt</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co"># from sagemaker.sklearn.estimator import SKLearn</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># sklearn_estimator = SKLearn(</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co">#     base_job_name=notebook_instance_name,</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#     entry_point="train_script.py",</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#     role=role,</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">#     instance_count=1,</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#     instance_type="ml.m5.large",</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#     output_path=f"s3://{bucket_name}/output",</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">#     framework_version="1.0-1",</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co">#     dependencies=['requirements.txt'],  # Adding custom dependencies</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co">#     hyperparameters={</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co">#         "max_depth": 5,</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co">#         "eta": 0.1,</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="co">#         "subsample": 0.8,</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="co">#         "num_round": 100</span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="co">#     }</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="co"># )</span></span></code></pre>
</div>
<p>This setup simplifies training, allowing you to maintain custom
environments directly within SageMaker’s managed containers, without
needing to build and manage your own Docker images. The <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html" class="external-link">AWS
SageMaker Documentation</a> provides lists of pre-built container images
for each framework and their standard libraries, including details on
pre-installed packages.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="deploying-to-other-instances">Deploying to other instances<a class="anchor" aria-label="anchor" href="#deploying-to-other-instances"></a>
</h3>
<p>For this deployment, we configure the “XGBoost” estimator with a
custom training script, train_xgboost.py, and define hyperparameters
directly within the SageMaker setup. Here’s the full code, with some
additional explanation following the code.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="im">from</span> sagemaker.inputs <span class="im">import</span> TrainingInput</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="im">from</span> sagemaker.xgboost.estimator <span class="im">import</span> XGBoost</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co"># Define instance type/count we'll use for training</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.m5.large"</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>instance_count<span class="op">=</span><span class="dv">1</span> <span class="co"># always start with 1. Rarely is parallelized training justified with data &lt; 50 GB. More on this later.</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># Define max runtime in seconds to ensure you don't use more compute time than expected. Use a generous threshold (2x expected time but &lt; 2 days) so that work isn't interrupted without any gains.</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>max_run <span class="op">=</span> <span class="dv">2</span><span class="op">*</span><span class="dv">60</span><span class="op">*</span><span class="dv">60</span> <span class="co"># 2 hours</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="co"># Define S3 paths for input and output</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>train_s3_path <span class="op">=</span> <span class="ss">f's3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>train_filename<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co"># we'll store all results in a subfolder called xgboost on our bucket. This folder will automatically be created if it doesn't exist already.</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>output_folder <span class="op">=</span> <span class="st">'xgboost'</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>output_path <span class="op">=</span> <span class="ss">f's3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>output_folder<span class="sc">}</span><span class="ss">/'</span> </span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a><span class="co"># Set up the SageMaker XGBoost Estimator with custom script</span></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>xgboost_estimator <span class="op">=</span> XGBoost(</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>    entry_point<span class="op">=</span><span class="st">'train_xgboost.py'</span>,      <span class="co"># Custom script path</span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>    source_dir<span class="op">=</span><span class="st">'AWS_helpers'</span>,               <span class="co"># Directory where your script is located</span></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type,</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>    output_path<span class="op">=</span>output_path,</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>    framework_version<span class="op">=</span><span class="st">"1.5-1"</span>,           <span class="co"># Use latest supported version for better compatibility</span></span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a>    hyperparameters<span class="op">=</span>{</span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a>        <span class="st">'train'</span>: train_file,</span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>        <span class="st">'max_depth'</span>: max_depth,</span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>        <span class="st">'eta'</span>: eta,</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a>        <span class="st">'subsample'</span>: subsample,</span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>        <span class="st">'colsample_bytree'</span>: colsample_bytree,</span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>        <span class="st">'num_round'</span>: num_round</span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a>    }</span>
<span id="cb14-38"><a href="#cb14-38" tabindex="-1"></a>)</span>
<span id="cb14-39"><a href="#cb14-39" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" tabindex="-1"></a><span class="co"># Define input data</span></span>
<span id="cb14-41"><a href="#cb14-41" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(train_s3_path, content_type<span class="op">=</span><span class="st">'csv'</span>)</span>
<span id="cb14-42"><a href="#cb14-42" tabindex="-1"></a></span>
<span id="cb14-43"><a href="#cb14-43" tabindex="-1"></a><span class="co"># Measure and start training time</span></span>
<span id="cb14-44"><a href="#cb14-44" tabindex="-1"></a>start <span class="op">=</span> t.time()</span>
<span id="cb14-45"><a href="#cb14-45" tabindex="-1"></a>xgboost_estimator.fit({<span class="st">'train'</span>: train_input})</span>
<span id="cb14-46"><a href="#cb14-46" tabindex="-1"></a>end <span class="op">=</span> t.time()</span>
<span id="cb14-47"><a href="#cb14-47" tabindex="-1"></a></span>
<span id="cb14-48"><a href="#cb14-48" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>When running longer training jobs, you can check on their status
periodically from the AWS SageMaker Console (where we originally
launched our Notebook instance) on left side panel under “Training”.</p>
<div class="section level4">
<h4 id="hyperparameters">Hyperparameters<a class="anchor" aria-label="anchor" href="#hyperparameters"></a>
</h4>
<p>The <code>hyperparameters</code> section in this code defines the
input arguments of train_XGBoost.py. The first is the name of the
training input file, and the others are hyperparameters for the XGBoost
model, such as <code>max_depth</code>, <code>eta</code>,
<code>subsample</code>, <code>colsample_bytree</code>, and
<code>num_round</code>.</p>
</div>
<div class="section level4">
<h4 id="traininginput">TrainingInput<a class="anchor" aria-label="anchor" href="#traininginput"></a>
</h4>
<p>Additionally, we define a TrainingInput object containing the
training data’s S3 path, to pass to
<code>.fit({'train': train_input})</code>. SageMaker uses
<code>TrainingInput</code> to download your dataset from S3 to a
temporary location on the training instance. This location is mounted
and managed by SageMaker and can be accessed by the training job if/when
needed.</p>
</div>
<div class="section level4">
<h4 id="model-results">Model results<a class="anchor" aria-label="anchor" href="#model-results"></a>
</h4>
<p>With this code, the training results and model artifacts are saved in
a subfolder called <code>xgboost</code> in your specified S3 bucket.
This folder (<code>s3://{bucket_name}/xgboost/</code>) will be
automatically created if it doesn’t already exist, and will contain:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Model “artifacts”</strong>: The trained model file (often a
<code>.tar.gz</code> file) that SageMaker saves in the
<code>output_path</code>.</li>
<li>
<strong>Logs and metrics</strong>: Any metrics and logs related to
the training job, stored in the same <code>xgboost</code> folder.</li>
</ol>
<p>This setup allows for convenient access to both the trained model and
related output for later evaluation or deployment.</p>
</div>
</div>
<div class="section level3">
<h3 id="extracting-trained-model-from-s3-for-final-evaluation">Extracting trained model from S3 for final evaluation<a class="anchor" aria-label="anchor" href="#extracting-trained-model-from-s3-for-final-evaluation"></a>
</h3>
<p>To evaluate the model on a test set after training, we’ll go through
these steps:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Download the trained model from S3</strong>.</li>
<li>
<strong>Load and preprocess</strong> the test dataset.</li>
<li>
<strong>Evaluate</strong> the model on the test data.</li>
</ol>
<p>Here’s how you can implement this in your SageMaker notebook. The
following code will:</p>
<ul>
<li>Download the <code>model.tar.gz</code> file containing the trained
model from S3.</li>
<li>Load the <code>test.csv</code> data from S3 and preprocess it as
needed.</li>
<li>Use the XGBoost model to make predictions on the test set and then
compute accuracy or other metrics on the results.</li>
</ul>
<p>If additional metrics or custom evaluation steps are needed, you can
add them in place of or alongside accuracy.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># Model results are saved in auto-generated folders. Use xgboost_estimator.latest_training_job.name to get the folder name</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>model_s3_path <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>output_folder<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>xgboost_estimator<span class="sc">.</span>latest_training_job<span class="sc">.</span>name<span class="sc">}</span><span class="ss">/output/model.tar.gz'</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="bu">print</span>(model_s3_path)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>local_model_path <span class="op">=</span> <span class="st">'model.tar.gz'</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="co"># Download the trained model from S3</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>s3.download_file(bucket_name, model_s3_path, local_model_path)</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co"># Extract the model file</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="im">import</span> tarfile</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="cf">with</span> tarfile.<span class="bu">open</span>(local_model_path) <span class="im">as</span> tar:</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>    tar.extractall()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="im">import</span> joblib</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="im">from</span> AWS_helpers.train_xgboost <span class="im">import</span> preprocess_data</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="co"># Load the test data</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>test_data <span class="op">=</span> pd.read_csv(<span class="st">'./titanic_test.csv'</span>)</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co"># Preprocess the test data using the imported preprocess_data function</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>X_test, y_test <span class="op">=</span> preprocess_data(test_data)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a><span class="co"># Convert the test features to DMatrix for XGBoost</span></span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(X_test)</span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a><span class="co"># Load the trained model from the saved file</span></span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a>model <span class="op">=</span> joblib.load(<span class="st">'./xgboost-model'</span>)</span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb16-21"><a href="#cb16-21" tabindex="-1"></a>preds <span class="op">=</span> model.predict(dtest)</span>
<span id="cb16-22"><a href="#cb16-22" tabindex="-1"></a>predictions <span class="op">=</span> np.<span class="bu">round</span>(preds)  <span class="co"># Round predictions to 0 or 1 for binary classification</span></span>
<span id="cb16-23"><a href="#cb16-23" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" tabindex="-1"></a><span class="co"># Calculate and print the accuracy of the model on the test data</span></span>
<span id="cb16-25"><a href="#cb16-25" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, predictions)</span>
<span id="cb16-26"><a href="#cb16-26" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Set Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>Now that we’ve covered training using a custom script with the
<code>XGBoost</code> estimator, let’s examine the built-in image-based
approach. Using SageMaker’s pre-configured XGBoost image streamlines the
setup by eliminating the need to manage custom scripts for common
workflows, and it can also provide optimization advantages. Below, we’ll
discuss both the code and pros and cons of the image-based setup
compared to the custom script approach.</p>
</div>
</section><section><h2 class="section-heading" id="training-with-sagemakers-built-in-xgboost-image">Training with SageMaker’s Built-in XGBoost Image<a class="anchor" aria-label="anchor" href="#training-with-sagemakers-built-in-xgboost-image"></a>
</h2>
<hr class="half-width">
<p>With the SageMaker-provided XGBoost container, you can bypass custom
script configuration if your workflow aligns with standard XGBoost
training. This setup is particularly useful when you need quick, default
configurations without custom preprocessing or additional libraries.</p>
<div class="section level3">
<h3 id="comparison-custom-script-vs--built-in-image">Comparison: Custom Script vs. Built-in Image<a class="anchor" aria-label="anchor" href="#comparison-custom-script-vs--built-in-image"></a>
</h3>
<table class="table">
<colgroup>
<col width="20%">
<col width="41%">
<col width="38%">
</colgroup>
<thead><tr class="header">
<th>Feature</th>
<th>Custom Script (<code>XGBoost</code> with
<code>entry_point</code>)</th>
<th>Built-in XGBoost Image</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Flexibility</strong></td>
<td>Allows for custom preprocessing, data transformation, or advanced
parameterization. Requires a Python script and custom dependencies can
be added through <code>requirements.txt</code>.</td>
<td>Limited to XGBoost’s built-in functionality, no custom preprocessing
steps without additional customization.</td>
</tr>
<tr class="even">
<td><strong>Simplicity</strong></td>
<td>Requires setting up a script with <code>entry_point</code> and
managing dependencies. Ideal for specific needs but requires
configuration.</td>
<td>Streamlined for fast deployment without custom code. Simple setup
and no need for custom scripts.</td>
</tr>
<tr class="odd">
<td><strong>Performance</strong></td>
<td>Similar performance, though potential for overhead with additional
preprocessing.</td>
<td>Optimized for typical XGBoost tasks with faster startup. May offer
marginally faster time-to-first-train.</td>
</tr>
<tr class="even">
<td><strong>Use Cases</strong></td>
<td>Ideal for complex workflows requiring unique preprocessing steps or
when adding specific libraries or functionalities.</td>
<td>Best for quick experiments, standard workflows, or initial testing
on datasets without complex preprocessing.</td>
</tr>
</tbody>
</table>
<p><strong>When to use each approach</strong>:</p>
<ul>
<li>
<strong>Custom script</strong>: Recommended if you need to implement
custom data preprocessing, advanced feature engineering, or specific
workflow steps that require more control over training.</li>
<li>
<strong>Built-in image</strong>: Ideal when running standard XGBoost
training, especially for quick experiments or production deployments
where default configurations suffice.</li>
</ul>
<p>Both methods offer powerful and flexible approaches to model training
on SageMaker, allowing you to select the approach best suited to your
needs. Below is an example of training using the built-in XGBoost
Image.</p>
<div class="section level4">
<h4 id="setting-up-the-data-path">Setting up the data path<a class="anchor" aria-label="anchor" href="#setting-up-the-data-path"></a>
</h4>
<p>In this approach, using <code>TrainingInput</code> directly with
SageMaker’s built-in XGBoost container contrasts with our previous
method, where we specified a custom script with argument inputs
(specified in hyperparameters) for data paths and settings. Here, we use
hyperparameters only to specify the model’s hyperparameters.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">from</span> sagemaker.estimator <span class="im">import</span> Estimator <span class="co"># when using images, we use the general Estimator class</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="co"># Define instance type/count we'll use for training</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.m5.large"</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>instance_count<span class="op">=</span><span class="dv">1</span> <span class="co"># always start with 1. Rarely is parallelized training justified with data &lt; 50 GB. More on this later.</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co"># Use Estimator directly for built-in container without specifying entry_point</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>xgboost_estimator_builtin <span class="op">=</span> Estimator(</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>    image_uri<span class="op">=</span>sagemaker.image_uris.retrieve(<span class="st">"xgboost"</span>, session.boto_region_name, version<span class="op">=</span><span class="st">"1.5-1"</span>),</span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type,</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>    output_path<span class="op">=</span>output_path,</span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>    hyperparameters<span class="op">=</span>{</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>        <span class="st">'max_depth'</span>: max_depth,</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a>        <span class="st">'eta'</span>: eta,</span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a>        <span class="st">'subsample'</span>: subsample,</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>        <span class="st">'colsample_bytree'</span>: colsample_bytree,</span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a>        <span class="st">'num_round'</span>: num_round</span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>    }</span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a>)</span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a><span class="co"># Define input data</span></span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(train_s3_path, content_type<span class="op">=</span><span class="st">"csv"</span>)</span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" tabindex="-1"></a><span class="co"># Measure and start training time</span></span>
<span id="cb17-30"><a href="#cb17-30" tabindex="-1"></a>start <span class="op">=</span> t.time()</span>
<span id="cb17-31"><a href="#cb17-31" tabindex="-1"></a>xgboost_estimator_builtin.fit({<span class="st">'train'</span>: train_input})</span>
<span id="cb17-32"><a href="#cb17-32" tabindex="-1"></a>end <span class="op">=</span> t.time()</span>
<span id="cb17-33"><a href="#cb17-33" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="monitoring-training">Monitoring training<a class="anchor" aria-label="anchor" href="#monitoring-training"></a>
</h2>
<hr class="half-width">
<p>To view and monitor your SageMaker training job, follow these steps
in the AWS Management Console. Since training jobs may be visible to
multiple users in your account, it’s essential to confirm that you’re
interacting with your own job before making any changes.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Navigate to the SageMaker Console</strong>
<ul>
<li>Go to the AWS Management Console and open the
<strong>SageMaker</strong> service (can search for it)</li>
</ul>
</li>
<li>
<strong>View training jobs</strong>
<ul>
<li>In the left-hand navigation menu, select <strong>Training
jobs</strong>. You’ll see a list of recent training jobs, which may
include jobs from other users in the account.</li>
</ul>
</li>
<li>
<strong>Verify your training Job</strong>
<ul>
<li>Identify your job by looking for the specific name format (e.g.,
<code>sagemaker-xgboost-YYYY-MM-DD-HH-MM-SS-XXX</code>) generated when
you launched the job. Click on its name to access detailed information.
Cross-check the job details, such as the <strong>Instance Type</strong>
and <strong>Input data configuration</strong>, with the parameters you
set in your script.</li>
</ul>
</li>
<li>
<strong>Monitor the job status</strong>
<ul>
<li>Once you’ve verified the correct job, click on its name to access
detailed information:
<ul>
<li>
<strong>Status</strong>: Confirms whether the job is
<code>InProgress</code>, <code>Completed</code>, or
<code>Failed</code>.</li>
<li>
<strong>Logs</strong>: Review CloudWatch Logs and Job Metrics for
real-time updates.</li>
<li>
<strong>Output Data</strong>: Shows the S3 location with the trained
model artifacts.</li>
</ul>
</li>
</ul>
</li>
<li>
<strong>Stopping a training job</strong>
<ul>
<li>Before stopping a job, ensure you’ve selected the correct one by
verifying job details as outlined above.</li>
<li>If you’re certain it’s your job, go to <strong>Training
jobs</strong> in the SageMaker Console, select the job, and choose
<strong>Stop</strong> from the <strong>Actions</strong> menu. Confirm
your selection, as this action will halt the job and release any
associated resources.</li>
<li>
<strong>Important</strong>: Avoid stopping jobs you don’t own, as
this could disrupt other users’ work and may have unintended
consequences.</li>
</ul>
</li>
</ol>
<p>Following these steps helps ensure you only interact with and modify
jobs you own, reducing the risk of impacting other users’ training
processes.</p>
</section><section><h2 class="section-heading" id="when-training-takes-too-long">When training takes too long<a class="anchor" aria-label="anchor" href="#when-training-takes-too-long"></a>
</h2>
<hr class="half-width">
<p>When training time becomes excessive, two main options can improve
efficiency in SageMaker:</p>
<ul>
<li>
<strong>Option 1: Upgrading to a more powerful
instance</strong><br>
</li>
<li><strong>Option 2: Using multiple instances for distributed
training</strong></li>
</ul>
<p>Generally, Option 1 is the preferred approach and should be explored
first.</p>
<div class="section level3">
<h3 id="option-1-upgrade-to-a-more-powerful-instance-preferred-starting-point">Option 1: Upgrade to a more powerful instance (preferred starting
point)<a class="anchor" aria-label="anchor" href="#option-1-upgrade-to-a-more-powerful-instance-preferred-starting-point"></a>
</h3>
<p>Upgrading to a more capable instance, particularly one with GPU
capabilities, is often the simplest and most cost-effective way to speed
up training. Check the <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">Instances
for ML page</a> for guidance.</p>
<p>When to use a single instance upgrade:<br>
- Dataset size – The dataset is small to moderate (e.g., &lt;10 GB),
fitting comfortably within memory.<br>
- Model complexity – XGBoost models are typically small enough to fit in
memory.<br>
- Training time – If training completes in a few hours but could be
faster, upgrading may help.</p>
<p>Upgrading a single instance is usually the most efficient option. It
avoids the communication overhead of multi-instance setups and works
well for small to medium datasets.</p>
</div>
<div class="section level3">
<h3 id="option-2-use-multiple-instances-for-distributed-training">Option 2: Use multiple instances for distributed training<a class="anchor" aria-label="anchor" href="#option-2-use-multiple-instances-for-distributed-training"></a>
</h3>
<p>If upgrading a single instance doesn’t sufficiently reduce training
time, distributed training across multiple instances may be a viable
alternative. For XGBoost, SageMaker applies only data parallelism (not
model parallelism).</p>
<div class="section level4">
<h4 id="xgboost-uses-data-parallelism-not-model-parallelism">XGBoost uses data parallelism, not model parallelism<a class="anchor" aria-label="anchor" href="#xgboost-uses-data-parallelism-not-model-parallelism"></a>
</h4>
<ul>
<li>Data parallelism – The dataset is split across multiple instances,
with each instance training on a portion of the data. The gradient
updates are then synchronized and aggregated.<br>
</li>
<li>Why not model parallelism? – Unlike deep learning models, XGBoost
decision trees are small enough to fit in memory, so there’s no need to
split the model itself across multiple instances.</li>
</ul>
</div>
<div class="section level4">
<h4 id="how-sagemaker-implements-data-parallelism-for-xgboost">How SageMaker implements data parallelism for XGBoost<a class="anchor" aria-label="anchor" href="#how-sagemaker-implements-data-parallelism-for-xgboost"></a>
</h4>
<ul>
<li>When <code>instance_count &gt; 1</code>, SageMaker automatically
splits the dataset across instances.<br>
</li>
<li>Each instance trains on a subset of the data, computing gradient
updates in parallel.<br>
</li>
<li>Gradient updates are synchronized across instances before the next
iteration.<br>
</li>
<li>The final trained model is assembled as if it had been trained on
the full dataset.</li>
</ul>
</div>
</div>
<div class="section level3">
<h3 id="when-to-consider-multiple-instances">When to consider multiple instances<a class="anchor" aria-label="anchor" href="#when-to-consider-multiple-instances"></a>
</h3>
<p>Using multiple instances makes sense when:<br>
- Dataset size – The dataset is large and doesn’t fit comfortably in
memory.<br>
- Expected training time – A single instance takes too long (e.g.,
&gt;10 hours).<br>
- Need for faster training – Parallelization can speed up training but
introduces communication overhead.</p>
<p>If scaling to multiple instances, monitoring training time and
efficiency is critical. In many cases, a single, more powerful instance
may be more cost-effective than multiple smaller ones.</p>
</div>
<div class="section level3">
<h3 id="implementing-distributed-training-with-xgboost-in-sagemaker">Implementing distributed training with XGBoost in SageMaker<a class="anchor" aria-label="anchor" href="#implementing-distributed-training-with-xgboost-in-sagemaker"></a>
</h3>
<p>In SageMaker, setting up distributed training for XGBoost can offer
significant time savings as dataset sizes and computational requirements
increase. Here’s how you can configure it:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Select multiple instances</strong>: Specify
<code>instance_count &gt; 1</code> in the SageMaker
<code>Estimator</code> to enable distributed training.</li>
<li>
<strong>Optimize instance type</strong>: Choose an instance type
suitable for your dataset size and XGBoost requirements</li>
<li>
<strong>Monitor for speed improvements</strong>: With larger
datasets, distributed training can yield time savings by scaling
horizontally. However, gains may vary depending on the dataset and
computation per instance.</li>
</ol>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Define instance type/count we'll use for training</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.m5.large"</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>instance_count<span class="op">=</span><span class="dv">1</span> <span class="co"># always start with 1. Rarely is parallelized training justified with data &lt; 50 GB.</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co"># Define the XGBoost estimator for distributed training</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>xgboost_estimator <span class="op">=</span> Estimator(</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>    image_uri<span class="op">=</span>sagemaker.image_uris.retrieve(<span class="st">"xgboost"</span>, session.boto_region_name, version<span class="op">=</span><span class="st">"1.5-1"</span>),</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,  <span class="co"># Start with 1 instance for baseline</span></span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type,</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>    output_path<span class="op">=</span>output_path,</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>)</span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a>xgboost_estimator.set_hyperparameters(</span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a>    eta<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a>    subsample<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb18-22"><a href="#cb18-22" tabindex="-1"></a>    colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb18-23"><a href="#cb18-23" tabindex="-1"></a>    num_round<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb18-24"><a href="#cb18-24" tabindex="-1"></a>)</span>
<span id="cb18-25"><a href="#cb18-25" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" tabindex="-1"></a><span class="co"># Specify input data from S3</span></span>
<span id="cb18-27"><a href="#cb18-27" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(train_s3_path, content_type<span class="op">=</span><span class="st">"csv"</span>)</span>
<span id="cb18-28"><a href="#cb18-28" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" tabindex="-1"></a><span class="co"># Run with 1 instance</span></span>
<span id="cb18-30"><a href="#cb18-30" tabindex="-1"></a>start1 <span class="op">=</span> t.time()</span>
<span id="cb18-31"><a href="#cb18-31" tabindex="-1"></a>xgboost_estimator.fit({<span class="st">"train"</span>: train_input})</span>
<span id="cb18-32"><a href="#cb18-32" tabindex="-1"></a>end1 <span class="op">=</span> t.time()</span>
<span id="cb18-33"><a href="#cb18-33" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" tabindex="-1"></a><span class="co"># Now run with 2 instances to observe speedup</span></span>
<span id="cb18-36"><a href="#cb18-36" tabindex="-1"></a>xgboost_estimator.instance_count <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb18-37"><a href="#cb18-37" tabindex="-1"></a>start2 <span class="op">=</span> t.time()</span>
<span id="cb18-38"><a href="#cb18-38" tabindex="-1"></a>xgboost_estimator.fit({<span class="st">"train"</span>: train_input})</span>
<span id="cb18-39"><a href="#cb18-39" tabindex="-1"></a>end2 <span class="op">=</span> t.time()</span>
<span id="cb18-40"><a href="#cb18-40" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end1 <span class="op">-</span> start1<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-42"><a href="#cb18-42" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end2 <span class="op">-</span> start2<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>xgboost_estimator<span class="sc">.</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="why-scaling-instances-might-not-show-speedup-here">Why scaling instances might not show speedup here<a class="anchor" aria-label="anchor" href="#why-scaling-instances-might-not-show-speedup-here"></a>
</h3>
<ul>
<li><p>Small dataset: With only 892 rows, the dataset might be too small
to benefit from distributed training. Distributing small datasets often
adds overhead (like network communication between instances), which
outweighs the parallel processing benefits.</p></li>
<li><p>Distributed overhead: Distributed training introduces
coordination steps that can add latency. For very short training jobs,
this overhead can become a larger portion of the total training time,
reducing the benefit of additional instances.</p></li>
<li><p>Tree-based models: Tree-based models, like those in XGBoost,
don’t benefit from distributed scaling as much as deep learning models
when datasets are small. For large datasets, distributed XGBoost can
still offer speedups, but this effect is generally less than with neural
networks, where parallel gradient updates across multiple instances
become efficient.</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="when-multi-instance-training-helps">When multi-instance training helps<a class="anchor" aria-label="anchor" href="#when-multi-instance-training-helps"></a>
</h3>
<ul>
<li><p>Larger datasets: Multi-instance training shines with larger
datasets, where splitting the data across instances and processing it in
parallel can significantly reduce the training time.</p></li>
<li><p>Complex models: For highly complex models with many parameters
(like deep learning models or large XGBoost ensembles) and long training
times, distributing the training can help speed up the process as each
instance contributes to the gradient calculation and optimization
steps.</p></li>
<li><p>Distributed algorithms: XGBoost has a built-in distributed
training capability, but models that perform gradient descent, like deep
neural networks, gain more obvious benefits because each instance can
compute gradients for a batch of data simultaneously, allowing faster
convergence.</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="for-cost-optimization">For cost optimization<a class="anchor" aria-label="anchor" href="#for-cost-optimization"></a>
</h3>
<ul>
<li>Single-instance training is typically more cost-effective for small
or moderately sized datasets, while multi-instance setups can reduce
wall-clock time for larger datasets and complex models, at a higher
instance cost.</li>
<li>Increase instance count only if training time becomes prohibitive
even with more powerful single instances, while being mindful of
communication overhead and scaling efficiency.</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>
<strong>Environment initialization</strong>: Setting up a SageMaker
session, defining roles, and specifying the S3 bucket are essential for
managing data and running jobs in SageMaker.</li>
<li>
<strong>Local vs. managed training</strong>: Always test your code
locally (on a smaller scale) before scaling things up. This avoids
wasting resources on buggy code that doesn’t produce reliable
results.</li>
<li>
<strong>Estimator classes</strong>: SageMaker provides
framework-specific Estimator classes (e.g., XGBoost, PyTorch, SKLearn)
to streamline training setups, each suited to different model types and
workflows.</li>
<li>
<strong>Custom scripts vs. built-in images</strong>: Custom training
scripts offer flexibility with preprocessing and custom logic, while
built-in images are optimized for rapid deployment and simpler
setups.</li>
<li>
<strong>Training data channels</strong>: Using
<code>TrainingInput</code> ensures SageMaker manages data efficiently,
especially for distributed setups where data needs to be synchronized
across multiple instances.</li>
<li>
<strong>Distributed training options</strong>: Data parallelism
(splitting data across instances) is common for many models, while model
parallelism (splitting the model across instances) is useful for very
large models that exceed instance memory.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></section><section id="aio-Training-models-in-SageMaker-notebooks-part2"><p>Content from <a href="Training-models-in-SageMaker-notebooks-part2.html">Training Models in SageMaker: PyTorch Example</a></p>
<hr>
<p>Last updated on 2025-10-09 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Training-models-in-SageMaker-notebooks-part2.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>When should you consider using a GPU instance for training neural
networks in SageMaker, and what are the benefits and limitations?</li>
<li>How does SageMaker handle data parallelism and model parallelism,
and which is suitable for typical neural network training?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Preprocess the Titanic dataset for efficient training using
PyTorch.</li>
<li>Save and upload training and validation data in <code>.npz</code>
format to S3.</li>
<li>Understand the trade-offs between CPU and GPU training for smaller
datasets.</li>
<li>Deploy a PyTorch model to SageMaker and evaluate instance types for
training performance.</li>
<li>Differentiate between data parallelism and model parallelism, and
determine when each is appropriate in SageMaker.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="initial-setup-open-prefilled--ipynb-notebook">Initial setup: open prefilled .ipynb notebook<a class="anchor" aria-label="anchor" href="#initial-setup-open-prefilled--ipynb-notebook"></a>
</h2>
<hr class="half-width">
<p>Open the notebook from:
<code>/ML_with_AWS_SageMaker/notebooks/Training-models-in-SageMaker-notebooks-part2.ipynb</code>.
Select the <strong>pytorch environment</strong>.</p>
</section><section><h2 class="section-heading" id="setup-notebook-as-controller">Setup notebook as controller<a class="anchor" aria-label="anchor" href="#setup-notebook-as-controller"></a>
</h2>
<hr class="half-width">
<p>Once your notebook is open, we can setup our SageMaker controller as
usual:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Initialize the SageMaker role (will reflect notebook instance's policy)</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>role <span class="op">=</span> sagemaker.get_execution_role()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'role = </span><span class="sc">{</span>role<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co"># Initialize an S3 client to interact with Amazon S3, allowing operations like uploading, downloading, and managing objects and buckets.</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>s3 <span class="op">=</span> boto3.client(<span class="st">'s3'</span>)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co"># Define the S3 bucket that we will load from</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">'sinkorswim-doejohn-titanic'</span>  <span class="co"># replace with your S3 bucket name</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Define train/test filenames</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>train_filename <span class="op">=</span> <span class="st">'titanic_train.csv'</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>test_filename <span class="op">=</span> <span class="st">'titanic_test.csv'</span></span></code></pre>
</div>
<p>Create a SageMaker session to manage interactions with Amazon
SageMaker, such as training jobs, model deployments, and data
input/output.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span> <span class="co"># United States (Ohio). Make sure this matches what you see near top right of AWS Console menu</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>boto_session <span class="op">=</span> boto3.Session(region_name<span class="op">=</span>region) <span class="co"># Create a Boto3 session that ensures all AWS service calls (including SageMaker) use the specified region</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session(boto_session<span class="op">=</span>boto_session)</span></code></pre>
</div>
<p>We should also record our local instance information to report this
information during testing. First, let’s make sure we’re starting in the
same location to access helper functions</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> AWS_helpers.helpers <span class="im">as</span> helpers</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>notebook_instance_name <span class="op">=</span> <span class="st">'sinkorswim-DoeJohn-TrainClassifier'</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co"># Make sure this matches what you see near top right of AWS Console menu</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span> <span class="co"># United States (Ohio)</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>local_instance_info <span class="op">=</span> helpers.get_notebook_instance_info(notebook_instance_name, region)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>local_instance <span class="op">=</span> local_instance_info[<span class="st">'InstanceType'</span>]</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>local_instance</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="training-a-neural-network-with-sagemaker">Training a neural network with SageMaker<a class="anchor" aria-label="anchor" href="#training-a-neural-network-with-sagemaker"></a>
</h2>
<hr class="half-width">
<p>Let’s see how to do a similar experiment, but this time using PyTorch
neural networks. We will again demonstrate how to test our custom model
train script (train_nn.py) before deploying to SageMaker, and discuss
some strategies (e.g., using a GPU) for improving train time when
needed.</p>
<div class="section level3">
<h3 id="preparing-the-data-compressed-npz-files">Preparing the data (compressed npz files)<a class="anchor" aria-label="anchor" href="#preparing-the-data-compressed-npz-files"></a>
</h3>
<p>When deploying a PyTorch model on SageMaker, it’s helpful to prepare
the input data in a format that’s directly accessible and compatible
with PyTorch’s data handling methods. The next code cell will prep our
npz files from the existing csv versions.</p>
<div id="why-are-we-using-this-file-format" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="why-are-we-using-this-file-format" class="callout-inner">
<h3 class="callout-title">Why are we using this file format?</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li><p><strong>Optimized data loading</strong>:<br>
The <code>.npz</code> format stores arrays in a compressed, binary
format, making it efficient for both storage and loading. PyTorch can
easily handle <code>.npz</code> files, especially in batch processing,
without requiring complex data transformations during training.</p></li>
<li><p><strong>Batch compatibility</strong>:<br>
When training neural networks in PyTorch, it’s common to load data in
batches. By storing data in an <code>.npz</code> file, we can quickly
load the entire dataset or specific parts (e.g., <code>X_train</code>,
<code>y_train</code>) into memory and feed it to the PyTorch
<code>DataLoader</code>, enabling efficient batched data
loading.</p></li>
<li><p><strong>Reduced I/O overhead in SageMaker</strong>:<br>
Storing data in <code>.npz</code> files minimizes the I/O operations
during training, reducing time spent on data handling. This is
especially beneficial in cloud environments like SageMaker, where
efficient data handling directly impacts training costs and
performance.</p></li>
<li><p><strong>Consistency and compatibility</strong>:<br>
Using <code>.npz</code> files allows us to ensure consistency between
training and validation datasets. Each file (<code>train_data.npz</code>
and <code>val_data.npz</code>) stores the arrays in a standardized way
that can be easily accessed by keys (<code>X_train</code>,
<code>y_train</code>, <code>X_val</code>, <code>y_val</code>). This
structure is compatible with PyTorch’s <code>Dataset</code> class,
making it straightforward to design custom datasets for
training.</p></li>
<li><p><strong>Support for multiple data types</strong>:<br><code>.npz</code> files support storage of multiple arrays within a
single file. This is helpful for organizing features and labels without
additional code. Here, the <code>train_data.npz</code> file contains
both <code>X_train</code> and <code>y_train</code>, keeping everything
related to training data in one place. Similarly,
<code>val_data.npz</code> organizes validation features and labels,
simplifying file management.</p></li>
</ol>
<p>In summary, saving the data in <code>.npz</code> files ensures a
smooth workflow from data loading to model training in PyTorch,
leveraging SageMaker’s infrastructure for a more efficient, structured
training process.</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, LabelEncoder</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co"># Load and preprocess the Titanic dataset</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(train_filename)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co"># Encode categorical variables and normalize numerical ones</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>df[<span class="st">'Sex'</span>] <span class="op">=</span> LabelEncoder().fit_transform(df[<span class="st">'Sex'</span>])</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>df[<span class="st">'Embarked'</span>] <span class="op">=</span> df[<span class="st">'Embarked'</span>].fillna(<span class="st">'S'</span>)  <span class="co"># Fill missing values in 'Embarked'</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>df[<span class="st">'Embarked'</span>] <span class="op">=</span> LabelEncoder().fit_transform(df[<span class="st">'Embarked'</span>])</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co"># Fill missing values for 'Age' and 'Fare' with median</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>df[<span class="st">'Age'</span>] <span class="op">=</span> df[<span class="st">'Age'</span>].fillna(df[<span class="st">'Age'</span>].median())</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>df[<span class="st">'Fare'</span>] <span class="op">=</span> df[<span class="st">'Fare'</span>].fillna(df[<span class="st">'Fare'</span>].median())</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co"># Select features and target</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Pclass'</span>, <span class="st">'Sex'</span>, <span class="st">'Age'</span>, <span class="st">'SibSp'</span>, <span class="st">'Parch'</span>, <span class="st">'Fare'</span>, <span class="st">'Embarked'</span>]].values</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Survived'</span>].values</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="co"># Normalize features (helps avoid exploding/vanishing gradients)</span></span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>X <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a><span class="co"># Save the preprocessed data to our local jupyter environment</span></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a>np.savez(<span class="st">'train_data.npz'</span>, X_train<span class="op">=</span>X_train, y_train<span class="op">=</span>y_train)</span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>np.savez(<span class="st">'val_data.npz'</span>, X_val<span class="op">=</span>X_val, y_val<span class="op">=</span>y_val)</span></code></pre>
</div>
<p>Next, we will upload our compressed files to our S3 bucket. Storage
is farily cheap on AWS (around $0.023 per GB per month), but be mindful
of uploading too much data. It may be convenient to store a preprocessed
version of the data at times, but try not to store too many versions
that aren’t being actively used.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>train_file <span class="op">=</span> <span class="st">"train_data.npz"</span>  <span class="co"># Local file path in your notebook environment</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>val_file <span class="op">=</span> <span class="st">"val_data.npz"</span>  <span class="co"># Local file path in your notebook environment</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co"># Initialize the S3 client</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>s3 <span class="op">=</span> boto3.client(<span class="st">'s3'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co"># Upload the training and validation files to S3</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>s3.upload_file(train_file, bucket_name, <span class="ss">f"</span><span class="sc">{</span>train_file<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>s3.upload_file(val_file, bucket_name, <span class="ss">f"</span><span class="sc">{</span>val_file<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Files successfully uploaded to S3."</span>)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="testing-on-notebook-instance">Testing on notebook instance<a class="anchor" aria-label="anchor" href="#testing-on-notebook-instance"></a>
</h2>
<hr class="half-width">
<p>You should always test code thoroughly before scaling up and using
more resources. Here, we will test our script using a small number of
epochs — just to verify our setup is correct.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> t <span class="co"># Measure training time locally</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>start_time <span class="op">=</span> t.time()</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="op">%</span>run  AWS_helpers<span class="op">/</span>train_nn.py <span class="op">--</span>train train_data.npz <span class="op">--</span>val val_data.npz <span class="op">--</span>epochs {epochs} <span class="op">--</span>learning_rate {learning_rate}</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Local training time: </span><span class="sc">{</span>t<span class="sc">.</span>time() <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type = </span><span class="sc">{</span>local_instance<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="deploying-pytorch-neural-network-via-sagemaker">Deploying PyTorch neural network via SageMaker<a class="anchor" aria-label="anchor" href="#deploying-pytorch-neural-network-via-sagemaker"></a>
</h2>
<hr class="half-width">
<p>Now that we have tested things locally, we can try to train with a
larger number of epochs and a better instance selected. We can do this
easily by invoking the PyTorch estimator. Our notebook is currently
configured to use ml.m5.large. We can upgrade this to
<code>ml.m5.xlarge</code> with the below code (using our notebook as a
controller).</p>
<p><strong>Should we use a GPU?</strong>: Since this dataset is farily
small, we don’t necessarily need a GPU for training. Considering costs,
the m5.xlarge is <code>$0.17/hour</code>, while the cheapest GPU
instance is <code>$0.75/hour</code>. However, for larger datasets (&gt;
1 GB) and models, we may want to consider a GPU if training time becomes
cumbersome (see <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">Instances
for ML</a>. If that doesn’t work, we can try distributed computing
(setting instance &gt; 1). More on this in the next section.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> sagemaker.pytorch <span class="im">import</span> PyTorch</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="im">from</span> sagemaker.inputs <span class="im">import</span> TrainingInput</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>instance_count <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.m5.large"</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>output_path <span class="op">=</span> <span class="ss">f's3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/output_nn/'</span> <span class="co"># this folder will auto-generate if it doesn't exist already</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># Define max runtime in seconds to ensure you don't use more compute time than expected. Use a generous threshold (2x expected time but &lt; 2 days) so that work isn't interrupted without any gains.</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>max_run <span class="op">=</span> <span class="dv">2</span><span class="op">*</span><span class="dv">60</span><span class="op">*</span><span class="dv">60</span> <span class="co"># 2 hours</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co"># Define the PyTorch estimator and pass hyperparameters as arguments</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>pytorch_estimator <span class="op">=</span> PyTorch(</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    entry_point<span class="op">=</span><span class="st">"AWS_helpers/train_nn.py"</span>,</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type, <span class="co"># with this small dataset, we don't recessarily need a GPU for fast training. </span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,  <span class="co"># Distributed training with two instances</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    framework_version<span class="op">=</span><span class="st">"1.9"</span>,</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py38"</span>,</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>    output_path<span class="op">=</span>output_path,</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    hyperparameters<span class="op">=</span>{</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"/opt/ml/input/data/train/train_data.npz"</span>,  <span class="co"># SageMaker will mount this path</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>        <span class="st">"val"</span>: <span class="st">"/opt/ml/input/data/val/val_data.npz"</span>,        <span class="co"># SageMaker will mount this path</span></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>        <span class="st">"epochs"</span>: epochs,</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>        <span class="st">"learning_rate"</span>: learning_rate</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>    }</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>)</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a><span class="co"># Define input paths</span></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/train_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>val_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/val_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a><span class="co"># Start the training job and time it</span></span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a>start <span class="op">=</span> t.time()</span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a>pytorch_estimator.fit({<span class="st">"train"</span>: train_input, <span class="st">"val"</span>: val_input})</span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>end <span class="op">=</span> t.time()</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="deploying-pytorch-neural-network-via-sagemaker-with-a-gpu-instance">Deploying PyTorch neural network via SageMaker with a GPU
instance<a class="anchor" aria-label="anchor" href="#deploying-pytorch-neural-network-via-sagemaker-with-a-gpu-instance"></a>
</h2>
<hr class="half-width">
<p>In this section, we’ll implement the same procedure as above, but
using a GPU-enabled instance for potentially faster training. While GPU
instances are more expensive, they can be cost-effective for larger
datasets or more complex models that require significant computational
power.</p>
<div class="section level4">
<h4 id="selecting-a-gpu-instance">Selecting a GPU Instance<a class="anchor" aria-label="anchor" href="#selecting-a-gpu-instance"></a>
</h4>
<p>For a small dataset like ours, we don’t strictly need a GPU, but for
larger datasets or more complex models, a GPU can reduce training time.
Here, we’ll select an <code>ml.g4dn.xlarge</code> instance, which
provides a single GPU and costs approximately <code>$0.75/hour</code>
(check <a href="https://docs.google.com/spreadsheets/d/1uPT4ZAYl_onIl7zIjv5oEAdwy4Hdn6eiA9wVfOBbHmY/edit?usp=sharing" class="external-link">Instances
for ML</a> for detailed pricing).</p>
</div>
<div class="section level4">
<h4 id="code-modifications-for-gpu-use">Code modifications for GPU use<a class="anchor" aria-label="anchor" href="#code-modifications-for-gpu-use"></a>
</h4>
<p>Using a GPU requires minor changes in your training script
(<code>train_nn.py</code>). Specifically, you’ll need to: 1. Check for
GPU availability in PyTorch. 2. Move the model and tensors to the GPU
device if available.</p>
</div>
<div class="section level4">
<h4 id="enabling-pytorch-to-use-gpu-in-train_nn-py">Enabling PyTorch to use GPU in <code>train_nn.py</code>
<a class="anchor" aria-label="anchor" href="#enabling-pytorch-to-use-gpu-in-train_nn-py"></a>
</h4>
<p>The following code snippet to enables GPU support in
<code>train_nn.py</code>:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># Set device</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">from</span> sagemaker.pytorch <span class="im">import</span> PyTorch</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="im">from</span> sagemaker.inputs <span class="im">import</span> TrainingInput</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> t</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>instance_count <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.g4dn.xlarge"</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>output_path <span class="op">=</span> <span class="ss">f's3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/output_nn/'</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co"># Define the PyTorch estimator and pass hyperparameters as arguments</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>pytorch_estimator_gpu <span class="op">=</span> PyTorch(</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    entry_point<span class="op">=</span><span class="st">"AWS_helpers/train_nn.py"</span>,</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type,</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    framework_version<span class="op">=</span><span class="st">"1.9"</span>,</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py38"</span>,</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>    output_path<span class="op">=</span>output_path,</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    hyperparameters<span class="op">=</span>{</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"/opt/ml/input/data/train/train_data.npz"</span>,</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>        <span class="st">"val"</span>: <span class="st">"/opt/ml/input/data/val/val_data.npz"</span>,</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>        <span class="st">"epochs"</span>: epochs,</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>        <span class="st">"learning_rate"</span>: learning_rate</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    }</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>)</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a><span class="co"># Define input paths</span></span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/train_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>val_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/val_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a><span class="co"># Start the training job and time it</span></span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>start <span class="op">=</span> t.time()</span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>pytorch_estimator_gpu.fit({<span class="st">"train"</span>: train_input, <span class="st">"val"</span>: val_input})</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>end <span class="op">=</span> t.time()</span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div id="gpus-can-be-slow-for-small-datasetsmodels" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="gpus-can-be-slow-for-small-datasetsmodels" class="callout-inner">
<h3 class="callout-title">GPUs can be slow for small
datasets/models</h3>
<div class="callout-content">
<p>This performance discrepancy might be due to the following
factors:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Small Ddtaset/model size</strong>: When datasets and
models are small, the overhead of transferring data between the CPU and
GPU, as well as managing the GPU, can actually slow things down. For
very small models and datasets, CPUs are often faster since there’s
minimal data to process.</p></li>
<li><p><strong>GPU initialization overhead</strong>: Every time a
training job starts on a GPU, there’s a small overhead for initializing
CUDA libraries. For short jobs, this setup time can make the GPU appear
slower overall.</p></li>
<li><p><strong>Batch size</strong>: GPUs perform best with larger batch
sizes since they can process many data points in parallel. If the batch
size is too small, the GPU is underutilized, leading to suboptimal
performance. You may want to try increasing the batch size to see if
this reduces training time.</p></li>
<li><p><strong>Instance type</strong>: Some GPU instances, like the
<code>ml.g4dn</code> series, have less computational power than the
larger <code>p3</code> series. They’re better suited for inference or
lightweight tasks rather than intense training, so a more powerful
instance (e.g., <code>ml.p3.2xlarge</code>) could help for larger
tasks.</p></li>
</ol>
<p>If training time continues to be critical, sticking with a CPU
instance may be the best approach for smaller datasets. For larger, more
complex models and datasets, the GPU’s advantages should become more
apparent.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="distributed-training-for-neural-networks-in-sagemaker">Distributed Training for Neural Networks in SageMaker<a class="anchor" aria-label="anchor" href="#distributed-training-for-neural-networks-in-sagemaker"></a>
</h2>
<hr class="half-width">
<p>In the event that you do need distributed computing to achieve
reasonable train times (remember to try an upgraded instance first!),
simply adjust the instance count to a number between 2 and 5. Beyond 5
instances, you’ll see diminishing returns and may be needlessly spending
extra money/compute-energy.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">from</span> sagemaker.pytorch <span class="im">import</span> PyTorch</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="im">from</span> sagemaker.inputs <span class="im">import</span> TrainingInput</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> t</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>instance_count <span class="op">=</span> <span class="dv">2</span> <span class="co"># increasing to 2 to see if it has any benefit (likely won't see any with this small dataset)</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.m5.xlarge"</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>output_path <span class="op">=</span> <span class="ss">f's3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/output_nn/'</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co"># Define the PyTorch estimator and pass hyperparameters as arguments</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>pytorch_estimator <span class="op">=</span> PyTorch(</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>    entry_point<span class="op">=</span><span class="st">"AWS_helpers/train_nn.py"</span>,</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type, <span class="co"># with this small dataset, we don't recessarily need a GPU for fast training. </span></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,  <span class="co"># Distributed training with two instances</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>    framework_version<span class="op">=</span><span class="st">"1.9"</span>,</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py38"</span>,</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>    output_path<span class="op">=</span>output_path,</span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>    hyperparameters<span class="op">=</span>{</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"/opt/ml/input/data/train/train_data.npz"</span>,  <span class="co"># SageMaker will mount this path</span></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>        <span class="st">"val"</span>: <span class="st">"/opt/ml/input/data/val/val_data.npz"</span>,        <span class="co"># SageMaker will mount this path</span></span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a>        <span class="st">"epochs"</span>: epochs,</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>        <span class="st">"learning_rate"</span>: learning_rate</span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>    }</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>)</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a><span class="co"># Define input paths</span></span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/train_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>val_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/val_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a><span class="co"># Start the training job and time it</span></span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>start <span class="op">=</span> t.time()</span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a>pytorch_estimator.fit({<span class="st">"train"</span>: train_input, <span class="st">"val"</span>: val_input})</span>
<span id="cb11-36"><a href="#cb11-36" tabindex="-1"></a>end <span class="op">=</span> t.time()</span>
<span id="cb11-37"><a href="#cb11-37" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Runtime for training on SageMaker: </span><span class="sc">{</span>end <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss"> seconds, instance_type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, instance_count: </span><span class="sc">{</span>instance_count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div class="section level3">
<h3 id="distributed-training-for-neural-nets-how-epochs-are-managed">Distributed training for neural nets: how epochs are managed<a class="anchor" aria-label="anchor" href="#distributed-training-for-neural-nets-how-epochs-are-managed"></a>
</h3>
<p>Amazon SageMaker provides two main strategies for distributed
training: <strong>data parallelism</strong> and <strong>model
parallelism</strong>. Understanding which strategy will be used depends
on the model size and the configuration of your SageMaker training job,
as well as the default settings of the specific SageMaker Estimator you
are using.</p>
<div class="section level4">
<h4 id="data-parallelism-most-common-for-mini-batch-sgd">1. <strong>Data parallelism (most common for mini-batch
SGD)</strong>
<a class="anchor" aria-label="anchor" href="#data-parallelism-most-common-for-mini-batch-sgd"></a>
</h4>
<ul>
<li>
<strong>How it works</strong>: In data parallelism, each instance in
the cluster (e.g., multiple <code>ml.m5.xlarge</code> instances)
maintains a <strong>complete copy of the model</strong>. The
<strong>training dataset is split across instances</strong>, and each
instance processes a different subset of data simultaneously. This
enables multiple instances to complete forward and backward passes on
different data batches independently.</li>
<li>
<strong>Epoch distribution</strong>: Even though each instance
processes all the specified epochs, they only work on a portion of the
dataset for each epoch. After each batch, instances synchronize their
gradient updates across all instances using a method such as
<em>all-reduce</em>. This ensures that while each instance is working
with a unique data batch, the model weights remain consistent across
instances.</li>
<li>
<strong>Key insight</strong>: Because all instances process the
specified number of epochs and synchronize weight updates between
batches, each instance’s training contributes to a cohesive, shared
model. The <strong>effective epoch count across instances appears to be
shared</strong> because data parallelism allows each instance to handle
a fraction of the data per epoch, not the epochs themselves. Data
parallelism is well-suited for models that can fit into a single
instance’s memory and benefit from increased data throughput.</li>
</ul>
</div>
<div class="section level4">
<h4 id="model-parallelism-best-for-large-models">2. <strong>Model parallelism (best for large models)</strong>
<a class="anchor" aria-label="anchor" href="#model-parallelism-best-for-large-models"></a>
</h4>
<ul>
<li>
<strong>How it works</strong>: Model parallelism divides the model
itself across multiple instances, not the data. This approach is best
suited for very large models that cannot fit into a single GPU or
instance’s memory (e.g., large language models).</li>
<li>
<strong>Epoch distribution</strong>: The model is partitioned so
that each instance is responsible for specific layers or components.
Data flows sequentially through these partitions, where each instance
processes a part of each batch and passes it to the next instance.</li>
<li>
<strong>Key insight</strong>: This approach is more complex due to
the dependency between model components, so <strong>synchronization
occurs across the model layers rather than across data batches</strong>.
Model parallelism generally suits scenarios with exceptionally large
model architectures that exceed memory limits of typical instances.</li>
</ul>
</div>
</div>
<div class="section level3">
<h3 id="determining-which-distributed-training-strategy-is-used">Determining which distributed training strategy is used<a class="anchor" aria-label="anchor" href="#determining-which-distributed-training-strategy-is-used"></a>
</h3>
<p>SageMaker will select the distributed strategy based on:</p>
<ul>
<li>
<strong>Framework and Estimator configuration</strong>: Most deep
learning frameworks in SageMaker default to data parallelism, especially
when using PyTorch or TensorFlow with standard configurations.</li>
<li>
<strong>Model and data size</strong>: If you specify a model that
exceeds a single instance’s memory capacity, SageMaker may switch to
model parallelism if configured for it.</li>
<li>
<strong>Instance count</strong>: When you specify
<code>instance_count &gt; 1</code> in your Estimator with a deep
learning model, SageMaker will use data parallelism by default unless
explicitly configured for model parallelism.</li>
</ul>
<p>You observed that each instance ran all epochs with
<code>instance_count=2</code> and 10,000 epochs, which aligns with data
parallelism. Here, each instance processed the full set of epochs
independently, but each batch of data was different, and the gradient
updates were synchronized across instances.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>
<strong>Efficient data handling</strong>: The <code>.npz</code>
format is optimized for efficient loading, reducing I/O overhead and
enabling batch compatibility for PyTorch’s <code>DataLoader</code>.</li>
<li>
<strong>GPU training</strong>: While beneficial for larger models or
datasets, GPUs may introduce overhead for smaller tasks; selecting the
right instance type is critical for cost-efficiency.</li>
<li>
<strong>Data parallelism vs. model parallelism</strong>: Data
parallelism splits data across instances and synchronizes model weights,
suitable for typical neural network tasks. Model parallelism, which
divides model layers, is ideal for very large models that exceed memory
capacity.</li>
<li>
<strong>SageMaker configuration</strong>: By adjusting instance
counts and types, SageMaker supports scalable training setups. Starting
with CPU training and scaling as needed with GPUs or distributed setups
allows for performance optimization.</li>
<li>
<strong>Testing locally first</strong>: Before deploying large-scale
training in SageMaker, test locally with a smaller setup to ensure code
correctness and efficient resource usage.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></section><section id="aio-Hyperparameter-tuning"><p>Content from <a href="Hyperparameter-tuning.html">Hyperparameter Tuning in SageMaker: Neural Network Example</a></p>
<hr>
<p>Last updated on 2025-10-10 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Hyperparameter-tuning.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we efficiently manage hyperparameter tuning in
SageMaker?</li>
<li>How can we parallelize tuning jobs to optimize time without
increasing costs?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Set up and run a hyperparameter tuning job in SageMaker.</li>
<li>Define <code>ContinuousParameter</code> and
<code>CategoricalParameter</code> for targeted tuning.</li>
<li>Log and capture objective metrics for evaluating tuning
success.</li>
<li>Optimize tuning setup to balance cost and efficiency, including
parallelization.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="initial-setup-open-prefilled--ipynb-notebook">Initial setup: open prefilled .ipynb notebook<a class="anchor" aria-label="anchor" href="#initial-setup-open-prefilled--ipynb-notebook"></a>
</h2>
<hr class="half-width">
<p>Open the notebook from:
<code>/ML_with_AWS_SageMaker/notebooks/Hyperparameter-tuning.ipynb</code>.
Select the <strong>pytorch environment</strong>.</p>
</section><section><h2 class="section-heading" id="hyperparameter-tuning-in-sagemaker">Hyperparameter tuning in SageMaker<a class="anchor" aria-label="anchor" href="#hyperparameter-tuning-in-sagemaker"></a>
</h2>
<hr class="half-width">
<p>To conduct efficient hyperparameter tuning with neural networks (or
any model) in SageMaker, we’ll leverage SageMaker’s
<strong>hyperparameter tuning jobs</strong> while carefully managing
parameter ranges and model count. Here’s an overview of the process,
with a focus on both efficiency and cost-effectiveness.</p>
<div class="section level3">
<h3 id="key-steps">Key steps<a class="anchor" aria-label="anchor" href="#key-steps"></a>
</h3>
<p>The overall process involves these five below steps.</p>
<ol style="list-style-type: decimal">
<li>Setup estimator</li>
<li>Define parameter ranges</li>
<li>Set up HyperParamterTuner object</li>
<li>Prepare training script to log metrics</li>
<li>Set data paths and launch tuner.fit()</li>
<li>Monitor tuning job from SageMaker console</li>
<li>Extract best model for final evaluation</li>
</ol>
<div class="section level4">
<h4 id="code-example-for-sagemaker-hyperparameter-tuning-with-neural-networks">Code example for SageMaker hyperparameter tuning with neural
networks<a class="anchor" aria-label="anchor" href="#code-example-for-sagemaker-hyperparameter-tuning-with-neural-networks"></a>
</h4>
<p>We’ll walk through each step in detail by tuning a neural network.
Specifcially, we will test out different values for our
<code>epochs</code> and <code>learning_rate</code> parameters. We are
sticking to just two hyperparameters for demonstration purposes, but you
may wish to explore additional parameters in your own work.</p>
<p>This setup provides:</p>
<ul>
<li>
<strong>Explicit control</strong> over <code>epochs</code> using
<code>CategoricalParameter</code>, allowing targeted testing of specific
values.</li>
<li>
<strong>Efficient sampling</strong> for <code>learning_rate</code>
using <code>ContinuousParameter</code>, covering a defined range for a
balanced approach.</li>
<li>
<strong>Cost control</strong> by setting moderate
<code>max_jobs</code> and <code>max_parallel_jobs</code>.</li>
</ul>
<p>By managing these settings and configuring metrics properly, you can
achieve a balanced and efficient approach to hyperparameter tuning for
neural networks.</p>
</div>
<div class="section level4">
<h4 id="directory-setup">0. Directory setup<a class="anchor" aria-label="anchor" href="#directory-setup"></a>
</h4>
<p>Just to make we are all on the same directory starting point, let’s
cd to our instance’s root directory</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>ec2<span class="op">-</span>user<span class="op">/</span>SageMaker<span class="op">/</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="setup-estimator">1. Setup estimator<a class="anchor" aria-label="anchor" href="#setup-estimator"></a>
</h4>
<p>To kick off our hyperparameter tuning for a neural network model,
we’ll start by defining the <strong>SageMaker Estimator</strong>. The
estimator setup here is very similar to our previous episode, where we
used it to configure and train a model directly. However, this time,
rather than directly running a training job with the estimator, we’ll be
using it as the foundation for <strong>hyperparameter
tuning</strong>.</p>
<p>In SageMaker, the estimator serves as a blueprint for each tuning
job, specifying the training script, instance type, and key parameters
like data paths and metrics. Once defined, this estimator will be passed
to a <strong>Hyperparameter Tuner</strong> that manages the creation of
multiple training jobs with various hyperparameter combinations, helping
us find an optimal configuration.</p>
<p>Here’s the setup for our PyTorch estimator, which includes specifying
the entry script for training (<code>train_nn.py</code>) and defining
hyperparameters that will remain fixed across tuning jobs. The
hyperparameters we’re setting up to tune include <code>epochs</code> and
<code>learning_rate</code>, with a few specific values or ranges
defined:</p>
<p>We’ll use our notebook instance name again to label the training jobs
launched in this episode</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>notebook_instance_name <span class="op">=</span> <span class="st">'sinkorswim-DoeJohn-TrainClassifier'</span> <span class="co"># adjust to your notebook name. we'll use this variable to name the training jobs launched by the tuner.</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># the following code just verifies you have the right name for your notebook instance</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span> <span class="co"># United States (Ohio) —  make sure this matches what you see near top right of AWS Console menu</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>sagemaker_client <span class="op">=</span> boto3.client(<span class="st">'sagemaker'</span>, region_name<span class="op">=</span>region) <span class="co"># Initialize SageMaker client</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>response <span class="op">=</span> sagemaker_client.describe_notebook_instance(NotebookInstanceName<span class="op">=</span>notebook_instance_name) <span class="co"># Describe the notebook instance</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># Display the status and instance type</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Notebook Instance '</span><span class="sc">{</span>notebook_instance_name<span class="sc">}</span><span class="ss">' status: </span><span class="sc">{</span>response[<span class="st">'NotebookInstanceStatus'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>local_instance <span class="op">=</span> response[<span class="st">'InstanceType'</span>]</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Instance Type: </span><span class="sc">{</span>local_instance<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>Next, we’ll configure the baseline estimator that we plan to do
hyperparameter search on.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> sagemaker.tuner <span class="im">import</span> HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="im">from</span> sagemaker.pytorch <span class="im">import</span> PyTorch</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="im">from</span> sagemaker.inputs <span class="im">import</span> TrainingInput</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co"># Initialize role, bucket, and SageMaker session variables</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>role <span class="op">=</span> get_execution_role()</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">'sinkorswim-doejohn-titanic'</span>  <span class="co"># replace with your S3 bucket name</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span> <span class="co"># United States (Ohio). Make sure this matches what you see near top right of AWS Console menu</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>boto_session <span class="op">=</span> boto3.Session(region_name<span class="op">=</span>region) <span class="co"># Create a Boto3 session that ensures all AWS service calls (including SageMaker) use the specified region</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session(boto_session<span class="op">=</span>boto_session)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co"># Define instance type/count we'll use for training</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>instance_type<span class="op">=</span><span class="st">"ml.m5.large"</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>instance_count<span class="op">=</span><span class="dv">1</span> <span class="co"># always start with 1. Rarely is parallelized training justified with data &lt; 50 GB. More on this later.</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co"># Define max runtime in seconds to ensure you don't use more compute time than expected. Use a generous threshold (2x expected time but &lt; 2 days) so that work isn't interrupted without any gains.</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>max_run <span class="op">=</span> <span class="dv">2</span><span class="op">*</span><span class="dv">60</span><span class="op">*</span><span class="dv">60</span> <span class="co"># 2 hours</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co"># Define the PyTorch estimator with entry script and environment details</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>pytorch_estimator <span class="op">=</span> PyTorch(</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    base_job_name<span class="op">=</span>notebook_instance_name, <span class="co"># adjust to your notebook name,</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>    max_run<span class="op">=</span>max_run, <span class="co"># in seconds; always include (max 48 hours)</span></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>    entry_point<span class="op">=</span><span class="st">"AWS_helpers/train_nn.py"</span>,  <span class="co"># Your script for training</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type,</span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>    framework_version<span class="op">=</span><span class="st">"1.9"</span>,</span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py38"</span>,</span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a>    metric_definitions<span class="op">=</span>[{<span class="st">"Name"</span>: <span class="st">"validation:accuracy"</span>, <span class="st">"Regex"</span>: <span class="st">"validation:accuracy = ([0-9</span><span class="ch">\\</span><span class="st">.]+)"</span>}],</span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a>    hyperparameters<span class="op">=</span>{</span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a>        <span class="st">"train"</span>: <span class="st">"/opt/ml/input/data/train/train_data.npz"</span>,  <span class="co"># SageMaker will mount this path</span></span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a>        <span class="st">"val"</span>: <span class="st">"/opt/ml/input/data/val/val_data.npz"</span>,        <span class="co"># SageMaker will mount this path</span></span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a>        <span class="st">"epochs"</span>: <span class="dv">100</span>, <span class="co"># Placeholder initial value. Will be overridden by tuning by tuning values tested</span></span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a>        <span class="st">"learning_rate"</span>: <span class="fl">0.001</span> <span class="co"># Placeholder initial value. Will be overridden by tuning values tested</span></span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a>    },</span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="define-hyperparameter-ranges">2. Define hyperparameter ranges<a class="anchor" aria-label="anchor" href="#define-hyperparameter-ranges"></a>
</h4>
<p>In SageMaker, you must explicitly define ranges for any
hyperparameters you want to tune. SageMaker supports both
<code>ContinuousParameter</code> and <code>CategoricalParameter</code>
types:</p>
<ul>
<li>
<strong><code>ContinuousParameter</code></strong> allows SageMaker
to dynamically sample numeric values within a specified range, making it
ideal for broad, exploratory tuning. The total number of values tested
can be controlled through the upcoming <code>max_jobs</code> parameter,
which defines how many different combinations SageMaker will
evaluate.</li>
<li>
<strong><code>CategoricalParameter</code></strong> specifies exact
values for SageMaker to test, which is useful when you want the model to
only try a specific set of options.</li>
</ul>
<p>By default, SageMaker uses <strong>Bayesian optimization</strong>,
adjusting future selections based on previous results to efficiently
find optimal values. You can also set the <code>strategy</code> to
<strong>“Random”</strong> for uniform sampling across the range, which
is effective in larger or more exploratory search spaces. Random
sampling may end up costing much more in time and resources, however.
Generally, we recommend sticking with the default setting.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Hyperparameter tuning ranges</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>hyperparameter_ranges <span class="op">=</span> {</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    <span class="st">"epochs"</span>: CategoricalParameter([<span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>]),       <span class="co"># Adjust as needed</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    <span class="st">"learning_rate"</span>: ContinuousParameter(<span class="fl">0.001</span>, <span class="fl">0.1</span>),  <span class="co"># Range for continuous values</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="hyperparameter-considerations-in-neural-nets">Hyperparameter considerations in neural nets<a class="anchor" aria-label="anchor" href="#hyperparameter-considerations-in-neural-nets"></a>
</h4>
<p>When tuning hyperparameters in neural networks, it’s essential to
prioritize parameters that directly impact model performance while
remaining mindful of diminishing returns and potential overfitting.
Below are some core hyperparameters to consider and general strategies
for tuning:</p>
<ul>
<li><p><strong>Learning Rate</strong>: Often the most impactful
parameter, learning rate controls the speed of convergence. A smaller
learning rate can lead to more stable, though slower, convergence, while
a larger rate may speed things up but risks overshooting optimal values.
Testing ranges like <code>0.0001</code> to <code>0.1</code> with a
<code>ContinuousParameter</code> is common practice, and
<code>Bayesian</code> search can help home in on ideal values.</p></li>
<li><p><strong>Batch Size</strong>: Larger batch sizes often yield
faster training times and may improve stability, but this can risk
bypassing useful local minima, especially with small datasets. Smaller
batch sizes can capture more nuanced updates but are computationally
expensive. Ranges from <code>16</code> to <code>256</code> are worth
exploring for most use cases, although, for large datasets or
high-capacity models, even larger values may be beneficial.</p></li>
<li><p><strong>Number of Epochs</strong>: While larger epochs allow the
model to learn from data longer, increasing epochs doesn’t always equate
to better performance and can lead to overfitting. Exploring
<code>CategoricalParameter([50, 100, 500, 1000])</code> can help balance
performance without excessive training costs.</p></li>
<li><p><strong>Layer Width and Depth</strong>: Increasing the width or
depth (i.e., number of neurons and layers) can improve model capacity
but also risks overfitting if the dataset is small or lacks variability.
Testing a range of layer sizes or depths (e.g., <code>32, 64, 128</code>
neurons per layer) can reveal whether additional complexity yields
benefits. Notably, understanding <em>double descent</em> is essential
here, as larger networks may initially seem to overfit before
unexpectedly improving in the <em>second descent</em>—a phenomenon worth
investigating in high-capacity networks.</p></li>
<li><p><strong>Regularization Parameters</strong>: Regularization
techniques, such as dropout rates or weight decay, can help control
overfitting by limiting model capacity. For example, dropout rates from
<code>0.1</code> to <code>0.5</code> or weight decay values of
<code>0.0001</code> to <code>0.01</code> often balance underfitting and
overfitting effectively. Higher regularization might inhibit learning,
especially if the model is relatively small.</p></li>
<li><p><strong>Early Stopping</strong>: While not a traditional
hyperparameter, setting up early stopping based on the validation
performance can prevent overfitting without the need to exhaustively
test for epoch limits. By allowing the model to halt once performance
plateaus or worsens, early stopping can improve efficiency in
hyperparameter tuning.</p></li>
<li><p><strong>Special Phenomena - Grokking and Double Descent</strong>:
For certain complex datasets or when tuning particularly large models,
keep an eye on phenomena like <em>grokking</em> (sudden shifts from poor
to excellent generalization) and <em>double descent</em> (an unexpected
second drop in error after initial overfitting). These behaviors are
more likely to appear in models with high capacity and prolonged
training periods, potentially requiring longer epochs or lower learning
rates to observe.</p></li>
</ul>
<p>In summary, hyperparameter tuning is a balancing act between
expanding model capacity and mitigating overfitting. Prioritize
parameters that have shown past efficacy in similar problems, and limit
the search to a manageable range—often 20–30 model configurations are
sufficient to observe gains. This approach keeps resource consumption
practical while achieving meaningful improvements in model
performance.</p>
</div>
<div class="section level4">
<h4 id="set-up-hyperparamtertuner-object">3. Set up HyperParamterTuner object<a class="anchor" aria-label="anchor" href="#set-up-hyperparamtertuner-object"></a>
</h4>
<p>In step 3, we set up the <code>HyperparameterTuner</code>, which
controls the tuning process by specifying the…</p>
<ul>
<li>
<code>estimator</code>: Here, we connect the previously defined
<code>pytorch_estimator</code> to <code>tuner</code>, ensuring that the
tuning job will run with our PyTorch model configuration.</li>
<li>
<code>objectives</code>:</li>
<li>The <code>metric_definitions</code> and
<code>objective_metric_name</code> indicate which metric SageMaker
should monitor to find the best-performing model; in this case, we’re
tracking “validation:accuracy” and aiming to maximize it. We’ll show you
how to setup your training script to report this information in the next
step.</li>
<li>
<code>hyperparameter ranges</code>: Defined above.</li>
<li>
<code>tuning strategy</code>: SageMaker uses a <strong>Bayesian
strategy</strong> by default, which iteratively improves parameter
selection based on past performance to find an optimal model more
efficiently. Although it’s possible to adjust to a “Random” strategy,
Bayesian optimization generally provides better results, so it’s
recommended to keep this setting.</li>
<li>
<code>max_jobs</code> and <code>max_parallel_jobs</code>: Finally,
we set <code>max_jobs</code> to control the total number of
configurations SageMaker will explore and <code>max_parallel_jobs</code>
to limit the number of jobs that run simultaneously, balancing resource
usage and tuning speed. Since SageMaker tests different hyperparameter
values dynamically, it’s important to limit total parallel instances to
&lt;= 4.</li>
</ul>
<blockquote>
<p><strong>Resource-Conscious Approach</strong>: To control costs and
energy-needs, choose efficient instance types and limit the search to
impactful parameters at a sensible range, keeping resource consumption
in check. Hyperparameter tuning often does yield better performing
models, but these gains can be marginal after exhausting a reasonable
search window of 20-30 model configurations. As a researcher, it’s also
imortant to do some digging on past work to see which parameters may be
worthwhile to explore. Make sure you understand what each parameter is
doing before you adjust them.</p>
</blockquote>
<p><strong>Always start with <code>max_jobs = 1</code> and
<code>max_parallel_jobs=1</code>.</strong> Before running the full
search, let’s test our setup by setting max_jobs = 1. This will test
just one possible hyperparameter configuration. This critical step helps
ensure our code is functional before attempting to scale up.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Tuner configuration</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>tuner <span class="op">=</span> HyperparameterTuner(</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    base_tuning_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    estimator<span class="op">=</span>pytorch_estimator,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    metric_definitions<span class="op">=</span>[{<span class="st">"Name"</span>: <span class="st">"validation:accuracy"</span>, <span class="st">"Regex"</span>: <span class="st">"validation:accuracy = ([0-9</span><span class="ch">\\</span><span class="st">.]+)"</span>}],</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    objective_metric_name<span class="op">=</span><span class="st">"validation:accuracy"</span>,  <span class="co"># Ensure this matches the metric name exactly</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    objective_type<span class="op">=</span><span class="st">"Maximize"</span>,                   <span class="co"># Specify if maximizing or minimizing the metric</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>    hyperparameter_ranges<span class="op">=</span>hyperparameter_ranges,</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    strategy<span class="op">=</span><span class="st">"Bayesian"</span>,  <span class="co"># Default setting (recommend sticking with this!); can adjust to "Random" for uniform sampling across the range</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    max_jobs<span class="op">=</span><span class="dv">1</span>,                <span class="co"># Always start with 1 instance for debugging purposes. Adjust based on exploration needs (keep below 30 to be kind to environment). </span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>    max_parallel_jobs<span class="op">=</span><span class="dv">1</span>         <span class="co"># Always start with 1 instance for debugging purposes. Adjust based on available resources and budget. Recommended to keep this value &lt; 4 since SageMaker tests values dynamically.</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="prepare-training-script-to-log-metrics">4. Prepare training script to log metrics<a class="anchor" aria-label="anchor" href="#prepare-training-script-to-log-metrics"></a>
</h4>
<p>To prepare <code>train_nn.py</code> for hyperparameter tuning, we
added code to log validation metrics in a format that SageMaker
recognizes for tracking. In the training loop, we added a print
statement for <code>Val Accuracy</code> in a specific format that
SageMaker can capture.</p>
<p><strong>Note</strong>: It’s best to use an if statement to only print
out metrics periodically (e.g., every 100 epochs), so that you print
time does not each up too much of your training time. It may be a little
counter-intuitive that printing can slow things down so dramatically,
but it truly does become a significant factor if you’re doing it every
epoch. On the flipside of this, you don’t want to print metrics so
infrequently that you lose resolution in the monitored validation
accuracy. Choose a number between 100-1000 epochs or divide your total
epoch count by ~25 to yield a reasonable range.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># if (epoch + 1) % 100 == 0 or epoch == epochs - 1:</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co">#     print(f"validation:accuracy = {val_accuracy:.4f}", flush=True)  # Log for SageMaker metric tracking. Needed for hyperparameter tuning later.</span></span></code></pre>
</div>
<p>Paired with this, our <code>metric_definitions</code> above uses a
regular expression <code>"validation:accuracy = ([0-9\\.]+)"</code> to
extract the val_accuracy value from each log line. This regex
specifically looks for validation:accuracy =, followed by a
floating-point number, which corresponds to the format of our log
statement in train_nn.py.</p>
</div>
<div class="section level4">
<h4 id="set-data-paths-and-launch-tuner-fit">5. Set data paths and launch tuner.fit()<a class="anchor" aria-label="anchor" href="#set-data-paths-and-launch-tuner-fit"></a>
</h4>
<p>In step 4, we define the input data paths for the training job and
launch the hyperparameter tuning process. Using
<code>TrainingInput</code>, we specify the S3 paths to our
<code>train_data.npz</code> and <code>val_data.npz</code> files. This
setup ensures that SageMaker correctly accesses our training and
validation data during each job in the tuning process. We then call
<code>tuner.fit</code> and pass a dictionary mapping each data channel
(“train” and “val”) to its respective path. This command initiates the
tuning job, triggering SageMaker to begin sampling hyperparameter
combinations, training the model, and evaluating performance based on
our defined objective metric. Once the job is launched, SageMaker
handles the tuning process automatically, running the specified number
of configurations and keeping track of the best model parameters based
on validation accuracy.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Define the input paths</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/train_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>val_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/val_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co"># Launch the hyperparameter tuning job</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>tuner.fit({<span class="st">"train"</span>: train_input, <span class="st">"val"</span>: val_input})</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Hyperparameter tuning job launched."</span>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="monitor-tuning-job-from-sagemaker-console">6. Monitor tuning job from SageMaker console<a class="anchor" aria-label="anchor" href="#monitor-tuning-job-from-sagemaker-console"></a>
</h4>
<p>After running the above cell, we can check on the progress by
visiting the SageMaker Console and finding the “Training” tab located on
the left panel. Click “Hyperparmater tuning jobs” to view running
jobs.</p>
</div>
</div>
<div class="section level3">
<h3 id="scaling-up-our-approach">Scaling up our approach<a class="anchor" aria-label="anchor" href="#scaling-up-our-approach"></a>
</h3>
<p>If all goes well, we can scale up the experiment with the below code.
In this configuration, we’re scaling up the search by allowing SageMaker
to test more hyperparameter configurations (<code>max_jobs=20</code>)
while setting <code>max_parallel_jobs=2</code> to manage parallelization
efficiently. With two jobs running at once, SageMaker will be able to
explore potential improvements more quickly than in a fully sequential
setup, while still dynamically selecting promising values as it learns
from completed jobs. This balance leverages SageMaker’s Bayesian
optimization, which uses completed trials to inform subsequent ones,
helping to avoid redundant testing of less promising parameter
combinations. <strong>Setting <code>max_parallel_jobs</code> higher than
2-4 could increase costs and reduce tuning efficiency, as SageMaker’s
ability to learn from completed jobs decreases when too many jobs run
simultaneously.</strong></p>
<p>With this approach, SageMaker is better able to refine configurations
without overloading resources or risking inefficient exploration, making
<code>max_parallel_jobs=2</code> a solid default for most use cases.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> t <span class="co"># always a good idea to keep a runtime of your experiments </span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Configuration variables</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>instance_type <span class="op">=</span> <span class="st">"ml.m5.large"</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>max_jobs <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>max_parallel_jobs <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># Define the Tuner configuration</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>tuner <span class="op">=</span> HyperparameterTuner(</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    base_tuning_job_name<span class="op">=</span>notebook_instance_name,</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    estimator<span class="op">=</span>pytorch_estimator,</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>    metric_definitions<span class="op">=</span>[{<span class="st">"Name"</span>: <span class="st">"validation:accuracy"</span>, <span class="st">"Regex"</span>: <span class="st">"validation:accuracy = ([0-9</span><span class="ch">\\</span><span class="st">.]+)"</span>}],</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    objective_metric_name<span class="op">=</span><span class="st">"validation:accuracy"</span>,  <span class="co"># Ensure this matches the metric name exactly</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    objective_type<span class="op">=</span><span class="st">"Maximize"</span>,                   <span class="co"># Specify if maximizing or minimizing the metric</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    hyperparameter_ranges<span class="op">=</span>hyperparameter_ranges,</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    max_jobs<span class="op">=</span>max_jobs,</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    max_parallel_jobs<span class="op">=</span>max_parallel_jobs</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>)</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co"># Define the input paths</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>train_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/train_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>val_input <span class="op">=</span> TrainingInput(<span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/val_data.npz"</span>, content_type<span class="op">=</span><span class="st">"application/x-npz"</span>)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="co"># Track start time</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>start_time <span class="op">=</span> t.time()</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a><span class="co"># Launch the hyperparameter tuning job</span></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>tuner.fit({<span class="st">"train"</span>: train_input, <span class="st">"val"</span>: val_input})</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a><span class="co"># Calculate runtime</span></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>runtime <span class="op">=</span> t.time() <span class="op">-</span> start_time</span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a><span class="co"># Print confirmation with runtime and configuration details</span></span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tuning runtime: </span><span class="sc">{</span>runtime<span class="sc">:.2f}</span><span class="ss"> seconds, Instance Type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">, Max Jobs: </span><span class="sc">{</span>max_jobs<span class="sc">}</span><span class="ss">, Max Parallel Jobs: </span><span class="sc">{</span>max_parallel_jobs<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="monitoring-tuning">Monitoring tuning<a class="anchor" aria-label="anchor" href="#monitoring-tuning"></a>
</h3>
<p>After running the above cell, we can check on the progress by
visiting the SageMaker Console and finding the “Training” tab located on
the left panel. Click “Hyperparmater tuning jobs” to view running
jobs.</p>
<ul>
<li>Initial Jobs: SageMaker starts by running only max_parallel_jobs (2
in this case) as the initial batch. As each job completes, new jobs from
the remaining pool are triggered until max_jobs (20) is reached.</li>
<li>Job Completion: Once the first few jobs complete, SageMaker will
continue to launch the remaining jobs up to the maximum of 20, but no
more than two at a time.</li>
</ul>
</div>
<div class="section level3">
<h3 id="canshould-we-run-more-instances-in-parallel">Can/should we run more instances in parallel?<a class="anchor" aria-label="anchor" href="#canshould-we-run-more-instances-in-parallel"></a>
</h3>
<p>Setting max_parallel_jobs to 20 (equal to max_jobs) will indeed
launch all 20 jobs in parallel. This approach won’t affect the total
cost (since cost is based on the number of total jobs, not how many run
concurrently), but it can impact the final results and resource usage
pattern due to SageMaker’s ability to dynamically select hyperparameter
values to test to maximize efficiency and improve model performance.
This adaptability is especially useful for neural networks, which often
have a large hyperparameter space with complex interactions. Here’s how
SageMaker’s approach impacts typical neural network training:</p>
<div class="section level4">
<h4 id="adaptive-search-strategies">1. Adaptive Search Strategies<a class="anchor" aria-label="anchor" href="#adaptive-search-strategies"></a>
</h4>
<ul>
<li>SageMaker offers <strong>Bayesian optimization</strong> for
hyperparameter tuning. Instead of purely random sampling, it learns from
previous jobs to choose the next set of hyperparameters more likely to
improve the objective metric.</li>
<li>For neural networks, this strategy can help converge on
better-performing configurations faster by favoring promising areas of
the hyperparameter space and discarding poor ones.</li>
</ul>
</div>
<div class="section level4">
<h4 id="effect-of-max_parallel_jobs-on-adaptive-tuning">2. Effect of <code>max_parallel_jobs</code> on adaptive tuning<a class="anchor" aria-label="anchor" href="#effect-of-max_parallel_jobs-on-adaptive-tuning"></a>
</h4>
<ul>
<li>When using Bayesian optimization, a lower
<code>max_parallel_jobs</code> (e.g., 2–4) can allow SageMaker to
iteratively adjust and improve its choices. Each batch of jobs informs
the subsequent batch, which may yield better results over time.</li>
<li>Conversely, if all jobs are run in parallel (e.g.,
<code>max_parallel_jobs=20</code>), SageMaker can’t learn and adapt
within a single batch, making this setup more like a traditional grid or
random search. This approach is still valid, especially for small search
spaces, but it doesn’t leverage the full potential of adaptive
tuning.</li>
</ul>
</div>
<div class="section level4">
<h4 id="practical-impact-on-neural-network-training">3. Practical impact on neural network training<a class="anchor" aria-label="anchor" href="#practical-impact-on-neural-network-training"></a>
</h4>
<ul>
<li>
<strong>For simpler models</strong> or smaller parameter ranges,
running jobs in parallel with a higher <code>max_parallel_jobs</code>
works well and quickly completes the search.</li>
<li>
<strong>For more complex neural networks</strong> or large
hyperparameter spaces, an adaptive strategy with a smaller
<code>max_parallel_jobs</code> may yield a better model with fewer total
jobs by fine-tuning hyperparameters over multiple iterations.</li>
</ul>
</div>
<div class="section level4">
<h4 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h4>
<ul>
<li>
<strong>For fast, straightforward tuning</strong>: Set
<code>max_parallel_jobs</code> closer to <code>max_jobs</code> for
simultaneous testing.</li>
<li>
<strong>For adaptive, refined tuning</strong>: Use a smaller
<code>max_parallel_jobs</code> (like 2–4) to let SageMaker leverage
adaptive tuning for optimal configurations.</li>
</ul>
<p>This balance between exploration and exploitation is particularly
impactful in neural network tuning, where training costs can be high and
parameters interact in complex ways.</p>
</div>
</div>
<div class="section level3">
<h3 id="extracting-and-evaluating-the-best-model-after-tuning">Extracting and evaluating the best model after tuning<a class="anchor" aria-label="anchor" href="#extracting-and-evaluating-the-best-model-after-tuning"></a>
</h3>
<p>Tuning should only take about 5 minutes to complete — not bad for 20
models! After SageMaker completes the hyperparameter tuning job, the
results, including the trained models for each configuration, are stored
in an S3 bucket. Here’s a breakdown of the steps to locate and evaluate
the best model on test data.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Understanding the folder structure</strong>:
<ul>
<li>SageMaker saves each tuning job’s results in the specified S3 bucket
under a unique prefix.</li>
<li>For the best model, SageMaker stores the model artifact in the
format <code>s3://{bucket}/{job_name}/output/model.tar.gz</code>. Each
model is compressed as a <code>.tar.gz</code> file containing the saved
model parameters.</li>
</ul>
</li>
<li>
<strong>Retrieve and load the best model</strong>:
<ul>
<li>Using the <code>tuner.best_training_job()</code> method, you can get
the name of the best-performing job.</li>
<li>From there, retrieve the S3 URI of the best model artifact, download
it locally, and extract the files for use.</li>
</ul>
</li>
<li>
<strong>Prepare test data for final assessment of model
generalizability</strong>
<ul>
<li>If not done already.</li>
</ul>
</li>
<li>
<strong>Evaluate the model on test data</strong>:
<ul>
<li>Once extracted, load the saved model weights and evaluate the model
on your test dataset to get the final performance metrics.</li>
</ul>
</li>
</ol>
<p>Here’s the code to implement these steps:</p>
<div class="section level4">
<h4 id="view-best-model-details-and-storage-info">View best model details and storage info<a class="anchor" aria-label="anchor" href="#view-best-model-details-and-storage-info"></a>
</h4>
<p>We can easily view the best hyperparameters from the tuning
procedure…</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># 1. Get the best training job from the completed tuning job</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>best_job_name <span class="op">=</span> tuner.best_training_job()</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best training job name:"</span>, best_job_name)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co"># 2. Use describe_training_job to retrieve full details, including hyperparameters...</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>best_job_desc <span class="op">=</span> session.sagemaker_client.describe_training_job(TrainingJobName<span class="op">=</span>best_job_name)</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>best_hyperparameters <span class="op">=</span> best_job_desc[<span class="st">"HyperParameters"</span>]</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best hyperparameters:"</span>, best_hyperparameters)</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="co"># ...  and model URI (location on S3)</span></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>best_model_s3_uri <span class="op">=</span> best_job_desc[<span class="st">'ModelArtifacts'</span>][<span class="st">'S3ModelArtifacts'</span>]</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best model artifact S3 URI: </span><span class="sc">{</span>best_model_s3_uri<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="retrieve-and-load-best-model">Retrieve and load best model<a class="anchor" aria-label="anchor" href="#retrieve-and-load-best-model"></a>
</h4>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">import</span> tarfile</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co"># Initialize S3 client</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>s3 <span class="op">=</span> boto3.client(<span class="st">'s3'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co"># Download and extract the model artifact</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>local_model_path <span class="op">=</span> <span class="st">"best_model.tar.gz"</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>bucket_name, model_key <span class="op">=</span> best_model_s3_uri.split(<span class="st">'/'</span>)[<span class="dv">2</span>], <span class="st">'/'</span>.join(best_model_s3_uri.split(<span class="st">'/'</span>)[<span class="dv">3</span>:])</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>s3.download_file(bucket_name, model_key, local_model_path)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># Extract the model files from the tar.gz archive</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="cf">with</span> tarfile.<span class="bu">open</span>(local_model_path, <span class="st">'r:gz'</span>) <span class="im">as</span> tar:</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    tar.extractall()</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best model downloaded and extracted."</span>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="prepare-test-set-as-test_data-npz">Prepare test set as test_data.npz<a class="anchor" aria-label="anchor" href="#prepare-test-set-as-test_data-npz"></a>
</h4>
<p>In our previous episode, we converted our train dataset into
train/validate subsets, and saved them out as .npz files for efficient
processing. We’ll need to preprocess our test data the same way to
evaluate it on our model.</p>
<p><strong>Note</strong>: It’s always a good idea to keep preprocessing
code as a function so you can apply the same exact procedure across
datasets with ease. We’ll import our preprocessing function from
<code>train_nn.py</code>.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co"># Now try importing the function again</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="im">from</span> AWS_helpers.train_nn <span class="im">import</span> preprocess_data</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co"># Example usage for test data (using the same scaler from training)</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>test_df <span class="op">=</span> pd.read_csv(<span class="st">"titanic_test.csv"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>X_test, y_test, _ <span class="op">=</span> preprocess_data(test_df)</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co"># Save processed data for testing</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>np.savez(<span class="st">'test_data.npz'</span>, X_test<span class="op">=</span>X_test, y_test<span class="op">=</span>y_test)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="evaluate-the-model-on-test-data">Evaluate the model on test data<a class="anchor" aria-label="anchor" href="#evaluate-the-model-on-test-data"></a>
</h4>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> AWS_helpers.train_nn <span class="im">import</span> TitanicNet</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="im">from</span> AWS_helpers.train_nn <span class="im">import</span> calculate_accuracy</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co"># Load the model (assuming it's saved as 'nn_model.pth' after extraction)</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>model <span class="op">=</span> TitanicNet()  <span class="co"># Ensure TitanicNet is defined as per your training script</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="st">"nn_model.pth"</span>))</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="co"># Load test data (assuming the test set is saved as "test_data.npz" in npz format)</span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>test_data <span class="op">=</span> np.load(<span class="st">"test_data.npz"</span>)  <span class="co"># Replace "test_data.npz" with actual test data path if different</span></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>X_test <span class="op">=</span> torch.tensor(test_data[<span class="st">'X_test'</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>y_test <span class="op">=</span> torch.tensor(test_data[<span class="st">'y_test'</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a><span class="co"># Evaluate the model on the test set</span></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>    predictions <span class="op">=</span> model(X_test)</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>    accuracy <span class="op">=</span> calculate_accuracy(predictions, y_test)  <span class="co"># Assuming calculate_accuracy is defined as in your training script</span></span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h3>
<p>In just under 5 minutes, we produced a model that is almost 100%
accurate on the test set. However, this performance does come at a cost
(albeit manageable if you’ve stuck with our advise thus far). This next
section will help you assess the total compute time that was used by
your tuning job.</p>
<p>In SageMaker, training time and billing time (extracted in our code
below) are often expected to differ slightly for training jobs, but not
for tuning jobs. Here’s a breakdown of what’s happening:</p>
<ul>
<li><p>Training Time: This is the actual wall-clock time that each
training job takes to run, from start to end. This metric represents the
pure time spent on training without considering the compute
resources.</p></li>
<li><p>Billing Time: This includes the training time but is adjusted for
the resources used. Billing time considers:</p></li>
</ul>
<p>Instance Count: The number of instances used for training affects
billing time. Round-Up Policy: SageMaker rounds up the billing time to
the nearest second for each job and multiplies it by the instance count
used. This means that for short jobs, the difference between training
and billing time can be more pronounced.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># Set region</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>region <span class="op">=</span> <span class="st">"us-east-2"</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co"># Initialize SageMaker client</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>sagemaker_client <span class="op">=</span> boto3.client(<span class="st">"sagemaker"</span>, region_name<span class="op">=</span>region)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Retrieve tuning job details</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>tuning_job_name <span class="op">=</span> tuner.latest_tuning_job.name  <span class="co"># Replace with your tuning job name if needed</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>tuning_job_desc <span class="op">=</span> sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName<span class="op">=</span>tuning_job_name)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co"># Extract relevant settings</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>instance_type <span class="op">=</span> tuning_job_desc[<span class="st">'TrainingJobDefinition'</span>][<span class="st">'ResourceConfig'</span>][<span class="st">'InstanceType'</span>]</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>max_jobs <span class="op">=</span> tuning_job_desc[<span class="st">'HyperParameterTuningJobConfig'</span>][<span class="st">'ResourceLimits'</span>][<span class="st">'MaxNumberOfTrainingJobs'</span>]</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>max_parallel_jobs <span class="op">=</span> tuning_job_desc[<span class="st">'HyperParameterTuningJobConfig'</span>][<span class="st">'ResourceLimits'</span>][<span class="st">'MaxParallelTrainingJobs'</span>]</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co"># Retrieve all training jobs for the tuning job</span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>training_jobs <span class="op">=</span> sagemaker_client.list_training_jobs_for_hyper_parameter_tuning_job(</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>    HyperParameterTuningJobName<span class="op">=</span>tuning_job_name, StatusEquals<span class="op">=</span><span class="st">'Completed'</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>)[<span class="st">"TrainingJobSummaries"</span>]</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="co"># Calculate total training and billing time</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>total_training_time <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>total_billing_time <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a><span class="cf">for</span> job <span class="kw">in</span> training_jobs:</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>    job_name <span class="op">=</span> job[<span class="st">"TrainingJobName"</span>]</span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>    job_desc <span class="op">=</span> sagemaker_client.describe_training_job(TrainingJobName<span class="op">=</span>job_name)</span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>    </span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>    <span class="co"># Calculate training time (in seconds)</span></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>    training_time <span class="op">=</span> job_desc[<span class="st">"TrainingEndTime"</span>] <span class="op">-</span> job_desc[<span class="st">"TrainingStartTime"</span>]</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    total_training_time <span class="op">+=</span> training_time.total_seconds()</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    </span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>    <span class="co"># Calculate billed time with rounding up</span></span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>    billed_time <span class="op">=</span> math.ceil(training_time.total_seconds())</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>    total_billing_time <span class="op">+=</span> billed_time <span class="op">*</span> job_desc[<span class="st">"ResourceConfig"</span>][<span class="st">"InstanceCount"</span>]</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a><span class="co"># Print configuration details and total compute/billing time</span></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Instance Type: </span><span class="sc">{</span>instance_type<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max Jobs: </span><span class="sc">{</span>max_jobs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max Parallel Jobs: </span><span class="sc">{</span>max_parallel_jobs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total training time across all jobs: </span><span class="sc">{</span>total_training_time <span class="op">/</span> <span class="dv">3600</span><span class="sc">:.2f}</span><span class="ss"> hours"</span>)</span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated total billing time across all jobs: </span><span class="sc">{</span>total_billing_time <span class="op">/</span> <span class="dv">3600</span><span class="sc">:.2f}</span><span class="ss"> hours"</span>)</span></code></pre>
</div>
<p>For convenience, we have added this as a function in helpers.py</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="im">import</span> AWS_helpers.helpers <span class="im">as</span> helpers</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="im">import</span> importlib</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>importlib.<span class="bu">reload</span>(helpers)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>helpers.calculate_tuning_job_time(tuner, region)</span></code></pre>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></section><section id="aio-00_Overview-RAG-on-AWS"><p>Content from <a href="00_Overview-RAG-on-AWS.html">Overview of RAG Workflows on AWS</a></p>
<hr>
<p>Last updated on 2025-11-26 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/00_Overview-RAG-on-AWS.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<section><h2 class="section-heading" id="retrieval-augmented-generation-rag-on-aws">Retrieval-Augmented Generation (RAG) on AWS<a class="anchor" aria-label="anchor" href="#retrieval-augmented-generation-rag-on-aws"></a>
</h2>
<hr class="half-width">
<p>Retrieval-Augmented Generation (RAG) is a pattern where you
<strong>retrieve</strong> relevant context from your data and then
<strong>generate</strong> an answer using that context. Unlike model
training, a standard RAG workflow does <strong>not</strong> fine‑tune or
train a model — it combines retrieval + inference only.</p>
<p>This episode introduces the major ways to build RAG systems on AWS
and prepares us for later episodes where we experiment with each
approach.</p>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is Retrieval‑Augmented Generation (RAG)?</li>
<li>What are the main architectural options for running RAG on AWS?</li>
<li>When is each RAG workflow appropriate?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand that RAG does <em>not</em> require training or
fine‑tuning a model.</li>
<li>Recognize the three major architectural patterns for RAG systems on
AWS.</li>
<li>Understand the core trade‑offs that drive which approach to
use.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="what-is-rag">What is RAG?<a class="anchor" aria-label="anchor" href="#what-is-rag"></a>
</h2>
<hr class="half-width">
<p>RAG combines two steps:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Retrieve</strong>: Search your document store (vector DB or
FAISS index) to find relevant text.</li>
<li>
<strong>Generate</strong>: Provide those retrieved chunks to a large
language model (LLM) to answer a question.</li>
</ol>
<p>No model weights are updated. No backprop. No training job.<br>
RAG is an inference‑only pattern that layers retrieval logic around an
LLM.</p>
</section><section><h2 class="section-heading" id="approaches-to-running-rag-on-aws">Approaches to Running RAG on AWS<a class="anchor" aria-label="anchor" href="#approaches-to-running-rag-on-aws"></a>
</h2>
<hr class="half-width">
<p>There are several general approaches for setting up a
Retrieval-Augmented Generation (RAG) workflow on AWS, each suited to
different scales and constraints.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Run everything inside a single GPU-backed notebook
instance</strong> For small- to medium-sized models (&lt; 70 B), it’s
often simplest to just pick a GPU instance (e.g., <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">p3.2xlarge</a>),
load your embedding and generation models directly in the notebook, and
run RAG end-to-end there. This keeps the architecture simple and avoids
extra moving parts, as long as you’re disciplined about shutting down
the instance when you’re done so you don’t leak cost. It’s also possible
to do this with larger models, but the costs to use more powerful GPUs
(e.g., $15/hour) may be a limiting factor.</p></li>
<li><p><strong>Use SageMaker Processing Jobs to run batch jobs for
embeddings and/or generation.</strong> For large corpora or workflows
where you want repeatable, offline computation, you can treat parts of
the RAG pipeline—especially embedding—like a batch processing job rather
than a live model. Instead of deploying an inference endpoint, you run a
short-lived Hugging Face Processing job that spins up a GPU instance,
loads your embedding or generation model, processes all the chunked text
in one shot, and saves the results back to S3. This pattern is ideal for
“compute once, use many times” workloads, such as generating embeddings
for thousands of documents or producing long-form outputs that don’t
require low latency. Because the job only exists while the batch
completes, you avoid the continuous cost of an always-on endpoint.
However, this approach is not suited for per-query RAG
retrieval—launching a job per user request would be far too slow, since
starting a training job can take several minutes.</p></li>
<li><p><strong>Use Amazon Bedrock for managed embedding and generation
APIs.</strong> If you prefer fully managed foundation models and don’t
want to own model hosting at all, Bedrock lets you call embedding and
generation models via API from your RAG pipeline. You still can still
manage retrieval logic (e.g., add reranking), but you outsource the
heavy model lifecycle work—at the trade-off of less control over
architectures and sometimes higher per-token cost.</p></li>
<li><p><strong>Use long-lived inference endpoints for online RAG
workloads.</strong> For applications that need low-latency, interactive
RAG (APIs, chatbots, dashboards), you can deploy your own embedding and
generation models as SageMaker inference endpoints (or Bedrock-like
managed endpoints) and call them from your retrieval service. This gives
you control over the model, scaling policies, and autoscaling, but it’s
also the most expensive option if traffic is low or bursty, since you’re
keeping capacity online even when no one is querying the
system.</p></li>
</ol></section><section><h2 class="section-heading" id="when-do-you-use-which-approach">When Do You Use Which Approach?<a class="anchor" aria-label="anchor" href="#when-do-you-use-which-approach"></a>
</h2>
<hr class="half-width">
<ol style="list-style-type: decimal">
<li><p><strong>Notebook RAG</strong>: Fastest to build. Great for
learning, prototyping, and small‑scale research.</p></li>
<li><p><strong>Processing‑job RAG</strong>: Ideal for embedding large
corpora and running periodic batch generation. Clean, reproducible,
cost‑efficient (especially if you spend a lot of time in your notebook
viewing results, rather than generating them).</p></li>
<li><p><strong>Bedrock RAG</strong>: Best for production or long‑term
research tools that need scalability without hosting models. Bedrock can
also give RAG systems access to proprietary models which would need to
be purhcased separately otherwise.</p></li>
<li><p>TODO</p></li>
</ol>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>RAG is an inference‑only workflow: no training or fine‑tuning
required.</li>
<li>AWS supports three broad approaches: notebook RAG, batch RAG, and
Bedrock‑managed RAG.</li>
<li>The right choice depends on latency needs, scale, cost sensitivity,
and model‑management preferences.</li>
<li>Later episodes will walk through each pattern in depth using
hands‑on examples.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-01_RAG_WattBot_GPU-instance"><p>Content from <a href="01_RAG_WattBot_GPU-instance.html">RAG with a Notebook GPU</a></p>
<hr>
<p>Last updated on 2025-11-26 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/01_RAG_WattBot_GPU-instance.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we run a basic Retrieval-Augmented Generation (RAG) pipeline
entirely from a single GPU-backed SageMaker notebook?</li>
<li>How do we go from raw PDFs and CSV files to a searchable embedding
space for WattBot documents?</li>
<li>How can we generate WattBot-style answers (including citations and
evidence) that follow the competition’s scoring conventions?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Verify that our SageMaker notebook instance has a working GPU and
compatible Python environment.</li>
<li>Load the WattBot metadata and question–answer files from local
storage and inspect their structure.</li>
<li>Download all referenced PDFs from <code>metadata.csv</code> and turn
them into a collection of text pages with useful metadata attached.</li>
<li>Implement a simple, explicit “from scratch” text-chunking and
embedding pipeline without relying on FAISS or production vector
DBs.</li>
<li>Build a small retrieval helper that finds the most relevant chunks
for a question using cosine similarity in embedding space.</li>
<li>Wire the retriever to a local Qwen 7B-style generator to produce
WattBot-format answers (including <code>answer</code>,
<code>ref_id</code>, <code>ref_url</code>, and
<code>supporting_materials</code>).</li>
<li>Add a second LLM pass that generates short explanations and marks
whether the evidence comes from text, figures, tables, or a
combination.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="working-with-aws-for-rag-experiments">Working with AWS for RAG Experiments<a class="anchor" aria-label="anchor" href="#working-with-aws-for-rag-experiments"></a>
</h2>
<hr class="half-width">
<p>In the previous episode, we briefly introduced several approaches for
implementing RAG in AWS. Here, we are simply selecting a good GPU
instance that can handle whatever RAG system we want to build. This
approach is:</p>
<ul>
<li>Very easy to understand core on the AWS side of things (just select
GPU instance and you’re good to move on)</li>
<li>Ideal for learning retrieval and generation steps<br>
</li>
<li>Great for experimentation and debugging</li>
</ul>
<p>However, it is <strong>not the most cost‑efficient method</strong>.
In upcoming episodes we will introduce more efficient and
production‑aligned GPU strategies, including:</p>
<ul>
<li>On-demand GPU tasks<br>
</li>
<li>Fully managed asynchronous jobs<br>
</li>
<li>Serverless or streaming LLM inference<br>
</li>
<li>SageMaker batch transform &amp; RAG pipelines<br>
</li>
<li>Embedding jobs that run only when needed</li>
</ul>
<p>Those techniques bring you closer to best practice for scalable and
budget‑friendly research computing.</p>
<p><strong>Remember to Shut Down Your AWS Instance</strong>: GPU
notebook instances continue billing <strong>even when idle</strong>.
Always:</p>
<ul>
<li>Save your work<br>
</li>
<li>Shut down or stop the instance when not in use</li>
<li>Verify the status in the AWS console</li>
</ul>
<p>This habit prevents accidental ongoing GPU charges.</p>
</section><section><h2 class="section-heading" id="overview-wattbot-rag-on-a-single-notebook-gpu">Overview: WattBot RAG on a single notebook GPU<a class="anchor" aria-label="anchor" href="#overview-wattbot-rag-on-a-single-notebook-gpu"></a>
</h2>
<hr class="half-width">
<p>In this episode we build a <strong>minimal but realistic RAG
pipeline</strong> from the <a href="https://www.kaggle.com/competitions/WattBot2025/overview" class="external-link">WattBot
2025</a> challenge that runs entirely from a single GPU-backed SageMaker
notebook.</p>
<p>In this episode we will:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Work directly with the WattBot data.</strong>
<ul>
<li>Use <code>train_QA.csv</code> and <code>metadata.csv</code> from the
competition dataset.</li>
<li>Download all referenced PDFs (our RAG corpus) using the URLs in
<code>metadata.csv</code>.</li>
</ul>
</li>
<li>
<strong>Implement the core RAG steps explicitly in code.</strong>
<ul>
<li>Read PDFs, extract per-page text, and attach document metadata.</li>
<li>Chunk text into overlapping segments suitable for embedding.</li>
<li>Embed chunks with a sentence-transformer
(<code>thenlper/gte-base</code>)</li>
<li>Implement cosine-similarity search over the embedding matrix.</li>
</ul>
</li>
<li>
<strong>Connect to a local Qwen-style generator.</strong>
<ul>
<li>Use a quantized 7B model on a GPU-backed instance (e.g.,
<code>ml.g5.xlarge</code>).</li>
<li>Construct WattBot-style answers that we can compare against
<code>train_QA.csv</code>.</li>
</ul>
</li>
<li>
<strong>Add an explanation pass.</strong>
<ul>
<li>Use an LLM to look at the retrieved evidence, the answer, and
citations.</li>
<li>Generate a short explanation and label the <strong>evidence
type</strong>: <code>[Quote]</code>, <code>[Table]</code>,
<code>[Figure]</code>, or <code>[Mixed]</code>.</li>
</ul>
</li>
</ol></section><section><h2 class="section-heading" id="notebook-dataset-setup">Notebook + dataset setup<a class="anchor" aria-label="anchor" href="#notebook-dataset-setup"></a>
</h2>
<hr class="half-width">
<p>For this episode, we assume you are running on an AWS SageMaker
notebook instance with a GPU, such as:</p>
<ul>
<li>
<code>ml.g5.xlarge</code> (recommended) or</li>
<li>
<code>ml.g4dn.xlarge</code> (may work with smaller models / more
aggressive quantization).</li>
</ul>
<p>See <a href="https://carpentries-incubator.github.io/ML_with_AWS_SageMaker/instances-for-ML.html" class="external-link">Instances
for ML</a> for further guidance.</p>
<div class="section level3">
<h3 id="step-1-download-data-zip-locally">Step 1 – Download <code>data.zip</code> locally<a class="anchor" aria-label="anchor" href="#step-1-download-data-zip-locally"></a>
</h3>
<p>We’ll use the <strong>WattBot 2025</strong> dataset. Download the
workshop data archive to your laptop or desktop:</p>
<ul>
<li>Open this link in your browser: <a href="https://github.com/carpentries-incubator/ML_with_AWS_SageMaker/blob/main/data/data.zip" class="external-link uri">https://github.com/carpentries-incubator/ML_with_AWS_SageMaker/blob/main/data/data.zip</a>
</li>
<li>Save <code>data.zip</code> somewhere you can find it easily and
unzip the folder contents</li>
</ul>
<p>This archive should include a <code>data/wattbot/</code> folder
containing:</p>
<ul>
<li>
<code>metadata.csv</code> – index of all WattBot papers.</li>
<li>
<code>train_QA.csv</code> – labeled questions + ground truth
answers.</li>
</ul>
</div>
<div class="section level3">
<h3 id="step-2-create-a-wattbot-s3-bucket">Step 2 – Create a WattBot S3 bucket<a class="anchor" aria-label="anchor" href="#step-2-create-a-wattbot-s3-bucket"></a>
</h3>
<p>In the AWS console:</p>
<ol style="list-style-type: decimal">
<li>Go to <strong>S3</strong>.</li>
<li>Create a new bucket named something like:<br><code>teamname-yourname-wattbot</code>
</li>
<li>Keep <strong>Block all public access</strong> enabled.</li>
<li>(Optional, but recommended) Add tags so we can track costs:
<ul>
<li>
<code>Project = your-team-name</code><br>
</li>
<li>
<code>Name = your-name</code><br>
</li>
<li><code>Purpose = RAG-demo</code></li>
</ul>
</li>
</ol>
</div>
<div class="section level3">
<h3 id="step-3-upload-the-wattbot-files-to-s3">Step 3 – Upload the WattBot files to S3<a class="anchor" aria-label="anchor" href="#step-3-upload-the-wattbot-files-to-s3"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>In your new bucket, click <strong>Upload</strong>.</p></li>
<li><p>Drag <strong>the <code>data/wattbot/</code> folder</strong> from
<code>data.zip</code> into the upload dialog.</p></li>
<li>
<p>Upload it so that your bucket contains paths like:</p>
<ul>
<li><code>wattbot/metadata.csv</code></li>
<li><code>wattbot/train_QA.csv</code></li>
</ul>
</li>
</ol>
<p>We’ll pull these files from S3 into the notebook in the next
steps.</p>
</div>
<div class="section level3">
<h3 id="verify-gpu-and-basic-environment">Verify GPU and basic environment<a class="anchor" aria-label="anchor" href="#verify-gpu-and-basic-environment"></a>
</h3>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">!</span>nvidia<span class="op">-</span>smi <span class="op">||</span> echo <span class="st">"No GPU detected – please switch to a GPU-backed instance (e.g., ml.g5.xlarge) before running this notebook."</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># also verify you've selected teh conda_pytorch_p310 kernel</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"torch cuda available:"</span>, torch.cuda.is_available())</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"num gpus:"</span>, torch.cuda.device_count())</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="import-data-from-bucket-into-notebook">Import data from bucket into notebook<a class="anchor" aria-label="anchor" href="#import-data-from-bucket-into-notebook"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Any</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co"># Initialize SageMaker + AWS basics</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session()</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>region <span class="op">=</span> session.boto_region_name</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>role <span class="op">=</span> get_execution_role()</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>s3_client <span class="op">=</span> boto3.client(<span class="st">"s3"</span>, region_name<span class="op">=</span>region)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Region:"</span>, region)</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Role:"</span>, role)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">def</span> download_s3_object(bucket: <span class="bu">str</span>, key: <span class="bu">str</span>, local_path: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    os.makedirs(os.path.dirname(local_path), exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Downloading s3://</span><span class="sc">{</span>bucket<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>local_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    s3_client.download_file(bucket, key, local_path)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: update this to your bucket name</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">"chris-rag"</span>  <span class="co"># &lt;-- EDIT ME</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># Local working directory in the notebook instance</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>local_data_dir <span class="op">=</span> <span class="st">"./data"</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Local data dir:"</span>, local_data_dir)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Download metadata.csv and train_QA.csv</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>metadata_key <span class="op">=</span> <span class="st">"metadata.csv"</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>train_qa_key <span class="op">=</span> <span class="st">"train_QA.csv"</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>metadata_path <span class="op">=</span> os.path.join(local_data_dir, metadata_key)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>train_qa_path <span class="op">=</span> os.path.join(local_data_dir, train_qa_key)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>download_s3_object(bucket_name, metadata_key, metadata_path)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>download_s3_object(bucket_name, train_qa_key, train_qa_path)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-1-imports-paths-and-safe-csv-loading">Step 1 – Imports, paths, and safe CSV loading<a class="anchor" aria-label="anchor" href="#step-1-imports-paths-and-safe-csv-loading"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Any, Tuple</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">def</span> smart_read_csv(path: <span class="bu">str</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="co">"""Try several encodings when reading a CSV file.</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">    Some CSVs (especially those with special characters in author names or titles)</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">    may not be valid UTF-8. This helper rotates through common encodings and raises</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">    the last error only if all fail.</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>    encodings <span class="op">=</span> [<span class="st">"utf-8"</span>, <span class="st">"latin1"</span>, <span class="st">"ISO-8859-1"</span>, <span class="st">"cp1252"</span>]</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>    last_error <span class="op">=</span> <span class="va">None</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    <span class="cf">for</span> enc <span class="kw">in</span> encodings:</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>            <span class="cf">return</span> pd.read_csv(path, encoding<span class="op">=</span>enc)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>            last_error <span class="op">=</span> e</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    <span class="cf">if</span> last_error <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>        <span class="cf">raise</span> last_error</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="ss">f"Unable to read CSV at </span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>train_df <span class="op">=</span> smart_read_csv(train_qa_path)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>metadata_df <span class="op">=</span> smart_read_csv(metadata_path)</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train_QA.csv columns:"</span>, train_df.columns.tolist())</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"metadata.csv columns:"</span>, metadata_df.columns.tolist())</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Number of training QAs:"</span>, <span class="bu">len</span>(train_df))</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of metadata rows:"</span>, <span class="bu">len</span>(metadata_df))</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>train_df.head(<span class="dv">15</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-2-download-all-pdfs-from-metadata-csv">Step 2 – Download all PDFs from <code>metadata.csv</code>
<a class="anchor" aria-label="anchor" href="#step-2-download-all-pdfs-from-metadata-csv"></a>
</h2>
<hr class="half-width">
<p>Next we will…</p>
<ol style="list-style-type: decimal">
<li>Read the <code>url</code> column from
<code>metadata.csv</code>.</li>
<li>Download each PDF via HTTP and save it locally as
<code>&lt;id&gt;.pdf</code> under <code>pdfs/</code>.</li>
<li>Report any failures (e.g., missing or malformed URLs) at the
end.</li>
<li>Upload zipped version of corpus to S3</li>
</ol>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>PDF_DIR <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"pdfs"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>os.makedirs(PDF_DIR, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="kw">def</span> download_all_pdfs_from_urls(</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    metadata: pd.DataFrame,</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    local_pdf_dir: <span class="bu">str</span>,</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    url_col: <span class="bu">str</span> <span class="op">=</span> <span class="st">"url"</span>,</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    id_col: <span class="bu">str</span> <span class="op">=</span> <span class="st">"id"</span>,</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>    timeout: <span class="bu">int</span> <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    <span class="co">"""Download all PDFs referenced in `metadata` using their URLs.</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="co">    - Saves each file as `&lt;id&gt;.pdf` in `local_pdf_dir`.</span></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="co">    - Strips whitespace from the URL (to avoid trailing spaces becoming `%20`).</span></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="co">    - Skips rows with missing or non-HTTP URLs.</span></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a><span class="co">    - Prints a short summary of any failures.</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>    os.makedirs(local_pdf_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    errors: List[Tuple[<span class="bu">str</span>, <span class="bu">str</span>]] <span class="op">=</span> []</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Saving PDFs to: </span><span class="sc">{</span>local_pdf_dir<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> metadata.iterrows():</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>        doc_id <span class="op">=</span> <span class="bu">str</span>(row[id_col]).strip()</span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>        raw_url <span class="op">=</span> row.get(url_col, <span class="va">None</span>)</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(raw_url, <span class="bu">str</span>):</span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>            errors.append((doc_id, <span class="st">"URL is not a string"</span>))</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>        pdf_url <span class="op">=</span> raw_url.strip()  <span class="co"># important: strip trailing whitespace</span></span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> pdf_url.startswith(<span class="st">"http"</span>):</span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>            errors.append((doc_id, <span class="ss">f"Invalid URL: </span><span class="sc">{</span>pdf_url<span class="sc">!r}</span><span class="ss">"</span>))</span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb9-35"><a href="#cb9-35" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" tabindex="-1"></a>        local_path <span class="op">=</span> os.path.join(local_pdf_dir, <span class="ss">f"</span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">.pdf"</span>)</span>
<span id="cb9-37"><a href="#cb9-37" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb9-39"><a href="#cb9-39" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Downloading </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss"> from </span><span class="sc">{</span>pdf_url<span class="sc">}</span><span class="ss"> ..."</span>)</span>
<span id="cb9-40"><a href="#cb9-40" tabindex="-1"></a>            resp <span class="op">=</span> requests.get(pdf_url, timeout<span class="op">=</span>timeout, allow_redirects<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-41"><a href="#cb9-41" tabindex="-1"></a>            resp.raise_for_status()</span>
<span id="cb9-42"><a href="#cb9-42" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" tabindex="-1"></a>            content_type <span class="op">=</span> resp.headers.get(<span class="st">"Content-Type"</span>, <span class="st">""</span>)</span>
<span id="cb9-44"><a href="#cb9-44" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">"pdf"</span> <span class="kw">not</span> <span class="kw">in</span> content_type.lower() <span class="kw">and</span> <span class="kw">not</span> pdf_url.lower().endswith(<span class="st">".pdf"</span>):</span>
<span id="cb9-46"><a href="#cb9-46" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"  Warning: Content-Type for </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss"> does not look like PDF (</span><span class="sc">{</span>content_type<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb9-47"><a href="#cb9-47" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" tabindex="-1"></a>            <span class="cf">with</span> <span class="bu">open</span>(local_path, <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb9-49"><a href="#cb9-49" tabindex="-1"></a>                f.write(resp.content)</span>
<span id="cb9-50"><a href="#cb9-50" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb9-52"><a href="#cb9-52" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  -&gt; FAILED for </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-53"><a href="#cb9-53" tabindex="-1"></a>            errors.append((doc_id, <span class="bu">str</span>(e)))</span>
<span id="cb9-54"><a href="#cb9-54" tabindex="-1"></a></span>
<span id="cb9-55"><a href="#cb9-55" tabindex="-1"></a>    <span class="cf">if</span> errors:</span>
<span id="cb9-56"><a href="#cb9-56" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Some PDFs could not be downloaded:"</span>)</span>
<span id="cb9-57"><a href="#cb9-57" tabindex="-1"></a>        <span class="cf">for</span> doc_id, err <span class="kw">in</span> errors:</span>
<span id="cb9-58"><a href="#cb9-58" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>err<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-59"><a href="#cb9-59" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-60"><a href="#cb9-60" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">All PDFs downloaded successfully!"</span>)</span>
<span id="cb9-61"><a href="#cb9-61" tabindex="-1"></a></span>
<span id="cb9-62"><a href="#cb9-62" tabindex="-1"></a></span>
<span id="cb9-63"><a href="#cb9-63" tabindex="-1"></a>download_all_pdfs_from_urls(</span>
<span id="cb9-64"><a href="#cb9-64" tabindex="-1"></a>    metadata_df,</span>
<span id="cb9-65"><a href="#cb9-65" tabindex="-1"></a>    PDF_DIR,</span>
<span id="cb9-66"><a href="#cb9-66" tabindex="-1"></a>    url_col<span class="op">=</span><span class="st">"url"</span>,</span>
<span id="cb9-67"><a href="#cb9-67" tabindex="-1"></a>    id_col<span class="op">=</span><span class="st">"id"</span>,</span>
<span id="cb9-68"><a href="#cb9-68" tabindex="-1"></a>    timeout<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb9-69"><a href="#cb9-69" tabindex="-1"></a>)</span>
<span id="cb9-70"><a href="#cb9-70" tabindex="-1"></a></span>
<span id="cb9-71"><a href="#cb9-71" tabindex="-1"></a><span class="bu">len</span>(os.listdir(PDF_DIR))</span></code></pre>
</div>
<div class="section level3">
<h3 id="zip-all-pdfs-and-upload-to-s3">Zip all PDFs and upload to S3<a class="anchor" aria-label="anchor" href="#zip-all-pdfs-and-upload-to-s3"></a>
</h3>
<p>Once we have all PDFs locally, it can be convenient and efficient
to:</p>
<ol style="list-style-type: decimal">
<li>Zip them into a single file (e.g.,
<code>wattbot_pdfs.zip</code>).<br>
</li>
<li>Upload that ZIP archive to an S3 bucket, such as
<code>s3://&lt;your-wattbot-bucket&gt;/data/wattbot/wattbot_pdfs.zip</code>.</li>
</ol>
<p>We’ll include a short code example here, but feel free to skip this
during the workshop if time is tight.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="kw">def</span> zip_and_upload_pdfs(</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    local_pdf_dir: <span class="bu">str</span>,</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    bucket: <span class="bu">str</span>,</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    zip_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">"corpus.zip"</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co">    Zips all PDFs in local_pdf_dir and uploads the ZIP file to:</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="co">        s3://&lt;bucket&gt;/&lt;prefix&gt;/&lt;zip_name&gt;</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co">    Returns the full S3 URI of the uploaded zip file.</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    <span class="co"># Ensure directory exists</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(local_pdf_dir):</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Directory not found: </span><span class="sc">{</span>local_pdf_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    <span class="co"># Path for the ZIP file</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>    zip_path <span class="op">=</span> os.path.join(local_pdf_dir, zip_name)</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>    <span class="co"># Create ZIP archive</span></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>    <span class="cf">with</span> zipfile.ZipFile(zip_path, <span class="st">"w"</span>, zipfile.ZIP_DEFLATED) <span class="im">as</span> zipf:</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>        <span class="cf">for</span> fname <span class="kw">in</span> os.listdir(local_pdf_dir):</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>            <span class="cf">if</span> fname.lower().endswith(<span class="st">".pdf"</span>):</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>                fpath <span class="op">=</span> os.path.join(local_pdf_dir, fname)</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>                zipf.write(fpath, arcname<span class="op">=</span>fname)</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Added to ZIP: </span><span class="sc">{</span>fname<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ZIP created: </span><span class="sc">{</span>zip_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a></span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>    <span class="co"># Upload to S3</span></span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>    s3_client <span class="op">=</span> boto3.client(<span class="st">"s3"</span>)</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>    s3_key <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>zip_name<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a></span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Uploading to s3://</span><span class="sc">{</span>bucket<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>s3_key<span class="sc">}</span><span class="ss"> ..."</span>)</span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>    s3_client.upload_file(zip_path, bucket, s3_key)</span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Upload complete."</span>)</span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>s3_key<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" tabindex="-1"></a>zip_s3_uri <span class="op">=</span> zip_and_upload_pdfs(</span>
<span id="cb10-46"><a href="#cb10-46" tabindex="-1"></a>    local_pdf_dir<span class="op">=</span>PDF_DIR,</span>
<span id="cb10-47"><a href="#cb10-47" tabindex="-1"></a>    bucket<span class="op">=</span>bucket_name</span>
<span id="cb10-48"><a href="#cb10-48" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="step-3-turn-pdfs-into-page-level-documents">Step 3 – Turn PDFs into page-level “documents”<a class="anchor" aria-label="anchor" href="#step-3-turn-pdfs-into-page-level-documents"></a>
</h2>
<hr class="half-width">
<p>Next, we convert each PDF into a list of <strong>page-level
records</strong>. Each record stores:</p>
<ul>
<li>
<code>text</code>: page text (as extracted by
<code>pypdf</code>).</li>
<li>
<code>doc_id</code>: short ID from <code>metadata.csv</code> (e.g.,
<code>strubell2019</code>).</li>
<li>
<code>title</code>: title of the document.</li>
<li>
<code>url</code>: original PDF URL.</li>
<li>
<code>page_num</code>: zero-based page index.</li>
<li>
<code>page_label</code>: label used inside the PDF (often
1-based).</li>
</ul>
<p>Later, we will <strong>chunk these pages</strong> into smaller
overlapping segments for embedding.</p>
<div class="section level3">
<h3 id="why-we-page-chunk-first">Why we page-chunk first<a class="anchor" aria-label="anchor" href="#why-we-page-chunk-first"></a>
</h3>
<p>We split the PDF into <strong>pages before chunking</strong> because
pages give us a stable, easy-to-interpret unit.<br>
This helps with:</p>
<ul>
<li>
<strong>Keeping metadata</strong> (doc ID, URL, page labels) tied to
the text.<br>
</li>
<li>
<strong>Debugging retrieval</strong> — it’s much easier to
understand what the model saw if we know which page(s) were used.<br>
</li>
<li>
<strong>Cleaning text</strong> before making smaller overlapping
chunks.<br>
</li>
<li>
<strong>Flexibility later</strong> — once pages are structured, we
can try different chunk sizes or strategies without re-extracting the
PDF.</li>
</ul>
<p>In short: <strong>pages first → then chunks</strong> keeps the
workflow cleaner and easier to reason about.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="op">!</span>pip install pypdf</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> pypdf <span class="im">import</span> PdfReader</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="kw">def</span> pdfs_to_page_docs(metadata: pd.DataFrame, pdf_dir: <span class="bu">str</span>) <span class="op">-&gt;</span> List[Dict[<span class="bu">str</span>, Any]]:</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    <span class="co">"""Load each PDF into a list of page-level dictionaries.</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="co">    Each dict has keys: text, doc_id, title, url, page_num, page_label, total_pages.</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    page_docs: List[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> []</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> metadata.iterrows():</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>        doc_id <span class="op">=</span> <span class="bu">str</span>(row[<span class="st">"id"</span>]).strip()</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>        title <span class="op">=</span> <span class="bu">str</span>(row.get(<span class="st">"title"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>        url <span class="op">=</span> <span class="bu">str</span>(row.get(<span class="st">"url"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>        pdf_path <span class="op">=</span> os.path.join(pdf_dir, <span class="ss">f"</span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">.pdf"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> os.path.exists(pdf_path):</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Missing PDF for </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">, skipping."</span>)</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>            reader <span class="op">=</span> PdfReader(pdf_path)</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Failed to read </span><span class="sc">{</span>pdf_path<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a>        total_pages <span class="op">=</span> <span class="bu">len</span>(reader.pages)</span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>        <span class="cf">for</span> i, page <span class="kw">in</span> <span class="bu">enumerate</span>(reader.pages):</span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a>                text <span class="op">=</span> page.extract_text() <span class="kw">or</span> <span class="st">""</span></span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Failed to extract text from </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss"> page </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>                text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" tabindex="-1"></a>            text <span class="op">=</span> text.strip()</span>
<span id="cb12-35"><a href="#cb12-35" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> text:</span>
<span id="cb12-36"><a href="#cb12-36" tabindex="-1"></a>                <span class="co"># Still keep the page so we know it exists, but mark it as empty</span></span>
<span id="cb12-37"><a href="#cb12-37" tabindex="-1"></a>                text <span class="op">=</span> <span class="st">"[[EMPTY PAGE TEXT – see original PDF for tables/figures]]"</span></span>
<span id="cb12-38"><a href="#cb12-38" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" tabindex="-1"></a>            page_docs.append(</span>
<span id="cb12-40"><a href="#cb12-40" tabindex="-1"></a>                {</span>
<span id="cb12-41"><a href="#cb12-41" tabindex="-1"></a>                    <span class="st">"text"</span>: text,</span>
<span id="cb12-42"><a href="#cb12-42" tabindex="-1"></a>                    <span class="st">"doc_id"</span>: doc_id,</span>
<span id="cb12-43"><a href="#cb12-43" tabindex="-1"></a>                    <span class="st">"title"</span>: title,</span>
<span id="cb12-44"><a href="#cb12-44" tabindex="-1"></a>                    <span class="st">"url"</span>: url,</span>
<span id="cb12-45"><a href="#cb12-45" tabindex="-1"></a>                    <span class="st">"page_num"</span>: i,</span>
<span id="cb12-46"><a href="#cb12-46" tabindex="-1"></a>                    <span class="st">"page_label"</span>: <span class="bu">str</span>(i <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb12-47"><a href="#cb12-47" tabindex="-1"></a>                    <span class="st">"total_pages"</span>: total_pages,</span>
<span id="cb12-48"><a href="#cb12-48" tabindex="-1"></a>                }</span>
<span id="cb12-49"><a href="#cb12-49" tabindex="-1"></a>            )</span>
<span id="cb12-50"><a href="#cb12-50" tabindex="-1"></a></span>
<span id="cb12-51"><a href="#cb12-51" tabindex="-1"></a>    <span class="cf">return</span> page_docs</span>
<span id="cb12-52"><a href="#cb12-52" tabindex="-1"></a></span>
<span id="cb12-53"><a href="#cb12-53" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" tabindex="-1"></a>page_docs <span class="op">=</span> pdfs_to_page_docs(metadata_df, PDF_DIR)</span>
<span id="cb12-55"><a href="#cb12-55" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(page_docs)<span class="sc">}</span><span class="ss"> page-level records from </span><span class="sc">{</span><span class="bu">len</span>(metadata_df)<span class="sc">}</span><span class="ss"> PDFs."</span>)</span>
<span id="cb12-56"><a href="#cb12-56" tabindex="-1"></a>page_docs[<span class="dv">0</span>] <span class="cf">if</span> page_docs <span class="cf">else</span> <span class="va">None</span></span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="step-4-simple-explicit-text-chunking">Step 4 – Simple, explicit text chunking<a class="anchor" aria-label="anchor" href="#step-4-simple-explicit-text-chunking"></a>
</h2>
<hr class="half-width">
<p>RAG systems typically break documents into <strong>chunks</strong> so
that:</p>
<ul>
<li>Each chunk is long enough to carry meaningful context.</li>
<li>No chunk is so long that it blows up the embedding/LLM context
window.</li>
</ul>
<p>For this workshop we will implement a <strong>simple sliding-window
chunker</strong> that operates on characters:</p>
<ul>
<li>
<code>chunk_size_chars</code>: maximum characters per chunk (e.g.,
1,000–1,500).</li>
<li>
<code>chunk_overlap_chars</code>: overlap between consecutive chunks
(e.g., 200).</li>
</ul>
<p>In our own work, you may wish to plug in more sophisticated
<em>semantic chunking</em> methods(e.g., splitting on headings, section
titles, or sentence boundaries). For now, we’ll keep the implementation
explicit and easy to debug.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="kw">def</span> split_text_into_chunks(</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>    text: <span class="bu">str</span>,</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>    chunk_size_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1200</span>,</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>    chunk_overlap_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>) <span class="op">-&gt;</span> List[<span class="bu">str</span>]:</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>    <span class="co">"""Split `text` into overlapping character-based chunks.</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">    This is a simple baseline; more advanced versions might:</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">    - split on sentence boundaries, or</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">    - merge short paragraphs and respect section headings.</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>    text <span class="op">=</span> text.strip()</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> text:</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>    chunks: List[<span class="bu">str</span>] <span class="op">=</span> []</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>    start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>    text_len <span class="op">=</span> <span class="bu">len</span>(text)</span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>    <span class="cf">while</span> start <span class="op">&lt;</span> text_len:</span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>        end <span class="op">=</span> <span class="bu">min</span>(start <span class="op">+</span> chunk_size_chars, text_len)</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>        chunk <span class="op">=</span> text[start:end]</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>        chunks.append(chunk)</span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>        <span class="cf">if</span> end <span class="op">==</span> text_len:</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a>        <span class="co"># Move the window forward, keeping some overlap</span></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>        start <span class="op">=</span> end <span class="op">-</span> chunk_overlap_chars</span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a>    <span class="cf">return</span> chunks</span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a><span class="kw">def</span> make_chunked_docs(</span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>    page_docs: List[Dict[<span class="bu">str</span>, Any]],</span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a>    chunk_size_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1200</span>,</span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a>    chunk_overlap_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a>) <span class="op">-&gt;</span> List[Dict[<span class="bu">str</span>, Any]]:</span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a>    <span class="co">"""Turn page-level records into smaller overlapping text chunks.</span></span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" tabindex="-1"></a><span class="co">    Each chunk keeps a pointer back to its document and page metadata.</span></span>
<span id="cb13-40"><a href="#cb13-40" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-41"><a href="#cb13-41" tabindex="-1"></a>    chunked: List[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> []</span>
<span id="cb13-42"><a href="#cb13-42" tabindex="-1"></a>    <span class="cf">for</span> page <span class="kw">in</span> page_docs:</span>
<span id="cb13-43"><a href="#cb13-43" tabindex="-1"></a>        page_text <span class="op">=</span> page[<span class="st">"text"</span>]</span>
<span id="cb13-44"><a href="#cb13-44" tabindex="-1"></a>        chunks <span class="op">=</span> split_text_into_chunks(</span>
<span id="cb13-45"><a href="#cb13-45" tabindex="-1"></a>            page_text,</span>
<span id="cb13-46"><a href="#cb13-46" tabindex="-1"></a>            chunk_size_chars<span class="op">=</span>chunk_size_chars,</span>
<span id="cb13-47"><a href="#cb13-47" tabindex="-1"></a>            chunk_overlap_chars<span class="op">=</span>chunk_overlap_chars,</span>
<span id="cb13-48"><a href="#cb13-48" tabindex="-1"></a>        )</span>
<span id="cb13-49"><a href="#cb13-49" tabindex="-1"></a>        <span class="cf">for</span> idx, chunk_text <span class="kw">in</span> <span class="bu">enumerate</span>(chunks):</span>
<span id="cb13-50"><a href="#cb13-50" tabindex="-1"></a>            chunked.append(</span>
<span id="cb13-51"><a href="#cb13-51" tabindex="-1"></a>                {</span>
<span id="cb13-52"><a href="#cb13-52" tabindex="-1"></a>                    <span class="st">"text"</span>: chunk_text,</span>
<span id="cb13-53"><a href="#cb13-53" tabindex="-1"></a>                    <span class="st">"doc_id"</span>: page[<span class="st">"doc_id"</span>],</span>
<span id="cb13-54"><a href="#cb13-54" tabindex="-1"></a>                    <span class="st">"title"</span>: page[<span class="st">"title"</span>],</span>
<span id="cb13-55"><a href="#cb13-55" tabindex="-1"></a>                    <span class="st">"url"</span>: page[<span class="st">"url"</span>],</span>
<span id="cb13-56"><a href="#cb13-56" tabindex="-1"></a>                    <span class="st">"page_num"</span>: page[<span class="st">"page_num"</span>],</span>
<span id="cb13-57"><a href="#cb13-57" tabindex="-1"></a>                    <span class="st">"page_label"</span>: page[<span class="st">"page_label"</span>],</span>
<span id="cb13-58"><a href="#cb13-58" tabindex="-1"></a>                    <span class="st">"total_pages"</span>: page[<span class="st">"total_pages"</span>],</span>
<span id="cb13-59"><a href="#cb13-59" tabindex="-1"></a>                    <span class="st">"chunk_idx_in_page"</span>: idx,</span>
<span id="cb13-60"><a href="#cb13-60" tabindex="-1"></a>                }</span>
<span id="cb13-61"><a href="#cb13-61" tabindex="-1"></a>            )</span>
<span id="cb13-62"><a href="#cb13-62" tabindex="-1"></a>    <span class="cf">return</span> chunked</span>
<span id="cb13-63"><a href="#cb13-63" tabindex="-1"></a></span>
<span id="cb13-64"><a href="#cb13-64" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="im">import</span> os, json</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>chunks_jsonl_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"chunks.jsonl"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="kw">def</span> save_chunked_docs_jsonl(path, chunks):</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(path, <span class="st">"w"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f:</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>        <span class="cf">for</span> rec <span class="kw">in</span> chunks:</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>            json.dump(rec, f, ensure_ascii<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>            f.write(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="kw">def</span> load_chunked_docs_jsonl(path):</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(path, <span class="st">"r"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f:</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>        <span class="cf">return</span> [json.loads(line) <span class="cf">for</span> line <span class="kw">in</span> f]</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a><span class="co"># Cached chunking logic</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------</span></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a><span class="cf">if</span> os.path.exists(chunks_jsonl_path):</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Found existing chunk file: </span><span class="sc">{</span>chunks_jsonl_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>    chunked_docs <span class="op">=</span> load_chunked_docs_jsonl(chunks_jsonl_path)</span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Loaded chunked docs:"</span>, <span class="bu">len</span>(chunked_docs))</span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No chunk file found. Running chunking step..."</span>)</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    chunked_docs <span class="op">=</span> make_chunked_docs(page_docs)</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    save_chunked_docs_jsonl(chunks_jsonl_path, chunked_docs)</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Saved chunked docs to </span><span class="sc">{</span>chunks_jsonl_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a><span class="co"># Show first chunk</span></span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Raw pages:"</span>, <span class="bu">len</span>(page_docs))</span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Chunked docs:"</span>, <span class="bu">len</span>(chunked_docs))</span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>chunked_docs[<span class="dv">0</span>] <span class="cf">if</span> chunked_docs <span class="cf">else</span> <span class="va">None</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-5-build-an-embedding-matrix">Step 5 – Build an embedding matrix<a class="anchor" aria-label="anchor" href="#step-5-build-an-embedding-matrix"></a>
</h2>
<hr class="half-width">
<p>Now we embed each chunk into a vector using a
<strong>sentence-transformer</strong> model. For WattBot, a strong and
relatively efficient choice is:</p>
<div class="section level3">
<h3 id="thenlpergte-large-recommended-baseline-embedder">
<code>thenlper/gte-large</code> (Recommended baseline embedder)<a class="anchor" aria-label="anchor" href="#thenlpergte-large-recommended-baseline-embedder"></a>
</h3>
<ul>
<li><p>Size / parameters: ~335M parameters, roughly 1.3–1.4 GB in
BF16/FP16 when loaded on GPU. Fits cleanly on T4 (16 GB), L4, A10G, A10,
A100, and all g5.* instances. Offers noticeably better retrieval quality
than smaller 100M–150M models without requiring high-end GPU memory.
Runs comfortably on g4dn.xlarge, g5.xlarge, or g5.2xlarge during
workshops. Lets participants see meaningful improvements from chunking
and retrieval methods without excessive compute cost.</p></li>
<li><p>Intended use: General-purpose retrieval and semantic search
across academic PDFs, sustainability reports, and mixed-domain long-form
documents. Stronger semantic coherence than gte-base or MiniLM, but
still lightweight enough for workshop hardware.</p></li>
<li>
<p>Throughput expectations:</p>
<ul>
<li>CPU only: workable for small corpora (&lt;2k chunks) but slow for
anything larger.<br>
</li>
<li>GPU (T4, L4, A10G, A100) with batch sizes around 64–128:
<ul>
<li>20k–40k chunks/min on L4 or A10G<br>
</li>
<li>10k–15k chunks/min on T4<br>
</li>
<li>50k+ chunks/min on A100</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We will:</p>
<ol style="list-style-type: decimal">
<li>Load the embedding model on GPU if available.</li>
<li>Encode all chunks in batches.</li>
<li>Store the resulting matrix as a <code>torch.Tensor</code> or
<code>numpy.ndarray</code> along with the original
<code>chunked_docs</code> list.</li>
</ol>
<p>Later, we’ll implement a small retrieval helper that does
cosine-similarity search over this matrix—no additional indexing library
required.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="co"># We'll use a stronger embedding model now that we have a GPU.</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co"># This model has ~335M parameters and benefits from GPU acceleration,</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co"># but is still reasonable to run on a single 24 GB GPU.</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>embedding_model_id <span class="op">=</span> <span class="st">"thenlper/gte-large"</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>use_cuda_for_embeddings <span class="op">=</span> torch.cuda.is_available()</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CUDA available for embeddings:"</span>, use_cuda_for_embeddings)</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co"># Single shared embedder object that we can pass around.</span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>embedder <span class="op">=</span> SentenceTransformer(</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>    embedding_model_id,</span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a>    device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> use_cuda_for_embeddings <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>)</span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="kw">def</span> embed_texts(embedder, docs, batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span>) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>    <span class="co">"""Embed all chunk texts into a dense matrix of shape (N, D)."""</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>    texts <span class="op">=</span> [d[<span class="st">"text"</span>] <span class="cf">for</span> d <span class="kw">in</span> docs]</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>    all_embeddings <span class="op">=</span> []</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(texts), batch_size):</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>        batch <span class="op">=</span> texts[i : i <span class="op">+</span> batch_size]</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>        emb <span class="op">=</span> embedder.encode(</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>            batch,</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>            convert_to_numpy<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>            show_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>            normalize_embeddings<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a>        )</span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>        all_embeddings.append(emb)</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>    embeddings <span class="op">=</span> np.vstack(all_embeddings) <span class="cf">if</span> all_embeddings <span class="cf">else</span> np.zeros((<span class="dv">0</span>, <span class="dv">768</span>))</span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Computed embeddings for </span><span class="sc">{</span><span class="bu">len</span>(texts)<span class="sc">}</span><span class="ss"> chunks in </span><span class="sc">{</span>time<span class="sc">.</span>time() <span class="op">-</span> start<span class="sc">:.1f}</span><span class="ss">s"</span>)</span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>    <span class="cf">return</span> embeddings</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>chunk_embeddings <span class="op">=</span> embed_texts(embedder, chunked_docs)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>chunk_embeddings.shape</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="build-a-simple-retrieval-step-cosine-similarity">6. Build a simple retrieval step (cosine similarity)<a class="anchor" aria-label="anchor" href="#build-a-simple-retrieval-step-cosine-similarity"></a>
</h3>
<p>We are <strong>not</strong> using a heavy vector database in this
first episode.</p>
<p>Instead, we:</p>
<ol style="list-style-type: decimal">
<li>Embed each chunk with <code>thenlper/gte-large</code> (done
above).</li>
<li>Embed each question.</li>
<li>Compute cosine similarity between the question embedding and all
chunk embeddings.</li>
<li>Take the top–k most similar chunks as our retrieved context.</li>
</ol>
<p>This keeps the retrieval logic completely transparent for teaching,
while still matching the <em>spirit</em> of production systems that use
FAISS, Chroma, Weaviate, etc.</p>
<div class="section level4">
<h4 id="when-might-faiss-or-a-vector-database-be-worth-exploring">When might FAISS or a vector database be worth exploring?<a class="anchor" aria-label="anchor" href="#when-might-faiss-or-a-vector-database-be-worth-exploring"></a>
</h4>
<p>For small–to–medium experiments (a few thousand to maybe tens of
thousands of chunks), this “plain NumPy + cosine similarity” approach is
usually enough. You might consider FAISS or a full vector DB when:</p>
<ul>
<li><p><strong>Your corpus gets big</strong><br>
Once you’re in the hundreds of thousands to millions of chunks,
brute-force similarity search can become slow and memory-hungry. FAISS
and friends provide <em>approximate nearest neighbor</em> search that
scales much better.</p></li>
<li>
<p><strong>You need low-latency, repeated queries</strong><br>
If many users (or a web app) will hit your RAG system concurrently,
you’ll want:</p>
<ul>
<li>fast indexing,</li>
<li>efficient caching, and</li>
<li>sub-second query latency.<br>
Vector DBs are designed for this use case.</li>
</ul>
</li>
<li>
<p><strong>You need rich filtering or metadata search</strong><br>
Vector DBs often support:</p>
<ul>
<li>filtering by metadata (e.g., <code>paper = "chung2025"</code>,
<code>year &gt; 2021</code>),</li>
<li>combining keyword + vector search (“hybrid search”),</li>
<li>role-based access control and multi-tenant setups.</li>
</ul>
</li>
<li><p><strong>You want to share an index across services</strong><br>
If multiple notebooks, microservices, or teams need to reuse the
<strong>same embedding index</strong>, a shared FAISS index or hosted
vector DB is much easier to manage than passing around <code>.npy</code>
files.</p></li>
<li><p><strong>You need GPU-accelerated or distributed
search</strong><br>
FAISS can use GPUs and sharding to speed up search on very large
embedding collections. This is overkill for our teaching demo (and the
Wattbot project in general), but very relevant for production-scale
systems.</p></li>
</ul>
<p>In this episode we deliberately stick with a simple in-memory index
so the retrieval step is easy to inspect and debug. In later episodes
(or your own projects), you can <strong>swap out the retrieval
layer</strong> for FAISS or a vector DB without changing the overall RAG
architecture: the model still sees “top–k retrieved chunks” as
context.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Any</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="kw">def</span> cosine_similarity_matrix(a: np.ndarray, b: np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    <span class="co">"""Compute cosine similarity between rows of a and rows of b."""</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>    a_norm <span class="op">=</span> a <span class="op">/</span> (np.linalg.norm(a, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-12</span>)</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>    b_norm <span class="op">=</span> b <span class="op">/</span> (np.linalg.norm(b, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-12</span>)</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>    <span class="cf">return</span> np.dot(a_norm, b_norm.T)</span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a><span class="kw">def</span> retrieve_top_k(</span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>    query_embedding: np.ndarray,</span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>    chunk_embeddings: np.ndarray,</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>    chunked_docs: List[Dict[<span class="bu">str</span>, Any]],</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>    k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>) <span class="op">-&gt;</span> List[Dict[<span class="bu">str</span>, Any]]:</span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a>    <span class="co">"""Return top-k most similar chunks for a query embedding."""</span></span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a>    <span class="cf">if</span> chunk_embeddings.shape[<span class="dv">0</span>] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a>    <span class="co"># query_embedding is 1D (D,)</span></span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a>    sims <span class="op">=</span> cosine_similarity_matrix(query_embedding.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>), chunk_embeddings)[<span class="dv">0</span>]</span>
<span id="cb18-22"><a href="#cb18-22" tabindex="-1"></a>    top_idx <span class="op">=</span> np.argsort(<span class="op">-</span>sims)[:k]</span>
<span id="cb18-23"><a href="#cb18-23" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" tabindex="-1"></a>    results: List[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> []</span>
<span id="cb18-25"><a href="#cb18-25" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_idx:</span>
<span id="cb18-26"><a href="#cb18-26" tabindex="-1"></a>        doc <span class="op">=</span> chunked_docs[idx]</span>
<span id="cb18-27"><a href="#cb18-27" tabindex="-1"></a>        results.append(</span>
<span id="cb18-28"><a href="#cb18-28" tabindex="-1"></a>            {</span>
<span id="cb18-29"><a href="#cb18-29" tabindex="-1"></a>                <span class="st">"score"</span>: <span class="bu">float</span>(sims[idx]),</span>
<span id="cb18-30"><a href="#cb18-30" tabindex="-1"></a>                <span class="st">"text"</span>: doc[<span class="st">"text"</span>],</span>
<span id="cb18-31"><a href="#cb18-31" tabindex="-1"></a>                <span class="st">"doc_id"</span>: doc[<span class="st">"doc_id"</span>],</span>
<span id="cb18-32"><a href="#cb18-32" tabindex="-1"></a>                <span class="st">"page_num"</span>: doc[<span class="st">"page_num"</span>],</span>
<span id="cb18-33"><a href="#cb18-33" tabindex="-1"></a>                <span class="st">"title"</span>: doc[<span class="st">"title"</span>],</span>
<span id="cb18-34"><a href="#cb18-34" tabindex="-1"></a>                <span class="st">"url"</span>: doc[<span class="st">"url"</span>],</span>
<span id="cb18-35"><a href="#cb18-35" tabindex="-1"></a>            }</span>
<span id="cb18-36"><a href="#cb18-36" tabindex="-1"></a>        )</span>
<span id="cb18-37"><a href="#cb18-37" tabindex="-1"></a>    <span class="cf">return</span> results</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="co"># Quick sanity check for `retrieve_top_k` on the first training question</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>first_row <span class="op">=</span> train_df.iloc[<span class="dv">0</span>]</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>test_question <span class="op">=</span> first_row[<span class="st">"question"</span>]</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sample question:"</span>, test_question)</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>test_q_emb <span class="op">=</span> embedder.encode(</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>    [test_question],</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>    convert_to_numpy<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a>    normalize_embeddings<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>)[<span class="dv">0</span>]</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a>test_retrieved <span class="op">=</span> retrieve_top_k(</span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a>    query_embedding<span class="op">=</span>test_q_emb,</span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a>    chunk_embeddings<span class="op">=</span>chunk_embeddings,</span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a>    chunked_docs<span class="op">=</span>chunked_docs,</span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a>    k<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a>)</span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span><span class="bu">len</span>(test_retrieved)<span class="sc">}</span><span class="ss"> retrieved chunks:"</span>)</span>
<span id="cb19-21"><a href="#cb19-21" tabindex="-1"></a><span class="cf">for</span> r <span class="kw">in</span> test_retrieved:</span>
<span id="cb19-22"><a href="#cb19-22" tabindex="-1"></a>    snippet <span class="op">=</span> r[<span class="st">"text"</span>].replace(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>, <span class="st">" "</span>)</span>
<span id="cb19-23"><a href="#cb19-23" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(snippet) <span class="op">&gt;</span> <span class="dv">160</span>:</span>
<span id="cb19-24"><a href="#cb19-24" tabindex="-1"></a>        snippet <span class="op">=</span> snippet[:<span class="dv">160</span>] <span class="op">+</span> <span class="st">"..."</span></span>
<span id="cb19-25"><a href="#cb19-25" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"- score=</span><span class="sc">{</span>r[<span class="st">'score'</span>]<span class="sc">:.3f}</span><span class="ss"> | doc_id=</span><span class="sc">{</span>r[<span class="st">'doc_id'</span>]<span class="sc">}</span><span class="ss"> | page=</span><span class="sc">{</span>r[<span class="st">'page_num'</span>]<span class="sc">}</span><span class="ss"> | snippet=</span><span class="sc">{</span>snippet<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="load-the-qwen-model-for-answer-generation">7. Load the Qwen model for answer generation<a class="anchor" aria-label="anchor" href="#load-the-qwen-model-for-answer-generation"></a>
</h3>
<p>For this episode we use <strong>Qwen2.5-7B-Instruct</strong> via the
Hugging Face <code>transformers</code> library.</p>
<ul>
<li>Parameter count: ~7 billion.</li>
<li>VRAM needs: ~14–16 GB in bfloat16 / 4-bit; fine for
<code>ml.g5.xlarge</code> or a similar single-GPU instance.</li>
<li>Intended use here: short, grounded answers plus a normalized
<code>answer_value</code>.</li>
</ul>
<p>We will:</p>
<ol style="list-style-type: decimal">
<li>Call Qwen once to propose an answer and supporting evidence.</li>
<li>Call Qwen a <strong>second time</strong> with a smaller prompt to
generate a short explanation (&lt;= 100 characters).</li>
</ol>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer, pipeline</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>qwen_model_id <span class="op">=</span> <span class="st">"Qwen/Qwen2.5-7B-Instruct"</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>use_cuda_for_llm <span class="op">=</span> torch.cuda.is_available()</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CUDA available for LLM:"</span>, use_cuda_for_llm)</span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>tokenizer_qwen <span class="op">=</span> AutoTokenizer.from_pretrained(qwen_model_id)</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a><span class="cf">if</span> use_cuda_for_llm:</span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a>    llm_dtype <span class="op">=</span> torch.bfloat16</span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a>    model_qwen <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a>        qwen_model_id,</span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a>        dtype<span class="op">=</span>llm_dtype,</span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a>        device_map<span class="op">=</span><span class="va">None</span>,  <span class="co"># load on a single GPU</span></span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a>    ).to(<span class="st">"cuda"</span>)</span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a>    generation_device <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a>    llm_dtype <span class="op">=</span> torch.float32</span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a>    model_qwen <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a>        qwen_model_id,</span>
<span id="cb20-23"><a href="#cb20-23" tabindex="-1"></a>        dtype<span class="op">=</span>llm_dtype,</span>
<span id="cb20-24"><a href="#cb20-24" tabindex="-1"></a>        device_map<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb20-25"><a href="#cb20-25" tabindex="-1"></a>    )</span>
<span id="cb20-26"><a href="#cb20-26" tabindex="-1"></a>    generation_device <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>  <span class="co"># CPU</span></span>
<span id="cb20-27"><a href="#cb20-27" tabindex="-1"></a></span>
<span id="cb20-28"><a href="#cb20-28" tabindex="-1"></a>qwen_pipe <span class="op">=</span> pipeline(</span>
<span id="cb20-29"><a href="#cb20-29" tabindex="-1"></a>    <span class="st">"text-generation"</span>,</span>
<span id="cb20-30"><a href="#cb20-30" tabindex="-1"></a>    model<span class="op">=</span>model_qwen,</span>
<span id="cb20-31"><a href="#cb20-31" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer_qwen,</span>
<span id="cb20-32"><a href="#cb20-32" tabindex="-1"></a>    device<span class="op">=</span>generation_device,</span>
<span id="cb20-33"><a href="#cb20-33" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">384</span>,</span>
<span id="cb20-34"><a href="#cb20-34" tabindex="-1"></a>)</span>
<span id="cb20-35"><a href="#cb20-35" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" tabindex="-1"></a><span class="kw">def</span> call_qwen_chat(system_prompt: <span class="bu">str</span>, user_prompt: <span class="bu">str</span>, max_new_tokens: <span class="bu">int</span> <span class="op">=</span> <span class="dv">384</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb20-37"><a href="#cb20-37" tabindex="-1"></a>    <span class="co">"""Use Qwen chat template and return only the newly generated text."""</span></span>
<span id="cb20-38"><a href="#cb20-38" tabindex="-1"></a>    messages <span class="op">=</span> [</span>
<span id="cb20-39"><a href="#cb20-39" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: system_prompt},</span>
<span id="cb20-40"><a href="#cb20-40" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: user_prompt},</span>
<span id="cb20-41"><a href="#cb20-41" tabindex="-1"></a>    ]</span>
<span id="cb20-42"><a href="#cb20-42" tabindex="-1"></a>    prompt_text <span class="op">=</span> tokenizer_qwen.apply_chat_template(</span>
<span id="cb20-43"><a href="#cb20-43" tabindex="-1"></a>        messages,</span>
<span id="cb20-44"><a href="#cb20-44" tabindex="-1"></a>        tokenize<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb20-45"><a href="#cb20-45" tabindex="-1"></a>        add_generation_prompt<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb20-46"><a href="#cb20-46" tabindex="-1"></a>    )</span>
<span id="cb20-47"><a href="#cb20-47" tabindex="-1"></a>    outputs <span class="op">=</span> qwen_pipe(</span>
<span id="cb20-48"><a href="#cb20-48" tabindex="-1"></a>        prompt_text,</span>
<span id="cb20-49"><a href="#cb20-49" tabindex="-1"></a>        max_new_tokens<span class="op">=</span>max_new_tokens,</span>
<span id="cb20-50"><a href="#cb20-50" tabindex="-1"></a>        do_sample<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb20-51"><a href="#cb20-51" tabindex="-1"></a>    )</span>
<span id="cb20-52"><a href="#cb20-52" tabindex="-1"></a>    full <span class="op">=</span> outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>]</span>
<span id="cb20-53"><a href="#cb20-53" tabindex="-1"></a>    generated <span class="op">=</span> full[<span class="bu">len</span>(prompt_text):]</span>
<span id="cb20-54"><a href="#cb20-54" tabindex="-1"></a>    <span class="cf">return</span> generated.strip()</span>
<span id="cb20-55"><a href="#cb20-55" tabindex="-1"></a></span>
<span id="cb20-56"><a href="#cb20-56" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Generator model and helper loaded."</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a><span class="co"># Quick sanity check for `call_qwen_chat`</span></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>test_system_prompt <span class="op">=</span> <span class="st">"You are a concise assistant who answers simple questions clearly."</span></span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>test_user_prompt <span class="op">=</span> <span class="st">"What is 2 + 2? Answer in one short sentence."</span></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>test_response <span class="op">=</span> call_qwen_chat(</span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a>    system_prompt<span class="op">=</span>test_system_prompt,</span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a>    user_prompt<span class="op">=</span>test_user_prompt,</span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a>)</span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Generator (</span><span class="sc">{</span>qwen_model_id<span class="sc">}</span><span class="ss">) test response: </span><span class="sc">{</span>test_response<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="build-prompts-for-answers-and-explanations">8. Build prompts for answers and explanations<a class="anchor" aria-label="anchor" href="#build-prompts-for-answers-and-explanations"></a>
</h3>
<p>We keep the prompts <strong>very explicit</strong>:</p>
<ul>
<li>The first call asks Qwen to return JSON with:
<ul>
<li>
<code>answer</code> (short text),</li>
<li>
<code>answer_value</code> (normalized scalar or category),</li>
<li>
<code>ref_id</code> (comma‑separated doc ids,
e.g. <code>"jegham2025"</code>),</li>
<li>
<code>supporting_material</code> (short quote or paraphrase).</li>
</ul>
</li>
<li>The second call asks Qwen to generate a <strong>single sentence
explanation</strong> (&lt;= 100 characters). We will prepend an evidence
type tag (e.g. <code>[text]</code> or <code>[text+table]</code>) in code
rather than asking the model to output it.</li>
</ul>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="kw">def</span> format_context_for_prompt(retrieved_chunks):</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>    <span class="co">"""Format retrieved chunks so the LLM can see where text came from."""</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>    blocks <span class="op">=</span> []</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>    <span class="cf">for</span> r <span class="kw">in</span> retrieved_chunks:</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>        header <span class="op">=</span> <span class="ss">f"[DOC </span><span class="sc">{</span>r[<span class="st">'doc_id'</span>]<span class="sc">}</span><span class="ss"> | page </span><span class="sc">{</span>r[<span class="st">'page_num'</span>]<span class="sc">}</span><span class="ss"> | score </span><span class="sc">{</span>r[<span class="st">'score'</span>]<span class="sc">:.3f}</span><span class="ss">]"</span></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a>        blocks.append(header <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> r[<span class="st">"text"</span>])</span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>.join(blocks)</span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>explanation_system_prompt <span class="op">=</span> (</span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>    <span class="st">"You are helping annotate how an answer is supported by a research paper. "</span></span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>    <span class="st">"You will see a question, an answer, and the supporting text used. "</span></span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a>    <span class="st">"Your job is to (1) choose the MAIN type of evidence and "</span></span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a>    <span class="st">"(2) give a VERY short explanation (&lt;= 100 characters). "</span></span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>    <span class="st">"Valid evidence types are: text, figure, table, text+figure, table+figure, etc. "</span></span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a>    <span class="st">"Respond in the strict format: evidence_type: explanation"</span></span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a>)</span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a><span class="kw">def</span> build_explanation_prompt(question, answer, supporting_materials, ref_id_list):</span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>    ref_str <span class="op">=</span> <span class="st">", "</span>.join(ref_id_list) <span class="cf">if</span> ref_id_list <span class="cf">else</span> <span class="st">"unknown"</span></span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f"""Question: </span><span class="sc">{</span>question<span class="sc">}</span></span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a><span class="ss">Answer: </span><span class="sc">{</span>answer<span class="sc">}</span></span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a><span class="ss">Supporting materials:</span></span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a><span class="sc">{</span>supporting_materials<span class="sc">}</span></span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a><span class="ss">Cited document ids: </span><span class="sc">{</span>ref_str<span class="sc">}</span></span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a><span class="ss">Remember:</span></span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a><span class="ss">- evidence_type in [text, figure, table, text+figure, table+figure, etc.]</span></span>
<span id="cb22-32"><a href="#cb22-32" tabindex="-1"></a><span class="ss">- explanation &lt;= 100 characters</span></span>
<span id="cb22-33"><a href="#cb22-33" tabindex="-1"></a><span class="ss">- Format: evidence_type: explanation</span></span>
<span id="cb22-34"><a href="#cb22-34" tabindex="-1"></a><span class="ss">"""</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="run-over-the-full-wattbot-training-set">9. Run over the full WattBot training set<a class="anchor" aria-label="anchor" href="#run-over-the-full-wattbot-training-set"></a>
</h3>
<p>Now we:</p>
<ol style="list-style-type: decimal">
<li>Iterate over <strong>all</strong> questions in
<code>train_QA.csv</code>.</li>
<li>Retrieve the top-<span class="math inline">\(k\)</span> chunks for
each question.</li>
<li>Ask Qwen for an answer proposal (JSON).</li>
<li>Derive:
<ul>
<li>
<code>answer</code> and <code>answer_value</code> from the
JSON,</li>
<li>
<code>answer_unit</code> <strong>copied directly from the ground
truth</strong> (never guessed),</li>
<li>
<code>ref_id</code> from the JSON,</li>
<li>
<code>ref_url</code> by mapping <code>ref_id</code> to
<code>metadata.csv</code>,</li>
<li>
<code>supporting_material</code> from the JSON,</li>
<li>
<code>evidence_type</code> from the supporting text,</li>
<li>
<code>explanation</code> via a second Qwen call, prefixed with
<code>[evidence_type]</code>.</li>
</ul>
</li>
<li>Save <code>wattbot_solutions.csv</code> in the project folder.</li>
</ol>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="im">from</span> decimal <span class="im">import</span> Decimal</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a><span class="kw">def</span> normalize_answer_value(raw_answer_value, answer_text, answer_unit, is_blank):</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="co">    Normalize answer_value into the conventions used by train_QA:</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="co">      - 'is_blank' for unanswerable questions</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a><span class="co">      - plain numeric strings without units, commas, or scientific notation</span></span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a><span class="co">      - booleans as 1/0</span></span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a><span class="co">      - categorical strings (e.g., 'ML.ENERGY Benchmark') unchanged</span></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a><span class="co">      - ranges like '[0.02,0.1]' preserved as-is</span></span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a>    s <span class="op">=</span> <span class="bu">str</span>(raw_answer_value).strip()</span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a>    <span class="cf">if</span> is_blank:</span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> s <span class="kw">or</span> s.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a>    <span class="co"># Preserve ranges like [0.02,0.1]</span></span>
<span id="cb23-20"><a href="#cb23-20" tabindex="-1"></a>    <span class="cf">if</span> s.startswith(<span class="st">"["</span>) <span class="kw">and</span> s.endswith(<span class="st">"]"</span>):</span>
<span id="cb23-21"><a href="#cb23-21" tabindex="-1"></a>        <span class="cf">return</span> s</span>
<span id="cb23-22"><a href="#cb23-22" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" tabindex="-1"></a>    lower <span class="op">=</span> s.lower()</span>
<span id="cb23-24"><a href="#cb23-24" tabindex="-1"></a></span>
<span id="cb23-25"><a href="#cb23-25" tabindex="-1"></a>    <span class="co"># Booleans -&gt; 1/0</span></span>
<span id="cb23-26"><a href="#cb23-26" tabindex="-1"></a>    <span class="cf">if</span> lower <span class="kw">in</span> {<span class="st">"true"</span>, <span class="st">"false"</span>}:</span>
<span id="cb23-27"><a href="#cb23-27" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"1"</span> <span class="cf">if</span> lower <span class="op">==</span> <span class="st">"true"</span> <span class="cf">else</span> <span class="st">"0"</span></span>
<span id="cb23-28"><a href="#cb23-28" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" tabindex="-1"></a>    <span class="co"># Pure categorical (no digits) -&gt; leave as-is</span></span>
<span id="cb23-30"><a href="#cb23-30" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">any</span>(ch.isdigit() <span class="cf">for</span> ch <span class="kw">in</span> s):</span>
<span id="cb23-31"><a href="#cb23-31" tabindex="-1"></a>        <span class="cf">return</span> s</span>
<span id="cb23-32"><a href="#cb23-32" tabindex="-1"></a></span>
<span id="cb23-33"><a href="#cb23-33" tabindex="-1"></a>    <span class="co"># Try to extract the first numeric token from either the raw string or the answer text</span></span>
<span id="cb23-34"><a href="#cb23-34" tabindex="-1"></a>    txt_candidates <span class="op">=</span> [s, <span class="bu">str</span>(answer_text)]</span>
<span id="cb23-35"><a href="#cb23-35" tabindex="-1"></a>    match <span class="op">=</span> <span class="va">None</span></span>
<span id="cb23-36"><a href="#cb23-36" tabindex="-1"></a>    <span class="cf">for</span> txt <span class="kw">in</span> txt_candidates:</span>
<span id="cb23-37"><a href="#cb23-37" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> txt:</span>
<span id="cb23-38"><a href="#cb23-38" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb23-39"><a href="#cb23-39" tabindex="-1"></a>        match <span class="op">=</span> re.search(<span class="vs">r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?"</span>, <span class="bu">str</span>(txt).replace(<span class="st">","</span>, <span class="st">""</span>))</span>
<span id="cb23-40"><a href="#cb23-40" tabindex="-1"></a>        <span class="cf">if</span> match:</span>
<span id="cb23-41"><a href="#cb23-41" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb23-42"><a href="#cb23-42" tabindex="-1"></a></span>
<span id="cb23-43"><a href="#cb23-43" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> match:</span>
<span id="cb23-44"><a href="#cb23-44" tabindex="-1"></a>        <span class="co"># Fallback: strip obvious formatting characters</span></span>
<span id="cb23-45"><a href="#cb23-45" tabindex="-1"></a>        cleaned <span class="op">=</span> s.replace(<span class="st">","</span>, <span class="st">""</span>).replace(<span class="st">"%"</span>, <span class="st">""</span>).strip()</span>
<span id="cb23-46"><a href="#cb23-46" tabindex="-1"></a>        <span class="cf">return</span> cleaned <span class="kw">or</span> <span class="st">"is_blank"</span></span>
<span id="cb23-47"><a href="#cb23-47" tabindex="-1"></a></span>
<span id="cb23-48"><a href="#cb23-48" tabindex="-1"></a>    num_str <span class="op">=</span> match.group(<span class="dv">0</span>)</span>
<span id="cb23-49"><a href="#cb23-49" tabindex="-1"></a></span>
<span id="cb23-50"><a href="#cb23-50" tabindex="-1"></a>    <span class="co"># Format without scientific notation, trim trailing zeros</span></span>
<span id="cb23-51"><a href="#cb23-51" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb23-52"><a href="#cb23-52" tabindex="-1"></a>        d <span class="op">=</span> Decimal(num_str)</span>
<span id="cb23-53"><a href="#cb23-53" tabindex="-1"></a>        normalized <span class="op">=</span> <span class="bu">format</span>(d.normalize(), <span class="st">"f"</span>)</span>
<span id="cb23-54"><a href="#cb23-54" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb23-55"><a href="#cb23-55" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb23-56"><a href="#cb23-56" tabindex="-1"></a>            f <span class="op">=</span> <span class="bu">float</span>(num_str)</span>
<span id="cb23-57"><a href="#cb23-57" tabindex="-1"></a>            normalized <span class="op">=</span> (<span class="st">"</span><span class="sc">%.15f</span><span class="st">"</span> <span class="op">%</span> f).rstrip(<span class="st">"0"</span>).rstrip(<span class="st">"."</span>)</span>
<span id="cb23-58"><a href="#cb23-58" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb23-59"><a href="#cb23-59" tabindex="-1"></a>            normalized <span class="op">=</span> num_str</span>
<span id="cb23-60"><a href="#cb23-60" tabindex="-1"></a></span>
<span id="cb23-61"><a href="#cb23-61" tabindex="-1"></a>    <span class="cf">return</span> normalized</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="running-the-full-rag-pipeline-for-one-question">Running the full RAG pipeline for one question<a class="anchor" aria-label="anchor" href="#running-the-full-rag-pipeline-for-one-question"></a>
</h3>
<p>At this point we have all the building blocks we need:</p>
<ul>
<li>an <strong>embedder</strong> to turn questions into vectors<br>
</li>
<li>a <strong>retriever</strong> (<code>retrieve_top_k</code>) to grab
the most relevant text chunks<br>
</li>
<li>a <strong>chat helper</strong> (<code>call_qwen_chat</code>) to talk
to Qwen and get JSON back<br>
</li>
<li>a small post-processing helper (<code>normalize_answer_value</code>)
to clean numbers</li>
</ul>
<p>In the next few cells we tie these pieces together. We keep the code
split into small helper functions so learners can follow each step:</p>
<ol style="list-style-type: decimal">
<li>Retrieve context for a question.<br>
</li>
<li>Ask the LLM for an answer, references, and a quote.<br>
</li>
<li>Clean and normalize the structured fields (answer_value, ref_id,
is_blank).<br>
</li>
<li>Ask a second LLM call for a short explanation and evidence
type.</li>
</ol>
</div>
<div class="section level3">
<h3 id="retrieving-relevant-context">🔍 Retrieving Relevant Context<a class="anchor" aria-label="anchor" href="#retrieving-relevant-context"></a>
</h3>
<p>This function embeds the question and fetches the top‐K most relevant
text chunks. It’s the first step of the RAG pipeline and determines what
evidence the LLM can see.</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="co"># Build a lookup from document id -&gt; URL using metadata</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>docid_to_url <span class="op">=</span> {</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>    <span class="bu">str</span>(row[<span class="st">"id"</span>]).strip(): row[<span class="st">"url"</span>]</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> metadata_df.iterrows()</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(row.get(<span class="st">"url"</span>, <span class="va">None</span>), <span class="bu">str</span>)</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>}</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a><span class="kw">def</span> retrieve_context_for_question(question, embedder, chunk_embeddings, chunked_docs, top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>):</span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>    <span class="co">"""Embed the question and retrieve the top-k most similar chunks."""</span></span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>    q_emb <span class="op">=</span> embedder.encode(</span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a>        [question],</span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a>        convert_to_numpy<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a>        normalize_embeddings<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a>    )[<span class="dv">0</span>]</span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a>    retrieved <span class="op">=</span> retrieve_top_k(q_emb, chunk_embeddings, chunked_docs, k<span class="op">=</span>top_k)</span>
<span id="cb24-16"><a href="#cb24-16" tabindex="-1"></a>    context <span class="op">=</span> format_context_for_prompt(retrieved)</span>
<span id="cb24-17"><a href="#cb24-17" tabindex="-1"></a>    <span class="cf">return</span> retrieved, context</span>
<span id="cb24-18"><a href="#cb24-18" tabindex="-1"></a></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="first-llm-step-producing-an-answer">First LLM Step: Producing an Answer<a class="anchor" aria-label="anchor" href="#first-llm-step-producing-an-answer"></a>
</h3>
<p>Here we prompt the model to: - Decide if the question is answerable -
Extract a numeric/categorical answer - Identify supporting evidence -
Select relevant document IDs</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="kw">def</span> answer_phase_for_question(qid, question, answer_unit, context):</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="co">    First LLM call: ask Qwen for an answer, answer_value, is_blank, ref_ids,</span></span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a><span class="co">    and a short supporting quote. Then normalize these fields.</span></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a>    <span class="co"># System prompt: what role Qwen should play</span></span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>    system_prompt_answer <span class="op">=</span> (</span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a>        <span class="st">"You answer questions about AI energy, carbon, and water from academic papers.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a>        <span class="st">"You are given:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a>        <span class="st">"- a question</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a>        <span class="st">"- retrieved text chunks from the relevant paper(s)</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a>        <span class="st">"You must:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a>        <span class="st">"1. Decide if the question can be answered from the provided context.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a>        <span class="st">"2. If answerable, extract a concise numeric or short-text answer_value.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a>        <span class="st">"3. Use the provided answer_unit EXACTLY as given (do NOT invent units).</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a>        <span class="st">"4. Select one or more document ids as ref_id from the supplied chunks.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-17"><a href="#cb25-17" tabindex="-1"></a>        <span class="st">"5. Copy a short supporting quote (&lt;= 300 chars) into supporting_materials.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-18"><a href="#cb25-18" tabindex="-1"></a>        <span class="st">"6. If the context is insufficient, mark is_blank = true and set all</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-19"><a href="#cb25-19" tabindex="-1"></a>        <span class="st">"   other fields to 'is_blank' except answer_unit (keep it as provided).</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-20"><a href="#cb25-20" tabindex="-1"></a>        <span class="st">"Return a JSON object with fields:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-21"><a href="#cb25-21" tabindex="-1"></a>        <span class="st">"  answer (string)</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-22"><a href="#cb25-22" tabindex="-1"></a>        <span class="st">"  answer_value (string)</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-23"><a href="#cb25-23" tabindex="-1"></a>        <span class="st">"  is_blank (true or false)</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-24"><a href="#cb25-24" tabindex="-1"></a>        <span class="st">"  ref_id (list of doc_id strings)</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-25"><a href="#cb25-25" tabindex="-1"></a>        <span class="st">"  supporting_materials (string)</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb25-26"><a href="#cb25-26" tabindex="-1"></a>    )</span>
<span id="cb25-27"><a href="#cb25-27" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" tabindex="-1"></a>    context_block <span class="op">=</span> context <span class="cf">if</span> context.strip() <span class="cf">else</span> <span class="st">"[NO CONTEXT FOUND]"</span></span>
<span id="cb25-29"><a href="#cb25-29" tabindex="-1"></a></span>
<span id="cb25-30"><a href="#cb25-30" tabindex="-1"></a>    <span class="co"># User prompt: question + unit hint + retrieved context</span></span>
<span id="cb25-31"><a href="#cb25-31" tabindex="-1"></a>    user_prompt_answer <span class="op">=</span> <span class="ss">f"""Question: </span><span class="sc">{</span>question<span class="sc">}</span></span>
<span id="cb25-32"><a href="#cb25-32" tabindex="-1"></a><span class="ss">Expected answer unit: </span><span class="sc">{</span>answer_unit<span class="sc">}</span></span>
<span id="cb25-33"><a href="#cb25-33" tabindex="-1"></a></span>
<span id="cb25-34"><a href="#cb25-34" tabindex="-1"></a><span class="ss">Retrieved context:</span></span>
<span id="cb25-35"><a href="#cb25-35" tabindex="-1"></a><span class="sc">{</span>context_block<span class="sc">}</span></span>
<span id="cb25-36"><a href="#cb25-36" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" tabindex="-1"></a><span class="ss">Return JSON ONLY with keys:</span></span>
<span id="cb25-38"><a href="#cb25-38" tabindex="-1"></a><span class="ss">  answer (string)</span></span>
<span id="cb25-39"><a href="#cb25-39" tabindex="-1"></a><span class="ss">  answer_value (string)</span></span>
<span id="cb25-40"><a href="#cb25-40" tabindex="-1"></a><span class="ss">  is_blank (true or false)</span></span>
<span id="cb25-41"><a href="#cb25-41" tabindex="-1"></a><span class="ss">  ref_id (list of doc_id strings)</span></span>
<span id="cb25-42"><a href="#cb25-42" tabindex="-1"></a><span class="ss">  supporting_materials (string)</span></span>
<span id="cb25-43"><a href="#cb25-43" tabindex="-1"></a><span class="ss">"""</span></span>
<span id="cb25-44"><a href="#cb25-44" tabindex="-1"></a></span>
<span id="cb25-45"><a href="#cb25-45" tabindex="-1"></a>    raw_answer <span class="op">=</span> call_qwen_chat(system_prompt_answer, user_prompt_answer, max_new_tokens<span class="op">=</span><span class="dv">384</span>)</span>
<span id="cb25-46"><a href="#cb25-46" tabindex="-1"></a></span>
<span id="cb25-47"><a href="#cb25-47" tabindex="-1"></a>    <span class="co"># Try to parse JSON from the model output</span></span>
<span id="cb25-48"><a href="#cb25-48" tabindex="-1"></a>    parsed <span class="op">=</span> {</span>
<span id="cb25-49"><a href="#cb25-49" tabindex="-1"></a>        <span class="st">"answer"</span>: <span class="st">""</span>,</span>
<span id="cb25-50"><a href="#cb25-50" tabindex="-1"></a>        <span class="st">"answer_value"</span>: <span class="st">"is_blank"</span>,</span>
<span id="cb25-51"><a href="#cb25-51" tabindex="-1"></a>        <span class="st">"is_blank"</span>: <span class="va">True</span>,</span>
<span id="cb25-52"><a href="#cb25-52" tabindex="-1"></a>        <span class="st">"ref_id"</span>: [],</span>
<span id="cb25-53"><a href="#cb25-53" tabindex="-1"></a>        <span class="st">"supporting_materials"</span>: <span class="st">"is_blank"</span>,</span>
<span id="cb25-54"><a href="#cb25-54" tabindex="-1"></a>    }</span>
<span id="cb25-55"><a href="#cb25-55" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb25-56"><a href="#cb25-56" tabindex="-1"></a>        first_brace <span class="op">=</span> raw_answer.find(<span class="st">"{"</span>)</span>
<span id="cb25-57"><a href="#cb25-57" tabindex="-1"></a>        last_brace <span class="op">=</span> raw_answer.rfind(<span class="st">"}"</span>)</span>
<span id="cb25-58"><a href="#cb25-58" tabindex="-1"></a>        <span class="cf">if</span> first_brace <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">and</span> last_brace <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb25-59"><a href="#cb25-59" tabindex="-1"></a>            json_str <span class="op">=</span> raw_answer[first_brace : last_brace <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb25-60"><a href="#cb25-60" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-61"><a href="#cb25-61" tabindex="-1"></a>            json_str <span class="op">=</span> raw_answer</span>
<span id="cb25-62"><a href="#cb25-62" tabindex="-1"></a>        candidate <span class="op">=</span> json.loads(json_str)</span>
<span id="cb25-63"><a href="#cb25-63" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(candidate, <span class="bu">dict</span>):</span>
<span id="cb25-64"><a href="#cb25-64" tabindex="-1"></a>            parsed.update(candidate)</span>
<span id="cb25-65"><a href="#cb25-65" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb25-66"><a href="#cb25-66" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"JSON parse error for question </span><span class="sc">{</span>qid<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-67"><a href="#cb25-67" tabindex="-1"></a>        <span class="co"># fall back to defaults in `parsed`</span></span>
<span id="cb25-68"><a href="#cb25-68" tabindex="-1"></a></span>
<span id="cb25-69"><a href="#cb25-69" tabindex="-1"></a>    <span class="co"># Normalize parsed fields</span></span>
<span id="cb25-70"><a href="#cb25-70" tabindex="-1"></a>    is_blank <span class="op">=</span> <span class="bu">bool</span>(parsed.get(<span class="st">"is_blank"</span>, <span class="va">False</span>))</span>
<span id="cb25-71"><a href="#cb25-71" tabindex="-1"></a>    ref_ids <span class="op">=</span> parsed.get(<span class="st">"ref_id"</span>) <span class="kw">or</span> []</span>
<span id="cb25-72"><a href="#cb25-72" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(ref_ids, <span class="bu">str</span>):</span>
<span id="cb25-73"><a href="#cb25-73" tabindex="-1"></a>        ref_ids <span class="op">=</span> [ref_ids]</span>
<span id="cb25-74"><a href="#cb25-74" tabindex="-1"></a>    ref_ids <span class="op">=</span> [<span class="bu">str</span>(r).strip() <span class="cf">for</span> r <span class="kw">in</span> ref_ids <span class="cf">if</span> <span class="bu">str</span>(r).strip()]</span>
<span id="cb25-75"><a href="#cb25-75" tabindex="-1"></a></span>
<span id="cb25-76"><a href="#cb25-76" tabindex="-1"></a>    answer <span class="op">=</span> <span class="bu">str</span>(parsed.get(<span class="st">"answer"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb25-77"><a href="#cb25-77" tabindex="-1"></a>    answer_value <span class="op">=</span> <span class="bu">str</span>(parsed.get(<span class="st">"answer_value"</span>, <span class="st">""</span>)).strip() <span class="kw">or</span> <span class="st">"is_blank"</span></span>
<span id="cb25-78"><a href="#cb25-78" tabindex="-1"></a>    answer_value <span class="op">=</span> normalize_answer_value(</span>
<span id="cb25-79"><a href="#cb25-79" tabindex="-1"></a>        raw_answer_value<span class="op">=</span>answer_value,</span>
<span id="cb25-80"><a href="#cb25-80" tabindex="-1"></a>        answer_text<span class="op">=</span>answer,</span>
<span id="cb25-81"><a href="#cb25-81" tabindex="-1"></a>        answer_unit<span class="op">=</span>answer_unit,</span>
<span id="cb25-82"><a href="#cb25-82" tabindex="-1"></a>        is_blank<span class="op">=</span>is_blank,</span>
<span id="cb25-83"><a href="#cb25-83" tabindex="-1"></a>    )</span>
<span id="cb25-84"><a href="#cb25-84" tabindex="-1"></a>    supporting_materials <span class="op">=</span> <span class="bu">str</span>(parsed.get(<span class="st">"supporting_materials"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb25-85"><a href="#cb25-85" tabindex="-1"></a></span>
<span id="cb25-86"><a href="#cb25-86" tabindex="-1"></a>    <span class="co"># If context is empty or model says blank, force is_blank behaviour</span></span>
<span id="cb25-87"><a href="#cb25-87" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> context.strip() <span class="kw">or</span> is_blank:</span>
<span id="cb25-88"><a href="#cb25-88" tabindex="-1"></a>        is_blank <span class="op">=</span> <span class="va">True</span></span>
<span id="cb25-89"><a href="#cb25-89" tabindex="-1"></a>        answer <span class="op">=</span> <span class="st">""</span></span>
<span id="cb25-90"><a href="#cb25-90" tabindex="-1"></a>        answer_value <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb25-91"><a href="#cb25-91" tabindex="-1"></a>        ref_ids <span class="op">=</span> []</span>
<span id="cb25-92"><a href="#cb25-92" tabindex="-1"></a>        supporting_materials <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb25-93"><a href="#cb25-93" tabindex="-1"></a></span>
<span id="cb25-94"><a href="#cb25-94" tabindex="-1"></a>    <span class="co"># String formatting for ref_id / ref_url to match training style</span></span>
<span id="cb25-95"><a href="#cb25-95" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ref_ids:</span>
<span id="cb25-96"><a href="#cb25-96" tabindex="-1"></a>        ref_id_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb25-97"><a href="#cb25-97" tabindex="-1"></a>        ref_url_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb25-98"><a href="#cb25-98" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb25-99"><a href="#cb25-99" tabindex="-1"></a>        ref_id_str <span class="op">=</span> <span class="bu">str</span>(ref_ids)</span>
<span id="cb25-100"><a href="#cb25-100" tabindex="-1"></a></span>
<span id="cb25-101"><a href="#cb25-101" tabindex="-1"></a>        <span class="co"># Resolve ref_url via metadata</span></span>
<span id="cb25-102"><a href="#cb25-102" tabindex="-1"></a>        ref_url <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb25-103"><a href="#cb25-103" tabindex="-1"></a>        <span class="cf">for</span> rid <span class="kw">in</span> ref_ids:</span>
<span id="cb25-104"><a href="#cb25-104" tabindex="-1"></a>            <span class="cf">if</span> rid <span class="kw">in</span> docid_to_url:</span>
<span id="cb25-105"><a href="#cb25-105" tabindex="-1"></a>                ref_url <span class="op">=</span> docid_to_url[rid]</span>
<span id="cb25-106"><a href="#cb25-106" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb25-107"><a href="#cb25-107" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> ref_url:</span>
<span id="cb25-108"><a href="#cb25-108" tabindex="-1"></a>            ref_url <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb25-109"><a href="#cb25-109" tabindex="-1"></a>        ref_url_str <span class="op">=</span> <span class="bu">str</span>([ref_url])</span>
<span id="cb25-110"><a href="#cb25-110" tabindex="-1"></a></span>
<span id="cb25-111"><a href="#cb25-111" tabindex="-1"></a>    <span class="cf">return</span> answer, answer_value, is_blank, ref_ids, supporting_materials, ref_id_str, ref_url_str</span>
<span id="cb25-112"><a href="#cb25-112" tabindex="-1"></a></span>
<span id="cb25-113"><a href="#cb25-113" tabindex="-1"></a></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="second-llm-step-explanation-and-evidence-type">Second LLM Step: Explanation and Evidence Type<a class="anchor" aria-label="anchor" href="#second-llm-step-explanation-and-evidence-type"></a>
</h3>
<p>Now that we have an answer, we produce a short explanation and
classify the evidence type. This step matches WattBot’s expected
metadata.</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="kw">def</span> explanation_phase_for_question(question, answer, supporting_materials, ref_ids, is_blank):</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a><span class="co">    Second LLM call: ask Qwen to label an evidence_type and provide a short</span></span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a><span class="co">    explanation tying the answer back to the supporting materials.</span></span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>    <span class="cf">if</span> is_blank:</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a>        <span class="co"># For unanswerable questions we just propagate a sentinel.</span></span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a>        evidence_type <span class="op">=</span> <span class="st">"other"</span></span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a>        explanation <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a>        <span class="cf">return</span> evidence_type, explanation</span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a></span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a>    expl_user_prompt <span class="op">=</span> build_explanation_prompt(</span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a>        question<span class="op">=</span>question,</span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a>        answer<span class="op">=</span>answer,</span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a>        supporting_materials<span class="op">=</span>supporting_materials,</span>
<span id="cb26-16"><a href="#cb26-16" tabindex="-1"></a>        ref_id_list<span class="op">=</span>ref_ids,</span>
<span id="cb26-17"><a href="#cb26-17" tabindex="-1"></a>    )</span>
<span id="cb26-18"><a href="#cb26-18" tabindex="-1"></a>    raw_expl <span class="op">=</span> call_qwen_chat(</span>
<span id="cb26-19"><a href="#cb26-19" tabindex="-1"></a>        explanation_system_prompt,</span>
<span id="cb26-20"><a href="#cb26-20" tabindex="-1"></a>        expl_user_prompt,</span>
<span id="cb26-21"><a href="#cb26-21" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb26-22"><a href="#cb26-22" tabindex="-1"></a>    )</span>
<span id="cb26-23"><a href="#cb26-23" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" tabindex="-1"></a>    <span class="co"># Take the first non-empty line (we expect something like "text: short reason")</span></span>
<span id="cb26-25"><a href="#cb26-25" tabindex="-1"></a>    first_line <span class="op">=</span> <span class="st">""</span></span>
<span id="cb26-26"><a href="#cb26-26" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> raw_expl.splitlines():</span>
<span id="cb26-27"><a href="#cb26-27" tabindex="-1"></a>        <span class="cf">if</span> line.strip():</span>
<span id="cb26-28"><a href="#cb26-28" tabindex="-1"></a>            first_line <span class="op">=</span> line.strip()</span>
<span id="cb26-29"><a href="#cb26-29" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb26-30"><a href="#cb26-30" tabindex="-1"></a></span>
<span id="cb26-31"><a href="#cb26-31" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">":"</span> <span class="kw">in</span> first_line:</span>
<span id="cb26-32"><a href="#cb26-32" tabindex="-1"></a>        etype, expl <span class="op">=</span> first_line.split(<span class="st">":"</span>, <span class="dv">1</span>)</span>
<span id="cb26-33"><a href="#cb26-33" tabindex="-1"></a>        evidence_type <span class="op">=</span> etype.strip().lower() <span class="kw">or</span> <span class="st">"other"</span></span>
<span id="cb26-34"><a href="#cb26-34" tabindex="-1"></a>        explanation <span class="op">=</span> expl.strip()</span>
<span id="cb26-35"><a href="#cb26-35" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb26-36"><a href="#cb26-36" tabindex="-1"></a>        evidence_type <span class="op">=</span> <span class="st">"other"</span></span>
<span id="cb26-37"><a href="#cb26-37" tabindex="-1"></a>        explanation <span class="op">=</span> first_line.strip() <span class="kw">or</span> <span class="st">"short justification"</span></span>
<span id="cb26-38"><a href="#cb26-38" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" tabindex="-1"></a>    <span class="co"># Keep explanations short for the CSV</span></span>
<span id="cb26-40"><a href="#cb26-40" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(explanation) <span class="op">&gt;</span> <span class="dv">100</span>:</span>
<span id="cb26-41"><a href="#cb26-41" tabindex="-1"></a>        explanation <span class="op">=</span> explanation[:<span class="dv">100</span>]</span>
<span id="cb26-42"><a href="#cb26-42" tabindex="-1"></a></span>
<span id="cb26-43"><a href="#cb26-43" tabindex="-1"></a>    <span class="cf">return</span> evidence_type, explanation</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="orchestration-run_single_qa">Orchestration: <code>run_single_qa</code>
<a class="anchor" aria-label="anchor" href="#orchestration-run_single_qa"></a>
</h3>
<p>This high‐level function ties together retrieval, answering,
normalization, and explanation into one full pass over a single
question.</p>
</div>
<div class="section level3">
<h3 id="handling-unanswerable-questions">Handling unanswerable questions<a class="anchor" aria-label="anchor" href="#handling-unanswerable-questions"></a>
</h3>
<p>Some WattBot questions truly <strong>cannot</strong> be answered from
the retrieved papers.<br>
We use a simple hybrid rule to detect these cases:</p>
<ul>
<li>We look at the <strong>top retrieval score</strong> (cosine
similarity).<br>
</li>
<li>We also use the LLM’s own <code>is_blank</code> flag from the first
JSON response.</li>
</ul>
<p>If <strong>either</strong> of these says the evidence is too weak, we
mark the question as unanswerable and set all relevant fields
(<code>answer_value</code>, <code>ref_id</code>,
<code>supporting_materials</code>) to <code>is_blank</code>.</p>
<p>The <code>THRESHOLD</code> inside <code>run_single_qa</code> controls
how strict this behaviour is:</p>
<ul>
<li>lower values → fewer questions marked unanswerable<br>
</li>
<li>higher values → more questions marked unanswerable</li>
</ul>
<p>You can change <code>THRESHOLD</code> and then re-run the notebook
and <code>Score.py</code> to see how this trade-off affects your final
WattBot score.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="kw">def</span> run_single_qa(</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>    row,</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>    embedder,</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>    chunk_embeddings,</span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>    chunked_docs,</span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>    top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>):</span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a>    <span class="co">"""Run retrieval + Qwen for a single training QA row.</span></span>
<span id="cb27-10"><a href="#cb27-10" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" tabindex="-1"></a><span class="co">    This is the high-level orchestration function that calls three helpers:</span></span>
<span id="cb27-12"><a href="#cb27-12" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" tabindex="-1"></a><span class="co">    1. retrieve_context_for_question  -&gt; get relevant text chunks</span></span>
<span id="cb27-14"><a href="#cb27-14" tabindex="-1"></a><span class="co">    2. answer_phase_for_question      -&gt; generate answer from context, returning citations and supporting materials</span></span>
<span id="cb27-15"><a href="#cb27-15" tabindex="-1"></a><span class="co">    3. explanation_phase_for_question -&gt; evidence type + short explanation</span></span>
<span id="cb27-16"><a href="#cb27-16" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb27-17"><a href="#cb27-17" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" tabindex="-1"></a>    <span class="co"># Confidence threshold for retrieval.</span></span>
<span id="cb27-19"><a href="#cb27-19" tabindex="-1"></a>    <span class="co"># If the top similarity score is below this value, we treat the question</span></span>
<span id="cb27-20"><a href="#cb27-20" tabindex="-1"></a>    <span class="co"># as unanswerable, even if the LLM tried to produce an answer.</span></span>
<span id="cb27-21"><a href="#cb27-21" tabindex="-1"></a>    THRESHOLD <span class="op">=</span> <span class="fl">0.25</span></span>
<span id="cb27-22"><a href="#cb27-22" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" tabindex="-1"></a>    qid <span class="op">=</span> row[<span class="st">"id"</span>]</span>
<span id="cb27-24"><a href="#cb27-24" tabindex="-1"></a>    question <span class="op">=</span> row[<span class="st">"question"</span>]</span>
<span id="cb27-25"><a href="#cb27-25" tabindex="-1"></a>    answer_unit <span class="op">=</span> row.get(<span class="st">"answer_unit"</span>, <span class="st">""</span>)</span>
<span id="cb27-26"><a href="#cb27-26" tabindex="-1"></a></span>
<span id="cb27-27"><a href="#cb27-27" tabindex="-1"></a>    <span class="co"># 1. Retrieval step</span></span>
<span id="cb27-28"><a href="#cb27-28" tabindex="-1"></a>    retrieved, context <span class="op">=</span> retrieve_context_for_question(</span>
<span id="cb27-29"><a href="#cb27-29" tabindex="-1"></a>        question<span class="op">=</span>question,</span>
<span id="cb27-30"><a href="#cb27-30" tabindex="-1"></a>        embedder<span class="op">=</span>embedder,</span>
<span id="cb27-31"><a href="#cb27-31" tabindex="-1"></a>        chunk_embeddings<span class="op">=</span>chunk_embeddings,</span>
<span id="cb27-32"><a href="#cb27-32" tabindex="-1"></a>        chunked_docs<span class="op">=</span>chunked_docs,</span>
<span id="cb27-33"><a href="#cb27-33" tabindex="-1"></a>        top_k<span class="op">=</span>top_k,</span>
<span id="cb27-34"><a href="#cb27-34" tabindex="-1"></a>    )</span>
<span id="cb27-35"><a href="#cb27-35" tabindex="-1"></a></span>
<span id="cb27-36"><a href="#cb27-36" tabindex="-1"></a>    top_score <span class="op">=</span> retrieved[<span class="dv">0</span>][<span class="st">"score"</span>] <span class="cf">if</span> retrieved <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb27-37"><a href="#cb27-37" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" tabindex="-1"></a>    <span class="co"># 2. Answer + refs + supporting materials (LLM's view)</span></span>
<span id="cb27-39"><a href="#cb27-39" tabindex="-1"></a>    (</span>
<span id="cb27-40"><a href="#cb27-40" tabindex="-1"></a>        answer,</span>
<span id="cb27-41"><a href="#cb27-41" tabindex="-1"></a>        answer_value,</span>
<span id="cb27-42"><a href="#cb27-42" tabindex="-1"></a>        is_blank_llm,</span>
<span id="cb27-43"><a href="#cb27-43" tabindex="-1"></a>        ref_ids,</span>
<span id="cb27-44"><a href="#cb27-44" tabindex="-1"></a>        supporting_materials,</span>
<span id="cb27-45"><a href="#cb27-45" tabindex="-1"></a>        ref_id_str,</span>
<span id="cb27-46"><a href="#cb27-46" tabindex="-1"></a>        ref_url_str,</span>
<span id="cb27-47"><a href="#cb27-47" tabindex="-1"></a>    ) <span class="op">=</span> answer_phase_for_question(</span>
<span id="cb27-48"><a href="#cb27-48" tabindex="-1"></a>        qid<span class="op">=</span>qid,</span>
<span id="cb27-49"><a href="#cb27-49" tabindex="-1"></a>        question<span class="op">=</span>question,</span>
<span id="cb27-50"><a href="#cb27-50" tabindex="-1"></a>        answer_unit<span class="op">=</span>answer_unit,</span>
<span id="cb27-51"><a href="#cb27-51" tabindex="-1"></a>        context<span class="op">=</span>context,</span>
<span id="cb27-52"><a href="#cb27-52" tabindex="-1"></a>    )</span>
<span id="cb27-53"><a href="#cb27-53" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" tabindex="-1"></a>    <span class="co"># Hybrid is_blank decision:</span></span>
<span id="cb27-55"><a href="#cb27-55" tabindex="-1"></a>    <span class="co"># - if retrieval is weak (top_score &lt; THRESHOLD)</span></span>
<span id="cb27-56"><a href="#cb27-56" tabindex="-1"></a>    <span class="co"># - OR the LLM marks is_blank = true</span></span>
<span id="cb27-57"><a href="#cb27-57" tabindex="-1"></a>    <span class="co"># then we treat the question as unanswerable.</span></span>
<span id="cb27-58"><a href="#cb27-58" tabindex="-1"></a>    is_blank <span class="op">=</span> <span class="bu">bool</span>(is_blank_llm) <span class="kw">or</span> (top_score <span class="op">&lt;</span> THRESHOLD)</span>
<span id="cb27-59"><a href="#cb27-59" tabindex="-1"></a></span>
<span id="cb27-60"><a href="#cb27-60" tabindex="-1"></a>    <span class="cf">if</span> is_blank:</span>
<span id="cb27-61"><a href="#cb27-61" tabindex="-1"></a>        answer <span class="op">=</span> <span class="st">""</span></span>
<span id="cb27-62"><a href="#cb27-62" tabindex="-1"></a>        answer_value <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb27-63"><a href="#cb27-63" tabindex="-1"></a>        ref_ids <span class="op">=</span> []</span>
<span id="cb27-64"><a href="#cb27-64" tabindex="-1"></a>        ref_id_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb27-65"><a href="#cb27-65" tabindex="-1"></a>        ref_url_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb27-66"><a href="#cb27-66" tabindex="-1"></a>        supporting_materials <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb27-67"><a href="#cb27-67" tabindex="-1"></a></span>
<span id="cb27-68"><a href="#cb27-68" tabindex="-1"></a>    <span class="co"># Always copy answer_unit from train_QA.csv (do NOT let the LLM invent it)</span></span>
<span id="cb27-69"><a href="#cb27-69" tabindex="-1"></a>    answer_unit <span class="op">=</span> row.get(<span class="st">"answer_unit"</span>, <span class="st">""</span>)</span>
<span id="cb27-70"><a href="#cb27-70" tabindex="-1"></a></span>
<span id="cb27-71"><a href="#cb27-71" tabindex="-1"></a>    <span class="co"># 3. Explanation + evidence_type</span></span>
<span id="cb27-72"><a href="#cb27-72" tabindex="-1"></a>    evidence_type, explanation <span class="op">=</span> explanation_phase_for_question(</span>
<span id="cb27-73"><a href="#cb27-73" tabindex="-1"></a>        question<span class="op">=</span>question,</span>
<span id="cb27-74"><a href="#cb27-74" tabindex="-1"></a>        answer<span class="op">=</span>answer,</span>
<span id="cb27-75"><a href="#cb27-75" tabindex="-1"></a>        supporting_materials<span class="op">=</span>supporting_materials,</span>
<span id="cb27-76"><a href="#cb27-76" tabindex="-1"></a>        ref_ids<span class="op">=</span>ref_ids,</span>
<span id="cb27-77"><a href="#cb27-77" tabindex="-1"></a>        is_blank<span class="op">=</span>is_blank,</span>
<span id="cb27-78"><a href="#cb27-78" tabindex="-1"></a>    )</span>
<span id="cb27-79"><a href="#cb27-79" tabindex="-1"></a></span>
<span id="cb27-80"><a href="#cb27-80" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb27-81"><a href="#cb27-81" tabindex="-1"></a>        <span class="st">"id"</span>: qid,</span>
<span id="cb27-82"><a href="#cb27-82" tabindex="-1"></a>        <span class="st">"question"</span>: question,</span>
<span id="cb27-83"><a href="#cb27-83" tabindex="-1"></a>        <span class="st">"answer"</span>: answer,</span>
<span id="cb27-84"><a href="#cb27-84" tabindex="-1"></a>        <span class="st">"answer_value"</span>: answer_value,</span>
<span id="cb27-85"><a href="#cb27-85" tabindex="-1"></a>        <span class="st">"answer_unit"</span>: answer_unit,</span>
<span id="cb27-86"><a href="#cb27-86" tabindex="-1"></a>        <span class="st">"is_blank"</span>: <span class="st">"true"</span> <span class="cf">if</span> is_blank <span class="cf">else</span> <span class="st">"false"</span>,</span>
<span id="cb27-87"><a href="#cb27-87" tabindex="-1"></a>        <span class="st">"ref_id"</span>: ref_id_str,</span>
<span id="cb27-88"><a href="#cb27-88" tabindex="-1"></a>        <span class="st">"ref_url"</span>: ref_url_str,</span>
<span id="cb27-89"><a href="#cb27-89" tabindex="-1"></a>        <span class="st">"supporting_materials"</span>: supporting_materials,</span>
<span id="cb27-90"><a href="#cb27-90" tabindex="-1"></a>        <span class="st">"evidence_type"</span>: evidence_type,</span>
<span id="cb27-91"><a href="#cb27-91" tabindex="-1"></a>        <span class="st">"explanation"</span>: explanation,</span>
<span id="cb27-92"><a href="#cb27-92" tabindex="-1"></a>    }</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------</span></span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a><span class="co"># Run over max_N training questions (this can take a while!)</span></span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------</span></span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a>all_results <span class="op">=</span> []</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a>error_log <span class="op">=</span> []</span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a>max_N <span class="op">=</span> np.inf</span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a><span class="cf">for</span> idx, row <span class="kw">in</span> train_df.iterrows():</span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">&gt;=</span> max_N:</span>
<span id="cb28-10"><a href="#cb28-10" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb28-11"><a href="#cb28-11" tabindex="-1"></a>    question <span class="op">=</span> row[<span class="st">"question"</span>]</span>
<span id="cb28-12"><a href="#cb28-12" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"########################################################################################################</span><span class="ch">\n</span><span class="ss">QUESTION: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-13"><a href="#cb28-13" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" tabindex="-1"></a>    res <span class="op">=</span> run_single_qa(</span>
<span id="cb28-15"><a href="#cb28-15" tabindex="-1"></a>        row<span class="op">=</span>row,</span>
<span id="cb28-16"><a href="#cb28-16" tabindex="-1"></a>        embedder<span class="op">=</span>embedder,</span>
<span id="cb28-17"><a href="#cb28-17" tabindex="-1"></a>        chunk_embeddings<span class="op">=</span>chunk_embeddings,</span>
<span id="cb28-18"><a href="#cb28-18" tabindex="-1"></a>        chunked_docs<span class="op">=</span>chunked_docs,</span>
<span id="cb28-19"><a href="#cb28-19" tabindex="-1"></a>        top_k<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb28-20"><a href="#cb28-20" tabindex="-1"></a>    )</span>
<span id="cb28-21"><a href="#cb28-21" tabindex="-1"></a>    answer <span class="op">=</span> res[<span class="st">"answer"</span>]</span>
<span id="cb28-22"><a href="#cb28-22" tabindex="-1"></a>    ref_ids <span class="op">=</span> res[<span class="st">"ref_id"</span>]</span>
<span id="cb28-23"><a href="#cb28-23" tabindex="-1"></a></span>
<span id="cb28-24"><a href="#cb28-24" tabindex="-1"></a>    explanation <span class="op">=</span> res[<span class="st">"explanation"</span>]</span>
<span id="cb28-25"><a href="#cb28-25" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"ANSWER: </span><span class="sc">{</span>answer<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-26"><a href="#cb28-26" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"ref_ids: </span><span class="sc">{</span>ref_ids<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-27"><a href="#cb28-27" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"EXPLANATION: </span><span class="sc">{</span>explanation<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-28"><a href="#cb28-28" tabindex="-1"></a>    </span>
<span id="cb28-29"><a href="#cb28-29" tabindex="-1"></a>    all_results.append(res)</span>
<span id="cb28-30"><a href="#cb28-30" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" tabindex="-1"></a>solutions_df <span class="op">=</span> pd.DataFrame(all_results)</span>
<span id="cb28-32"><a href="#cb28-32" tabindex="-1"></a>solutions_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"train_solutions_qwen.csv"</span>)</span>
<span id="cb28-33"><a href="#cb28-33" tabindex="-1"></a>solutions_df.to_csv(solutions_path, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb28-34"><a href="#cb28-34" tabindex="-1"></a></span>
<span id="cb28-35"><a href="#cb28-35" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Saved solutions for </span><span class="sc">{</span><span class="bu">len</span>(solutions_df)<span class="sc">}</span><span class="ss"> questions to: </span><span class="sc">{</span>solutions_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-36"><a href="#cb28-36" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of questions with errors (filled as blank): </span><span class="sc">{</span><span class="bu">len</span>(error_log)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-37"><a href="#cb28-37" tabindex="-1"></a></span>
<span id="cb28-38"><a href="#cb28-38" tabindex="-1"></a>solutions_df.head(<span class="dv">20</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="compare-answers-to-ground-truth">Compare answers to ground truth<a class="anchor" aria-label="anchor" href="#compare-answers-to-ground-truth"></a>
</h3>
<p>WattBot evaluates each prediction using a weighted score that
combines three components. Most of the credit (0.75) comes from the
<code>answer_value</code>, which must match the ground truth after
normalization (numeric answers must be within ±0.1% relative tolerance;
categorical values must match exactly). An additional 0.15 comes from
<code>ref_id</code>, where partial credit is given based on the Jaccard
overlap between your cited document IDs and the ground-truth set. The
final 0.10 comes from correctly marking unanswerable questions: if a
question is truly unanswerable, you must set <code>answer_value</code>,
<code>ref_id</code>, and <code>supporting_materials</code> to
<code>is_blank</code>. Any other combination scores zero for this
component.</p>
<table class="table">
<colgroup>
<col width="33%">
<col width="16%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>Component</th>
<th>Weight</th>
<th>What counts as correct</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>answer_value</td>
<td>0.75</td>
<td>Numeric within ±0.1% relative tolerance; categorical exact match;
<code>is_blank</code> if unanswerable</td>
</tr>
<tr class="even">
<td>ref_id</td>
<td>0.15</td>
<td>Jaccard overlap with the ground-truth reference set
(case-insensitive)</td>
</tr>
<tr class="odd">
<td>is_NA</td>
<td>0.10</td>
<td>All required fields set to <code>is_blank</code> when the question
is truly unanswerable</td>
</tr>
</tbody>
</table>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a><span class="kw">def</span> _to_bool_flag(x):</span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>    <span class="co">"""Convert typical truthy/falsey strings to bool."""</span></span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(x, <span class="bu">str</span>):</span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a>        s <span class="op">=</span> x.strip().lower()</span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">in</span> {<span class="st">"1"</span>, <span class="st">"True"</span>, <span class="st">"true"</span>, <span class="st">"yes"</span>}:</span>
<span id="cb29-9"><a href="#cb29-9" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb29-10"><a href="#cb29-10" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">in</span> {<span class="st">"0"</span>, <span class="st">"False"</span>, <span class="st">"false"</span>, <span class="st">"no"</span>}:</span>
<span id="cb29-11"><a href="#cb29-11" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb29-12"><a href="#cb29-12" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">bool</span>(x)</span>
<span id="cb29-13"><a href="#cb29-13" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" tabindex="-1"></a><span class="kw">def</span> _parse_float_or_none(x):</span>
<span id="cb29-15"><a href="#cb29-15" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb29-16"><a href="#cb29-16" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">float</span>(<span class="bu">str</span>(x).strip())</span>
<span id="cb29-17"><a href="#cb29-17" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb29-18"><a href="#cb29-18" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb29-19"><a href="#cb29-19" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" tabindex="-1"></a><span class="kw">def</span> _answer_value_correct(gt_val, pred_val, rel_tol<span class="op">=</span><span class="fl">1e-3</span>):</span>
<span id="cb29-21"><a href="#cb29-21" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb29-22"><a href="#cb29-22" tabindex="-1"></a><span class="co">    gt_val, pred_val: values from answer_value columns.</span></span>
<span id="cb29-23"><a href="#cb29-23" tabindex="-1"></a><span class="co">    rel_tol = 0.001 =&gt; 0.1% relative tolerance.</span></span>
<span id="cb29-24"><a href="#cb29-24" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-25"><a href="#cb29-25" tabindex="-1"></a>    gt_str <span class="op">=</span> <span class="bu">str</span>(gt_val).strip()</span>
<span id="cb29-26"><a href="#cb29-26" tabindex="-1"></a>    pred_str <span class="op">=</span> <span class="bu">str</span>(pred_val).strip()</span>
<span id="cb29-27"><a href="#cb29-27" tabindex="-1"></a>    </span>
<span id="cb29-28"><a href="#cb29-28" tabindex="-1"></a>    <span class="co"># If either is 'is_blank', treat as categorical</span></span>
<span id="cb29-29"><a href="#cb29-29" tabindex="-1"></a>    <span class="cf">if</span> gt_str.lower() <span class="op">==</span> <span class="st">"is_blank"</span> <span class="kw">or</span> pred_str.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb29-30"><a href="#cb29-30" tabindex="-1"></a>        <span class="cf">return</span> gt_str.lower() <span class="op">==</span> pred_str.lower()</span>
<span id="cb29-31"><a href="#cb29-31" tabindex="-1"></a>    </span>
<span id="cb29-32"><a href="#cb29-32" tabindex="-1"></a>    gt_num <span class="op">=</span> _parse_float_or_none(gt_val)</span>
<span id="cb29-33"><a href="#cb29-33" tabindex="-1"></a>    pred_num <span class="op">=</span> _parse_float_or_none(pred_val)</span>
<span id="cb29-34"><a href="#cb29-34" tabindex="-1"></a>    </span>
<span id="cb29-35"><a href="#cb29-35" tabindex="-1"></a>    <span class="co"># If both numeric, use relative tolerance</span></span>
<span id="cb29-36"><a href="#cb29-36" tabindex="-1"></a>    <span class="cf">if</span> gt_num <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_num <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb29-37"><a href="#cb29-37" tabindex="-1"></a>        <span class="cf">if</span> gt_num <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb29-38"><a href="#cb29-38" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">abs</span>(pred_num <span class="op">-</span> gt_num) <span class="op">&lt;=</span> rel_tol  <span class="co"># small absolute tolerance around 0</span></span>
<span id="cb29-39"><a href="#cb29-39" tabindex="-1"></a>        rel_err <span class="op">=</span> <span class="bu">abs</span>(pred_num <span class="op">-</span> gt_num) <span class="op">/</span> <span class="bu">max</span>(<span class="bu">abs</span>(gt_num), <span class="fl">1e-12</span>)</span>
<span id="cb29-40"><a href="#cb29-40" tabindex="-1"></a>        <span class="cf">return</span> rel_err <span class="op">&lt;=</span> rel_tol</span>
<span id="cb29-41"><a href="#cb29-41" tabindex="-1"></a>    </span>
<span id="cb29-42"><a href="#cb29-42" tabindex="-1"></a>    <span class="co"># Otherwise, fall back to normalized string match</span></span>
<span id="cb29-43"><a href="#cb29-43" tabindex="-1"></a>    <span class="cf">return</span> gt_str.lower() <span class="op">==</span> pred_str.lower()</span>
<span id="cb29-44"><a href="#cb29-44" tabindex="-1"></a></span>
<span id="cb29-45"><a href="#cb29-45" tabindex="-1"></a><span class="kw">def</span> _ref_id_jaccard(gt_ref, pred_ref):</span>
<span id="cb29-46"><a href="#cb29-46" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb29-47"><a href="#cb29-47" tabindex="-1"></a><span class="co">    Jaccard overlap between sets of ref_ids.</span></span>
<span id="cb29-48"><a href="#cb29-48" tabindex="-1"></a><span class="co">    Strings may contain semicolon-separated IDs, or 'is_blank'.</span></span>
<span id="cb29-49"><a href="#cb29-49" tabindex="-1"></a><span class="co">    Case-insensitive.</span></span>
<span id="cb29-50"><a href="#cb29-50" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-51"><a href="#cb29-51" tabindex="-1"></a>    <span class="kw">def</span> to_set(s):</span>
<span id="cb29-52"><a href="#cb29-52" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb29-53"><a href="#cb29-53" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">set</span>()</span>
<span id="cb29-54"><a href="#cb29-54" tabindex="-1"></a>        s <span class="op">=</span> <span class="bu">str</span>(s).strip()</span>
<span id="cb29-55"><a href="#cb29-55" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> s <span class="kw">or</span> s.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb29-56"><a href="#cb29-56" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">set</span>()</span>
<span id="cb29-57"><a href="#cb29-57" tabindex="-1"></a>        parts <span class="op">=</span> [p.strip().lower() <span class="cf">for</span> p <span class="kw">in</span> s.split(<span class="st">";"</span>) <span class="cf">if</span> p.strip()]</span>
<span id="cb29-58"><a href="#cb29-58" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">set</span>(parts)</span>
<span id="cb29-59"><a href="#cb29-59" tabindex="-1"></a>    </span>
<span id="cb29-60"><a href="#cb29-60" tabindex="-1"></a>    gt_set <span class="op">=</span> to_set(gt_ref)</span>
<span id="cb29-61"><a href="#cb29-61" tabindex="-1"></a>    pred_set <span class="op">=</span> to_set(pred_ref)</span>
<span id="cb29-62"><a href="#cb29-62" tabindex="-1"></a>    </span>
<span id="cb29-63"><a href="#cb29-63" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> gt_set <span class="kw">and</span> <span class="kw">not</span> pred_set:</span>
<span id="cb29-64"><a href="#cb29-64" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1.0</span></span>
<span id="cb29-65"><a href="#cb29-65" tabindex="-1"></a>    union <span class="op">=</span> gt_set <span class="op">|</span> pred_set</span>
<span id="cb29-66"><a href="#cb29-66" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> union:</span>
<span id="cb29-67"><a href="#cb29-67" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.0</span></span>
<span id="cb29-68"><a href="#cb29-68" tabindex="-1"></a>    inter <span class="op">=</span> gt_set <span class="op">&amp;</span> pred_set</span>
<span id="cb29-69"><a href="#cb29-69" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(inter) <span class="op">/</span> <span class="bu">len</span>(union)</span>
<span id="cb29-70"><a href="#cb29-70" tabindex="-1"></a></span>
<span id="cb29-71"><a href="#cb29-71" tabindex="-1"></a><span class="kw">def</span> compute_wattbot_score(</span>
<span id="cb29-72"><a href="#cb29-72" tabindex="-1"></a>    train_qa_path<span class="op">=</span><span class="st">"train_QA.csv"</span>,</span>
<span id="cb29-73"><a href="#cb29-73" tabindex="-1"></a>    preds_path<span class="op">=</span><span class="st">"train_solutions_qwen.csv"</span>,</span>
<span id="cb29-74"><a href="#cb29-74" tabindex="-1"></a>    id_col<span class="op">=</span><span class="st">"id"</span>,</span>
<span id="cb29-75"><a href="#cb29-75" tabindex="-1"></a>    gt_answer_col<span class="op">=</span><span class="st">"answer_value"</span>,</span>
<span id="cb29-76"><a href="#cb29-76" tabindex="-1"></a>    gt_ref_col<span class="op">=</span><span class="st">"ref_id"</span>,</span>
<span id="cb29-77"><a href="#cb29-77" tabindex="-1"></a>    gt_is_na_col<span class="op">=</span><span class="st">"is_NA"</span>,   <span class="co"># can also pass "is_blank" or None</span></span>
<span id="cb29-78"><a href="#cb29-78" tabindex="-1"></a>    pred_answer_col<span class="op">=</span><span class="st">"answer_value"</span>,</span>
<span id="cb29-79"><a href="#cb29-79" tabindex="-1"></a>    pred_ref_col<span class="op">=</span><span class="st">"ref_id"</span>,</span>
<span id="cb29-80"><a href="#cb29-80" tabindex="-1"></a>    pred_is_na_col<span class="op">=</span><span class="va">None</span>,    <span class="co"># can pass "is_blank", or leave None to auto</span></span>
<span id="cb29-81"><a href="#cb29-81" tabindex="-1"></a>    n_examples<span class="op">=</span><span class="dv">10</span>,          <span class="co"># how many incorrect examples to print</span></span>
<span id="cb29-82"><a href="#cb29-82" tabindex="-1"></a>):</span>
<span id="cb29-83"><a href="#cb29-83" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb29-84"><a href="#cb29-84" tabindex="-1"></a><span class="co">    Compare your solutions to train_QA.csv using a WattBot-style score.</span></span>
<span id="cb29-85"><a href="#cb29-85" tabindex="-1"></a></span>
<span id="cb29-86"><a href="#cb29-86" tabindex="-1"></a><span class="co">    NA logic:</span></span>
<span id="cb29-87"><a href="#cb29-87" tabindex="-1"></a><span class="co">    - If an explicit NA column is found/used (e.g. is_NA), we use it via _to_bool_flag.</span></span>
<span id="cb29-88"><a href="#cb29-88" tabindex="-1"></a><span class="co">    - If you pass gt_is_na_col="is_blank" or pred_is_na_col="is_blank",</span></span>
<span id="cb29-89"><a href="#cb29-89" tabindex="-1"></a><span class="co">      we *derive* NA from answer_value == "is_blank" instead of expecting a real column.</span></span>
<span id="cb29-90"><a href="#cb29-90" tabindex="-1"></a><span class="co">    - If no NA column is available at all, we derive from answer_value == "is_blank".</span></span>
<span id="cb29-91"><a href="#cb29-91" tabindex="-1"></a></span>
<span id="cb29-92"><a href="#cb29-92" tabindex="-1"></a><span class="co">    Also prints up to `n_examples` rows where the model is not perfect</span></span>
<span id="cb29-93"><a href="#cb29-93" tabindex="-1"></a><span class="co">    (answer_score &lt; 1, ref_id_score &lt; 1, or is_NA_score &lt; 1).</span></span>
<span id="cb29-94"><a href="#cb29-94" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-95"><a href="#cb29-95" tabindex="-1"></a>    gt <span class="op">=</span> pd.read_csv(train_qa_path)</span>
<span id="cb29-96"><a href="#cb29-96" tabindex="-1"></a>    preds <span class="op">=</span> pd.read_csv(preds_path)</span>
<span id="cb29-97"><a href="#cb29-97" tabindex="-1"></a>    </span>
<span id="cb29-98"><a href="#cb29-98" tabindex="-1"></a>    <span class="co"># Inner join on id to be strict</span></span>
<span id="cb29-99"><a href="#cb29-99" tabindex="-1"></a>    merged <span class="op">=</span> gt.merge(preds, on<span class="op">=</span>id_col, suffixes<span class="op">=</span>(<span class="st">"_gt"</span>, <span class="st">"_pred"</span>))</span>
<span id="cb29-100"><a href="#cb29-100" tabindex="-1"></a>    <span class="cf">if</span> merged.empty:</span>
<span id="cb29-101"><a href="#cb29-101" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"No overlapping ids between ground truth and predictions."</span>)</span>
<span id="cb29-102"><a href="#cb29-102" tabindex="-1"></a></span>
<span id="cb29-103"><a href="#cb29-103" tabindex="-1"></a>    <span class="co"># ----- ground truth NA flags -----</span></span>
<span id="cb29-104"><a href="#cb29-104" tabindex="-1"></a>    <span class="cf">if</span> gt_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> gt_is_na_col <span class="kw">in</span> merged.columns:</span>
<span id="cb29-105"><a href="#cb29-105" tabindex="-1"></a>        <span class="co"># Use explicit column (e.g. "is_NA")</span></span>
<span id="cb29-106"><a href="#cb29-106" tabindex="-1"></a>        gt_is_na_series <span class="op">=</span> merged[gt_is_na_col].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb29-107"><a href="#cb29-107" tabindex="-1"></a>    <span class="cf">elif</span> gt_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> gt_is_na_col.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb29-108"><a href="#cb29-108" tabindex="-1"></a>        <span class="co"># Special meaning: derive NA from answer_value_gt == "is_blank"</span></span>
<span id="cb29-109"><a href="#cb29-109" tabindex="-1"></a>        gt_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb29-110"><a href="#cb29-110" tabindex="-1"></a>        merged[<span class="st">"gt_is_blank_flag"</span>] <span class="op">=</span> gt_is_na_series</span>
<span id="cb29-111"><a href="#cb29-111" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb29-112"><a href="#cb29-112" tabindex="-1"></a>        <span class="co"># Fallback: if we have is_NA or is_blank col, use it; else derive</span></span>
<span id="cb29-113"><a href="#cb29-113" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"is_NA"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb29-114"><a href="#cb29-114" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="st">"is_NA"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb29-115"><a href="#cb29-115" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">"is_blank"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb29-116"><a href="#cb29-116" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="st">"is_blank"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb29-117"><a href="#cb29-117" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-118"><a href="#cb29-118" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb29-119"><a href="#cb29-119" tabindex="-1"></a>            merged[<span class="st">"gt_is_blank_flag"</span>] <span class="op">=</span> gt_is_na_series</span>
<span id="cb29-120"><a href="#cb29-120" tabindex="-1"></a></span>
<span id="cb29-121"><a href="#cb29-121" tabindex="-1"></a>    <span class="co"># ----- prediction NA flags -----</span></span>
<span id="cb29-122"><a href="#cb29-122" tabindex="-1"></a>    <span class="cf">if</span> pred_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_is_na_col <span class="kw">in</span> merged.columns:</span>
<span id="cb29-123"><a href="#cb29-123" tabindex="-1"></a>        pred_is_na_series <span class="op">=</span> merged[pred_is_na_col].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb29-124"><a href="#cb29-124" tabindex="-1"></a>    <span class="cf">elif</span> pred_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_is_na_col.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb29-125"><a href="#cb29-125" tabindex="-1"></a>        <span class="co"># Same convention: derive from answer_value_pred</span></span>
<span id="cb29-126"><a href="#cb29-126" tabindex="-1"></a>        pred_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb29-127"><a href="#cb29-127" tabindex="-1"></a>        merged[<span class="st">"pred_is_blank_flag"</span>] <span class="op">=</span> pred_is_na_series</span>
<span id="cb29-128"><a href="#cb29-128" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb29-129"><a href="#cb29-129" tabindex="-1"></a>        <span class="co"># Auto-detect or derive if no NA column in preds</span></span>
<span id="cb29-130"><a href="#cb29-130" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"is_NA"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb29-131"><a href="#cb29-131" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="st">"is_NA"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb29-132"><a href="#cb29-132" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">"is_blank"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb29-133"><a href="#cb29-133" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="st">"is_blank"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb29-134"><a href="#cb29-134" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-135"><a href="#cb29-135" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb29-136"><a href="#cb29-136" tabindex="-1"></a>            merged[<span class="st">"pred_is_blank_flag"</span>] <span class="op">=</span> pred_is_na_series</span>
<span id="cb29-137"><a href="#cb29-137" tabindex="-1"></a></span>
<span id="cb29-138"><a href="#cb29-138" tabindex="-1"></a>    ans_scores <span class="op">=</span> []</span>
<span id="cb29-139"><a href="#cb29-139" tabindex="-1"></a>    ref_scores <span class="op">=</span> []</span>
<span id="cb29-140"><a href="#cb29-140" tabindex="-1"></a>    na_scores <span class="op">=</span> []</span>
<span id="cb29-141"><a href="#cb29-141" tabindex="-1"></a>    </span>
<span id="cb29-142"><a href="#cb29-142" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> merged.iterrows():</span>
<span id="cb29-143"><a href="#cb29-143" tabindex="-1"></a>        gt_ans <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>]</span>
<span id="cb29-144"><a href="#cb29-144" tabindex="-1"></a>        pred_ans <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>]</span>
<span id="cb29-145"><a href="#cb29-145" tabindex="-1"></a>        gt_ref <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>gt_ref_col<span class="sc">}</span><span class="ss">_gt"</span>]</span>
<span id="cb29-146"><a href="#cb29-146" tabindex="-1"></a>        pred_ref <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>pred_ref_col<span class="sc">}</span><span class="ss">_pred"</span>]</span>
<span id="cb29-147"><a href="#cb29-147" tabindex="-1"></a>        </span>
<span id="cb29-148"><a href="#cb29-148" tabindex="-1"></a>        gt_is_na <span class="op">=</span> <span class="bu">bool</span>(gt_is_na_series.iloc[idx])</span>
<span id="cb29-149"><a href="#cb29-149" tabindex="-1"></a>        pred_is_na <span class="op">=</span> <span class="bu">bool</span>(pred_is_na_series.iloc[idx])</span>
<span id="cb29-150"><a href="#cb29-150" tabindex="-1"></a>        </span>
<span id="cb29-151"><a href="#cb29-151" tabindex="-1"></a>        <span class="co"># 1. answer_value component</span></span>
<span id="cb29-152"><a href="#cb29-152" tabindex="-1"></a>        ans_correct <span class="op">=</span> _answer_value_correct(gt_ans, pred_ans)</span>
<span id="cb29-153"><a href="#cb29-153" tabindex="-1"></a>        ans_scores.append(<span class="fl">1.0</span> <span class="op">*</span> ans_correct)</span>
<span id="cb29-154"><a href="#cb29-154" tabindex="-1"></a>        </span>
<span id="cb29-155"><a href="#cb29-155" tabindex="-1"></a>        <span class="co"># 2. ref_id Jaccard</span></span>
<span id="cb29-156"><a href="#cb29-156" tabindex="-1"></a>        ref_j <span class="op">=</span> _ref_id_jaccard(gt_ref, pred_ref)</span>
<span id="cb29-157"><a href="#cb29-157" tabindex="-1"></a>        ref_scores.append(ref_j)</span>
<span id="cb29-158"><a href="#cb29-158" tabindex="-1"></a>        </span>
<span id="cb29-159"><a href="#cb29-159" tabindex="-1"></a>        <span class="co"># 3. is_NA component (simple: must match ground truth flag)</span></span>
<span id="cb29-160"><a href="#cb29-160" tabindex="-1"></a>        na_scores.append(<span class="fl">1.0</span> <span class="cf">if</span> gt_is_na <span class="op">==</span> pred_is_na <span class="cf">else</span> <span class="fl">0.0</span>)</span>
<span id="cb29-161"><a href="#cb29-161" tabindex="-1"></a>    </span>
<span id="cb29-162"><a href="#cb29-162" tabindex="-1"></a>    merged[<span class="st">"answer_score"</span>] <span class="op">=</span> ans_scores</span>
<span id="cb29-163"><a href="#cb29-163" tabindex="-1"></a>    merged[<span class="st">"ref_id_score"</span>] <span class="op">=</span> ref_scores</span>
<span id="cb29-164"><a href="#cb29-164" tabindex="-1"></a>    merged[<span class="st">"is_NA_score"</span>] <span class="op">=</span> na_scores</span>
<span id="cb29-165"><a href="#cb29-165" tabindex="-1"></a>    </span>
<span id="cb29-166"><a href="#cb29-166" tabindex="-1"></a>    merged[<span class="st">"wattbot_score"</span>] <span class="op">=</span> (</span>
<span id="cb29-167"><a href="#cb29-167" tabindex="-1"></a>        <span class="fl">0.75</span> <span class="op">*</span> merged[<span class="st">"answer_score"</span>]</span>
<span id="cb29-168"><a href="#cb29-168" tabindex="-1"></a>        <span class="op">+</span> <span class="fl">0.15</span> <span class="op">*</span> merged[<span class="st">"ref_id_score"</span>]</span>
<span id="cb29-169"><a href="#cb29-169" tabindex="-1"></a>        <span class="op">+</span> <span class="fl">0.10</span> <span class="op">*</span> merged[<span class="st">"is_NA_score"</span>]</span>
<span id="cb29-170"><a href="#cb29-170" tabindex="-1"></a>    )</span>
<span id="cb29-171"><a href="#cb29-171" tabindex="-1"></a>    </span>
<span id="cb29-172"><a href="#cb29-172" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Rows compared: </span><span class="sc">{</span><span class="bu">len</span>(merged)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-173"><a href="#cb29-173" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean answer_value score: </span><span class="sc">{</span>merged[<span class="st">'answer_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb29-174"><a href="#cb29-174" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean ref_id score:       </span><span class="sc">{</span>merged[<span class="st">'ref_id_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb29-175"><a href="#cb29-175" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean is_NA score:        </span><span class="sc">{</span>merged[<span class="st">'is_NA_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb29-176"><a href="#cb29-176" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Overall WattBot score:   </span><span class="sc">{</span>merged[<span class="st">'wattbot_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb29-177"><a href="#cb29-177" tabindex="-1"></a>    </span>
<span id="cb29-178"><a href="#cb29-178" tabindex="-1"></a>    <span class="co"># ----- Show some incorrect examples -----</span></span>
<span id="cb29-179"><a href="#cb29-179" tabindex="-1"></a>    incorrect <span class="op">=</span> merged[</span>
<span id="cb29-180"><a href="#cb29-180" tabindex="-1"></a>        (merged[<span class="st">"answer_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb29-181"><a href="#cb29-181" tabindex="-1"></a>        <span class="op">|</span> (merged[<span class="st">"ref_id_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb29-182"><a href="#cb29-182" tabindex="-1"></a>        <span class="op">|</span> (merged[<span class="st">"is_NA_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb29-183"><a href="#cb29-183" tabindex="-1"></a>    ]</span>
<span id="cb29-184"><a href="#cb29-184" tabindex="-1"></a>    </span>
<span id="cb29-185"><a href="#cb29-185" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> incorrect.empty <span class="kw">and</span> n_examples <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb29-186"><a href="#cb29-186" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Examples of incorrect / partially correct responses "</span></span>
<span id="cb29-187"><a href="#cb29-187" tabindex="-1"></a>              <span class="ss">f"(up to </span><span class="sc">{</span>n_examples<span class="sc">}</span><span class="ss"> rows):</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb29-188"><a href="#cb29-188" tabindex="-1"></a>        <span class="co"># Grab up to n_examples "worst" rows by wattbot_score</span></span>
<span id="cb29-189"><a href="#cb29-189" tabindex="-1"></a>        <span class="cf">for</span> _, row <span class="kw">in</span> incorrect.sort_values(<span class="st">"wattbot_score"</span>).head(n_examples).iterrows():</span>
<span id="cb29-190"><a href="#cb29-190" tabindex="-1"></a>            q <span class="op">=</span> row[<span class="st">"question_gt"</span>] <span class="cf">if</span> <span class="st">"question_gt"</span> <span class="kw">in</span> row.index <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb29-191"><a href="#cb29-191" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb29-192"><a href="#cb29-192" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"id: </span><span class="sc">{</span>row[id_col]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-193"><a href="#cb29-193" tabindex="-1"></a>            <span class="cf">if</span> q <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb29-194"><a href="#cb29-194" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>q<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-195"><a href="#cb29-195" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"GT answer_value:   </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-196"><a href="#cb29-196" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Pred answer_value: </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-197"><a href="#cb29-197" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"GT ref_id:         </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>gt_ref_col<span class="sc">}</span><span class="ss">_gt'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-198"><a href="#cb29-198" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Pred ref_id:       </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>pred_ref_col<span class="sc">}</span><span class="ss">_pred'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-199"><a href="#cb29-199" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"answer_score: </span><span class="sc">{</span>row[<span class="st">'answer_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb29-200"><a href="#cb29-200" tabindex="-1"></a>                  <span class="ss">f"ref_id_score: </span><span class="sc">{</span>row[<span class="st">'ref_id_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb29-201"><a href="#cb29-201" tabindex="-1"></a>                  <span class="ss">f"is_NA_score: </span><span class="sc">{</span>row[<span class="st">'is_NA_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb29-202"><a href="#cb29-202" tabindex="-1"></a>                  <span class="ss">f"wattbot_score: </span><span class="sc">{</span>row[<span class="st">'wattbot_score'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb29-203"><a href="#cb29-203" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb29-204"><a href="#cb29-204" tabindex="-1"></a>    </span>
<span id="cb29-205"><a href="#cb29-205" tabindex="-1"></a>    <span class="cf">return</span> merged</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>results_df <span class="op">=</span> compute_wattbot_score(</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>    train_qa_path<span class="op">=</span><span class="st">"./data/train_QA.csv"</span>,</span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a>    preds_path<span class="op">=</span><span class="st">"./data/train_solutions_qwen.csv"</span>,</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a>    gt_is_na_col<span class="op">=</span><span class="st">"is_blank"</span>,   <span class="co"># or "is_blank" / None depending on how you mark NAs</span></span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a>    n_examples<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="recap-and-next-steps">Recap and next steps<a class="anchor" aria-label="anchor" href="#recap-and-next-steps"></a>
</h2>
<hr class="half-width">
<p>In this episode, we:</p>
<ul>
<li>Loaded a small corpus of AI / ML energy papers into our notebook
environment.</li>
<li>Split long documents into manageable chunks and cached those chunks
to disk so we don’t have to re-run the chunking step every time.</li>
<li>Created vector embeddings for each chunk and used similarity search
to retrieve relevant context for a given question.</li>
<li>Used an LLM to generate answers from retrieved context and wrote
results out to a CSV for later scoring and analysis.</li>
<li>Handled unanswerable questions with an <code>is_blank</code> flag so
the system can explicitly say “I don’t know” when the evidence isn’t
there.</li>
</ul>
<p>This is just a first pass at a RAG pipeline: it works, but there’s a
lot of headroom to improve both accuracy and robustness. Some natural
next steps:</p>
<ul>
<li><p><strong>Increase the size/quality of models used for embedding
and generation</strong>: Try stronger embedding models (e.g., larger
sentence-transformers or domain-tuned embeddings) and more capable LLMs
for answer generation, especially if you have GPU budget.</p></li>
<li><p><strong>Add a reranking step</strong>: Instead of sending the
top-k raw nearest neighbors directly to the LLM, use a cross-encoder or
reranker model to re-score those candidates and send only the best
ones.</p></li>
<li>
<p><strong>Handle figures and tables more carefully</strong>: Many
key numbers live in tables, figure captions, or plots. Consider:</p>
<ul>
<li>OCR / table-parsing tools (e.g., <code>pytesseract</code>, table
extractors, PDF parsers).</li>
<li>Multimodal models that can embed or interpret figures and diagrams,
not just text.</li>
<li>Separate chunking strategies for captions, tables, and main
text.</li>
</ul>
</li>
<li>
<p><strong>Enrich chunks with metadata</strong>: Attach metadata
like section headings (e.g., <em>Methods</em>, <em>Results</em>), paper
ID, year, or paragraph type. You can:</p>
<ul>
<li>Filter or boost chunks by metadata at retrieval time.</li>
<li>Use metadata in the prompt so the LLM knows where evidence is coming
from.</li>
</ul>
</li>
<li>
<p><strong>Look for LLMs tuned for scientific literature</strong>:
Experiment with models that are explicitly trained or finetuned on
scientific text (e.g., arXiv / PubMed) so they:</p>
<ul>
<li>Parse equations and technical language more reliably.</li>
<li>Are less likely to hallucinate when reading dense scientific
prose.</li>
</ul>
</li>
</ul>
<p>As you iterate, the goal is to treat this notebook as a baseline RAG
“workbench”: you can swap in better models, smarter retrieval
strategies, and richer document preprocessing without changing the
overall pipeline structure.</p>
<p>In the next episodes, we will repeat largely the same exact RAG
pipeline using slightly different approaches on AWS (processing jobs and
Bedrock).</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>
<strong>Notebook setup</strong>: Start by provisioning a GPU-backed
notebook instance (e.g., <code>ml.g5.xlarge</code>) so that both the
embedding model and Qwen2.5-7B can run comfortably.</li>
<li>
<strong>Local-first RAG</strong>: For teaching (and small corpora),
we avoid an external vector database and instead perform cosine
similarity search over in-memory embeddings.</li>
<li>
<strong>Ground-truth units</strong>: The <code>answer_unit</code>
column is always copied directly from <code>train_QA.csv</code>, never
guessed by the LLM.</li>
<li>
<strong>Two-stage LLM use</strong>: One call focuses on
<em>answering and citing</em>; a second, lighter call produces a short
explanation tagged with an evidence type.</li>
<li>
<strong>WattBot conventions</strong>: We respect the Kaggle
competition format, using <code>is_blank</code> for unanswerable
questions and for missing fields.</li>
<li>
<strong>Scalability path</strong>: The same logic can later be
swapped to FAISS/Chroma and larger models, while preserving the
interface used here.</li>
</ul>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"></code></pre>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-02_RAG_WattBot_Processing_Jobs"><p>Content from <a href="02_RAG_WattBot_Processing_Jobs.html">RAG with Processing Jobs</a></p>
<hr>
<p>Last updated on 2025-11-26 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/02_RAG_WattBot_Processing_Jobs.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>TODO</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>TODO</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="rag-with-processing-jobs">RAG with Processing Jobs<a class="anchor" aria-label="anchor" href="#rag-with-processing-jobs"></a>
</h1>
<p>In the previous episode, we ran the entire WattBot RAG pipeline on a
single GPU-backed SageMaker notebook. That was simple to teach, but the
GPU sat idle while we downloaded PDFs, chunked text, and evaluated
results.</p>
<p>In this Episode 2 notebook, we will keep the same WattBot corpus and
RAG logic, but restructure how we use AWS:</p>
<ul>
<li>The notebook itself can run on a small CPU-only instance.</li>
<li>We regenerate pages and chunks locally, as before.</li>
<li>We save the chunks to S3.</li>
<li>We run two short-lived SageMaker Processing jobs on a GPU:
<ol style="list-style-type: decimal">
<li>One job computes embeddings for all chunks.</li>
<li>A second job runs the full RAG loop (retrieval + Qwen) over all
training questions.</li>
</ol>
</li>
</ul>
<p>With this approach, we can more effectively use GPU resources only
when needed, and we can scale out to larger corpora, models, and
hardware more easily. The downside here is that you have to wait for
processing jobs to spin up and run in batch mode on your queries. For
many research applications of RAG, this is fine. However, if you want a
near-real time chatbot you can have back and forth discussion with, this
approach will not work. In the following episodes, we will discuss how
we can use <em>Bedrock</em> or our own <em>model inference
endpoints</em> to query models more rapidly.</p>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<p>We’ll first need to clone in some .py files that contain helper
functions for embedding and RAG processing jobs. Since we’re using
containerized Processing jobs, we can’t just import local Python
functions from the notebook. Instead, we create standalone scripts that
the jobs can run.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>carpentries<span class="op">-</span>incubator<span class="op">/</span>ML_with_AWS_SageMaker.git</span></code></pre>
</div>
<p>Create a /code directory and copy over the relevant scripts from
ML_with_AWS_SageMaker/scripts into /code:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="op">-</span> `embedding_inference.py` – generic embedding script</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="op">-</span> `wattbot_rag_batch.py` – WattBot<span class="op">-</span>specific RAG logic <span class="cf">for</span> batch processing job</span></code></pre>
</div>
<p>Next, setup your AWS SDK, SageMaker session, and S3 bucket
information.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="im">from</span> sagemaker.huggingface <span class="im">import</span> HuggingFaceProcessor</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="im">from</span> sagemaker.processing <span class="im">import</span> ProcessingInput, ProcessingOutput</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session()</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>region <span class="op">=</span> session.boto_region_name</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>role <span class="op">=</span> get_execution_role()</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">"chris-rag-2"</span>          <span class="co"># reuse your bucket from Episode 1</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co"># bucket_region = "us-east-1"</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>s3_client <span class="op">=</span> boto3.client(<span class="st">"s3"</span>, region_name<span class="op">=</span>region)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>local_data_dir <span class="op">=</span> <span class="st">"./data"</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>os.makedirs(local_data_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>corpus_dir <span class="op">=</span> local_data_dir <span class="op">+</span> <span class="st">"/pdfs/"</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>os.makedirs(corpus_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Region:"</span>, region)</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Role:"</span>, role)</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bucket:"</span>, bucket_name)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-1-load-wattbot-metadata-and-training-questions">Step 1 – Load WattBot metadata and training questions<a class="anchor" aria-label="anchor" href="#step-1-load-wattbot-metadata-and-training-questions"></a>
</h2>
<p>We reuse the same <code>metadata.csv</code> and
<code>train_QA.csv</code> files from Episode 1. If they are not already
on the notebook file system, we download them from S3.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="kw">def</span> smart_read_csv(path: <span class="bu">str</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>        <span class="cf">return</span> pd.read_csv(path)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">UnicodeDecodeError</span>:</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        <span class="cf">return</span> pd.read_csv(path, encoding<span class="op">=</span><span class="st">"latin-1"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>metadata_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"metadata.csv"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>train_qa_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"train_QA.csv"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>corpus_path <span class="op">=</span> os.path.join(corpus_dir, <span class="st">"corpus.zip"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(metadata_path):</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    s3_client.download_file(bucket_name, <span class="st">"metadata.csv"</span>, metadata_path)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(train_qa_path):</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>    s3_client.download_file(bucket_name, <span class="st">"train_QA.csv"</span>, train_qa_path)</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(corpus_path):</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    s3_client.download_file(bucket_name, <span class="st">"corpus.zip"</span>, corpus_path)</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>metadata_df <span class="op">=</span> smart_read_csv(metadata_path)</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>train_df <span class="op">=</span> smart_read_csv(train_qa_path)</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Metadata rows:"</span>, <span class="bu">len</span>(metadata_df))</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train QAs:"</span>, <span class="bu">len</span>(train_df))</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>train_df.head(<span class="dv">3</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(corpus_path, <span class="st">'r'</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    zip_ref.extractall(corpus_dir)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>corpus_dir</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-2-regenerate-pages-and-chunks-local">Step 2 – Regenerate pages and chunks (local)<a class="anchor" aria-label="anchor" href="#step-2-regenerate-pages-and-chunks-local"></a>
</h2>
<p>We reuse the same PDF → pages → overlapping chunks pipeline from
Episode 1. For clarity, we keep this logic in the notebook so learners
can see exactly how context is constructed.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="op">!</span>pip install pypdf</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> pypdf <span class="im">import</span> PdfReader</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Any</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="kw">def</span> pdfs_to_page_docs(metadata: pd.DataFrame, pdf_dir: <span class="bu">str</span>) <span class="op">-&gt;</span> List[Dict[<span class="bu">str</span>, Any]]:</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    <span class="co">"""Load each PDF into a list of page-level dictionaries.</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co">    Each dict has keys: text, doc_id, title, url, page_num, page_label, total_pages.</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    page_docs: List[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> []</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> metadata.iterrows():</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>        doc_id <span class="op">=</span> <span class="bu">str</span>(row[<span class="st">"id"</span>]).strip()</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>        title <span class="op">=</span> <span class="bu">str</span>(row.get(<span class="st">"title"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>        url <span class="op">=</span> <span class="bu">str</span>(row.get(<span class="st">"url"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>        pdf_path <span class="op">=</span> os.path.join(pdf_dir, <span class="ss">f"</span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">.pdf"</span>)</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> os.path.exists(pdf_path):</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Missing PDF for </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss">, skipping."</span>)</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>            reader <span class="op">=</span> PdfReader(pdf_path)</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Failed to read </span><span class="sc">{</span>pdf_path<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>        total_pages <span class="op">=</span> <span class="bu">len</span>(reader.pages)</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>        <span class="cf">for</span> i, page <span class="kw">in</span> <span class="bu">enumerate</span>(reader.pages):</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>                text <span class="op">=</span> page.extract_text() <span class="kw">or</span> <span class="st">""</span></span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Failed to extract text from </span><span class="sc">{</span>doc_id<span class="sc">}</span><span class="ss"> page </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a>                text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb9-35"><a href="#cb9-35" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" tabindex="-1"></a>            text <span class="op">=</span> text.strip()</span>
<span id="cb9-37"><a href="#cb9-37" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> text:</span>
<span id="cb9-38"><a href="#cb9-38" tabindex="-1"></a>                <span class="co"># Still keep the page so we know it exists, but mark it as empty</span></span>
<span id="cb9-39"><a href="#cb9-39" tabindex="-1"></a>                text <span class="op">=</span> <span class="st">"[[EMPTY PAGE TEXT – see original PDF for tables/figures]]"</span></span>
<span id="cb9-40"><a href="#cb9-40" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" tabindex="-1"></a>            page_docs.append(</span>
<span id="cb9-42"><a href="#cb9-42" tabindex="-1"></a>                {</span>
<span id="cb9-43"><a href="#cb9-43" tabindex="-1"></a>                    <span class="st">"text"</span>: text,</span>
<span id="cb9-44"><a href="#cb9-44" tabindex="-1"></a>                    <span class="st">"doc_id"</span>: doc_id,</span>
<span id="cb9-45"><a href="#cb9-45" tabindex="-1"></a>                    <span class="st">"title"</span>: title,</span>
<span id="cb9-46"><a href="#cb9-46" tabindex="-1"></a>                    <span class="st">"url"</span>: url,</span>
<span id="cb9-47"><a href="#cb9-47" tabindex="-1"></a>                    <span class="st">"page_num"</span>: i,</span>
<span id="cb9-48"><a href="#cb9-48" tabindex="-1"></a>                    <span class="st">"page_label"</span>: <span class="bu">str</span>(i <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb9-49"><a href="#cb9-49" tabindex="-1"></a>                    <span class="st">"total_pages"</span>: total_pages,</span>
<span id="cb9-50"><a href="#cb9-50" tabindex="-1"></a>                }</span>
<span id="cb9-51"><a href="#cb9-51" tabindex="-1"></a>            )</span>
<span id="cb9-52"><a href="#cb9-52" tabindex="-1"></a></span>
<span id="cb9-53"><a href="#cb9-53" tabindex="-1"></a>    <span class="cf">return</span> page_docs</span>
<span id="cb9-54"><a href="#cb9-54" tabindex="-1"></a></span>
<span id="cb9-55"><a href="#cb9-55" tabindex="-1"></a></span>
<span id="cb9-56"><a href="#cb9-56" tabindex="-1"></a>page_docs <span class="op">=</span> pdfs_to_page_docs(metadata_df, corpus_dir)</span>
<span id="cb9-57"><a href="#cb9-57" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(page_docs)<span class="sc">}</span><span class="ss"> page-level records from </span><span class="sc">{</span><span class="bu">len</span>(metadata_df)<span class="sc">}</span><span class="ss"> PDFs."</span>)</span>
<span id="cb9-58"><a href="#cb9-58" tabindex="-1"></a>page_docs[<span class="dv">0</span>] <span class="cf">if</span> page_docs <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb9-59"><a href="#cb9-59" tabindex="-1"></a></span>
<span id="cb9-60"><a href="#cb9-60" tabindex="-1"></a></span>
<span id="cb9-61"><a href="#cb9-61" tabindex="-1"></a><span class="kw">def</span> split_text_into_chunks(</span>
<span id="cb9-62"><a href="#cb9-62" tabindex="-1"></a>    text: <span class="bu">str</span>,</span>
<span id="cb9-63"><a href="#cb9-63" tabindex="-1"></a>    chunk_size_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1200</span>,</span>
<span id="cb9-64"><a href="#cb9-64" tabindex="-1"></a>    chunk_overlap_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb9-65"><a href="#cb9-65" tabindex="-1"></a>) <span class="op">-&gt;</span> List[<span class="bu">str</span>]:</span>
<span id="cb9-66"><a href="#cb9-66" tabindex="-1"></a>    <span class="co">"""Split `text` into overlapping character-based chunks.</span></span>
<span id="cb9-67"><a href="#cb9-67" tabindex="-1"></a></span>
<span id="cb9-68"><a href="#cb9-68" tabindex="-1"></a><span class="co">    This is a simple baseline; more advanced versions might:</span></span>
<span id="cb9-69"><a href="#cb9-69" tabindex="-1"></a><span class="co">    - split on sentence boundaries, or</span></span>
<span id="cb9-70"><a href="#cb9-70" tabindex="-1"></a><span class="co">    - merge short paragraphs and respect section headings.</span></span>
<span id="cb9-71"><a href="#cb9-71" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-72"><a href="#cb9-72" tabindex="-1"></a>    text <span class="op">=</span> text.strip()</span>
<span id="cb9-73"><a href="#cb9-73" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> text:</span>
<span id="cb9-74"><a href="#cb9-74" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb9-75"><a href="#cb9-75" tabindex="-1"></a></span>
<span id="cb9-76"><a href="#cb9-76" tabindex="-1"></a>    chunks: List[<span class="bu">str</span>] <span class="op">=</span> []</span>
<span id="cb9-77"><a href="#cb9-77" tabindex="-1"></a>    start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-78"><a href="#cb9-78" tabindex="-1"></a>    text_len <span class="op">=</span> <span class="bu">len</span>(text)</span>
<span id="cb9-79"><a href="#cb9-79" tabindex="-1"></a></span>
<span id="cb9-80"><a href="#cb9-80" tabindex="-1"></a>    <span class="cf">while</span> start <span class="op">&lt;</span> text_len:</span>
<span id="cb9-81"><a href="#cb9-81" tabindex="-1"></a>        end <span class="op">=</span> <span class="bu">min</span>(start <span class="op">+</span> chunk_size_chars, text_len)</span>
<span id="cb9-82"><a href="#cb9-82" tabindex="-1"></a>        chunk <span class="op">=</span> text[start:end]</span>
<span id="cb9-83"><a href="#cb9-83" tabindex="-1"></a>        chunks.append(chunk)</span>
<span id="cb9-84"><a href="#cb9-84" tabindex="-1"></a>        <span class="cf">if</span> end <span class="op">==</span> text_len:</span>
<span id="cb9-85"><a href="#cb9-85" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb9-86"><a href="#cb9-86" tabindex="-1"></a>        <span class="co"># Move the window forward, keeping some overlap</span></span>
<span id="cb9-87"><a href="#cb9-87" tabindex="-1"></a>        start <span class="op">=</span> end <span class="op">-</span> chunk_overlap_chars</span>
<span id="cb9-88"><a href="#cb9-88" tabindex="-1"></a></span>
<span id="cb9-89"><a href="#cb9-89" tabindex="-1"></a>    <span class="cf">return</span> chunks</span>
<span id="cb9-90"><a href="#cb9-90" tabindex="-1"></a></span>
<span id="cb9-91"><a href="#cb9-91" tabindex="-1"></a></span>
<span id="cb9-92"><a href="#cb9-92" tabindex="-1"></a><span class="kw">def</span> make_chunked_docs(</span>
<span id="cb9-93"><a href="#cb9-93" tabindex="-1"></a>    page_docs: List[Dict[<span class="bu">str</span>, Any]],</span>
<span id="cb9-94"><a href="#cb9-94" tabindex="-1"></a>    chunk_size_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1200</span>,</span>
<span id="cb9-95"><a href="#cb9-95" tabindex="-1"></a>    chunk_overlap_chars: <span class="bu">int</span> <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb9-96"><a href="#cb9-96" tabindex="-1"></a>) <span class="op">-&gt;</span> List[Dict[<span class="bu">str</span>, Any]]:</span>
<span id="cb9-97"><a href="#cb9-97" tabindex="-1"></a>    <span class="co">"""Turn page-level records into smaller overlapping text chunks.</span></span>
<span id="cb9-98"><a href="#cb9-98" tabindex="-1"></a></span>
<span id="cb9-99"><a href="#cb9-99" tabindex="-1"></a><span class="co">    Each chunk keeps a pointer back to its document and page metadata.</span></span>
<span id="cb9-100"><a href="#cb9-100" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-101"><a href="#cb9-101" tabindex="-1"></a>    chunked: List[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> []</span>
<span id="cb9-102"><a href="#cb9-102" tabindex="-1"></a>    <span class="cf">for</span> page <span class="kw">in</span> page_docs:</span>
<span id="cb9-103"><a href="#cb9-103" tabindex="-1"></a>        page_text <span class="op">=</span> page[<span class="st">"text"</span>]</span>
<span id="cb9-104"><a href="#cb9-104" tabindex="-1"></a>        chunks <span class="op">=</span> split_text_into_chunks(</span>
<span id="cb9-105"><a href="#cb9-105" tabindex="-1"></a>            page_text,</span>
<span id="cb9-106"><a href="#cb9-106" tabindex="-1"></a>            chunk_size_chars<span class="op">=</span>chunk_size_chars,</span>
<span id="cb9-107"><a href="#cb9-107" tabindex="-1"></a>            chunk_overlap_chars<span class="op">=</span>chunk_overlap_chars,</span>
<span id="cb9-108"><a href="#cb9-108" tabindex="-1"></a>        )</span>
<span id="cb9-109"><a href="#cb9-109" tabindex="-1"></a>        <span class="cf">for</span> idx, chunk_text <span class="kw">in</span> <span class="bu">enumerate</span>(chunks):</span>
<span id="cb9-110"><a href="#cb9-110" tabindex="-1"></a>            chunked.append(</span>
<span id="cb9-111"><a href="#cb9-111" tabindex="-1"></a>                {</span>
<span id="cb9-112"><a href="#cb9-112" tabindex="-1"></a>                    <span class="st">"text"</span>: chunk_text,</span>
<span id="cb9-113"><a href="#cb9-113" tabindex="-1"></a>                    <span class="st">"doc_id"</span>: page[<span class="st">"doc_id"</span>],</span>
<span id="cb9-114"><a href="#cb9-114" tabindex="-1"></a>                    <span class="st">"title"</span>: page[<span class="st">"title"</span>],</span>
<span id="cb9-115"><a href="#cb9-115" tabindex="-1"></a>                    <span class="st">"url"</span>: page[<span class="st">"url"</span>],</span>
<span id="cb9-116"><a href="#cb9-116" tabindex="-1"></a>                    <span class="st">"page_num"</span>: page[<span class="st">"page_num"</span>],</span>
<span id="cb9-117"><a href="#cb9-117" tabindex="-1"></a>                    <span class="st">"page_label"</span>: page[<span class="st">"page_label"</span>],</span>
<span id="cb9-118"><a href="#cb9-118" tabindex="-1"></a>                    <span class="st">"total_pages"</span>: page[<span class="st">"total_pages"</span>],</span>
<span id="cb9-119"><a href="#cb9-119" tabindex="-1"></a>                    <span class="st">"chunk_idx_in_page"</span>: idx,</span>
<span id="cb9-120"><a href="#cb9-120" tabindex="-1"></a>                }</span>
<span id="cb9-121"><a href="#cb9-121" tabindex="-1"></a>            )</span>
<span id="cb9-122"><a href="#cb9-122" tabindex="-1"></a>    <span class="cf">return</span> chunked</span>
<span id="cb9-123"><a href="#cb9-123" tabindex="-1"></a></span>
<span id="cb9-124"><a href="#cb9-124" tabindex="-1"></a></span>
<span id="cb9-125"><a href="#cb9-125" tabindex="-1"></a>chunked_docs <span class="op">=</span> make_chunked_docs(page_docs)</span>
<span id="cb9-126"><a href="#cb9-126" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Raw pages:"</span>, <span class="bu">len</span>(page_docs))</span>
<span id="cb9-127"><a href="#cb9-127" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Chunked docs:"</span>, <span class="bu">len</span>(chunked_docs))</span>
<span id="cb9-128"><a href="#cb9-128" tabindex="-1"></a>chunked_docs[<span class="dv">0</span>] <span class="cf">if</span> chunked_docs <span class="cf">else</span> <span class="va">None</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-serialize-chunks-to-jsonl-and-upload-to-s3">Step 3 – Serialize chunks to JSONL and upload to S3<a class="anchor" aria-label="anchor" href="#step-3-serialize-chunks-to-jsonl-and-upload-to-s3"></a>
</h2>
<p>The Processing jobs will not have access to your Python variables.
Instead, we serialize <code>chunked_docs</code> to
<code>wattbot_chunks.jsonl</code> and upload it to S3 under this
episode’s prefix.</p>
<p>Each line is one JSON object representing a chunk, including its text
and metadata.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>chunks_jsonl_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"wattbot_chunks.jsonl"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(chunks_jsonl_path, <span class="st">"w"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f:</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>    <span class="cf">for</span> ch <span class="kw">in</span> chunked_docs:</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>        f.write(json.dumps(ch, ensure_ascii<span class="op">=</span><span class="va">False</span>) <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Wrote </span><span class="sc">{</span><span class="bu">len</span>(chunked_docs)<span class="sc">}</span><span class="ss"> chunks to </span><span class="sc">{</span>chunks_jsonl_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>chunks_key <span class="op">=</span> <span class="st">"wattbot_chunks.jsonl"</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>s3_client.upload_file(chunks_jsonl_path, bucket_name, chunks_key)</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>chunks_s3_uri <span class="op">=</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>chunks_key<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Chunks JSONL in S3:"</span>, chunks_s3_uri)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-4-processing-job-1-embed-all-chunks-on-a-gpu">Step 4 – Processing Job 1: embed all chunks on a GPU<a class="anchor" aria-label="anchor" href="#step-4-processing-job-1-embed-all-chunks-on-a-gpu"></a>
</h2>
<p>Now we launch a short-lived Hugging Face <strong>Processing
job</strong> that:</p>
<ol style="list-style-type: decimal">
<li>Downloads <code>wattbot_chunks.jsonl</code> from S3.</li>
<li>Loads <code>thenlper/gte-large</code> from Hugging Face.</li>
<li>Encodes each chunk into an embedding vector.</li>
<li>Saves the full matrix as <code>embeddings.npy</code> back to
S3.</li>
</ol>
<p>We use the same <code>embedding_inference.py</code> script across
projects; here it expects a JSONL file with a <code>text</code>
field.</p>
<div class="section level3">
<h3 id="but-first">But first…<a class="anchor" aria-label="anchor" href="#but-first"></a>
</h3>
<p>we have to create a requirements.txt file that will add additional
libraries to the HuggingFaceProcessor we use below, which builds the
environment we’ll run our embedding_inference.py script in. For the
processing job to recognize this dependence, we’ll add it to the
source_dir (code/) referenced when we call embedding_processor.run()
below.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>requirements <span class="op">=</span> [</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    <span class="st">"sentence-transformers"</span>,</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>    <span class="co"># add more packages here if needed</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>]</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>req_path <span class="op">=</span> <span class="st">"code/requirements.txt"</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(req_path, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>    f.write(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(requirements))</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created requirements.txt at </span><span class="sc">{</span>req_path<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>embedding_model_id <span class="op">=</span> <span class="st">"thenlper/gte-large"</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>script_path <span class="op">=</span> <span class="st">"embedding_inference.py"</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>emb_output_prefix <span class="op">=</span> <span class="st">"embeddings"</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>emb_output_path <span class="op">=</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>emb_output_prefix<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>embedding_processor <span class="op">=</span> HuggingFaceProcessor(</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>    base_job_name<span class="op">=</span><span class="st">"WattBot-embed-gte-large"</span>,</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    instance_type<span class="op">=</span><span class="st">"ml.g5.xlarge"</span>,</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>    instance_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>    transformers_version<span class="op">=</span><span class="st">"4.56"</span>,</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>    pytorch_version<span class="op">=</span><span class="st">"2.8"</span>,</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py312"</span>,</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>    max_runtime_in_seconds<span class="op">=</span><span class="dv">2</span> <span class="op">*</span> <span class="dv">60</span> <span class="op">*</span> <span class="dv">60</span>,</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>)</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>embedding_processor.run(</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>    code<span class="op">=</span>script_path,</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>    source_dir<span class="op">=</span><span class="st">"code/"</span>,</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>    inputs<span class="op">=</span>[</span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a>        ProcessingInput(</span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>            source<span class="op">=</span>chunks_s3_uri,</span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a>            destination<span class="op">=</span><span class="st">"/opt/ml/processing/input"</span>,</span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>        )</span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>    ],</span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a>    outputs<span class="op">=</span>[</span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a>        ProcessingOutput(</span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>            output_name<span class="op">=</span><span class="st">"embeddings"</span>,</span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>            source<span class="op">=</span><span class="st">"/opt/ml/processing/output"</span>,</span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a>            destination<span class="op">=</span>emb_output_path,</span>
<span id="cb12-34"><a href="#cb12-34" tabindex="-1"></a>        )</span>
<span id="cb12-35"><a href="#cb12-35" tabindex="-1"></a>    ],</span>
<span id="cb12-36"><a href="#cb12-36" tabindex="-1"></a>    arguments<span class="op">=</span>[</span>
<span id="cb12-37"><a href="#cb12-37" tabindex="-1"></a>        <span class="st">"--model_id"</span>, embedding_model_id,</span>
<span id="cb12-38"><a href="#cb12-38" tabindex="-1"></a>        <span class="st">"--input_filename"</span>, <span class="st">"wattbot_chunks.jsonl"</span>,</span>
<span id="cb12-39"><a href="#cb12-39" tabindex="-1"></a>        <span class="st">"--text_key"</span>, <span class="st">"text"</span>,</span>
<span id="cb12-40"><a href="#cb12-40" tabindex="-1"></a>        <span class="st">"--input_dir"</span>, <span class="st">"/opt/ml/processing/input"</span>,</span>
<span id="cb12-41"><a href="#cb12-41" tabindex="-1"></a>        <span class="st">"--output_dir"</span>, <span class="st">"/opt/ml/processing/output"</span>,</span>
<span id="cb12-42"><a href="#cb12-42" tabindex="-1"></a>    ],</span>
<span id="cb12-43"><a href="#cb12-43" tabindex="-1"></a>)</span>
<span id="cb12-44"><a href="#cb12-44" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Embedding job complete."</span>)</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="check-on-running-job-in-aws-console">Check on running job in AWS Console<a class="anchor" aria-label="anchor" href="#check-on-running-job-in-aws-console"></a>
</h3>
<p>To view the job running from the AWS Console, you can visit SageMaker
AI, and then find the “Data Preparation” dropdown menu on the left side
panel. Click that to find “Processing jobs”. If you’re in us-east-1, the
following link should bring you there: <a href="https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs" class="external-link">https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs</a></p>
<p>It may take ~5 minutes in total for the job to complete. This is the
downside of launching jobs, but the good news is that we only need to
launch one embedding job for our RAG pipeline. This strategy also
ensures we’re only paying for GPUs when we need them during the
processing job.</p>
</div>
<div class="section level3">
<h3 id="sanity-check-the-embeddings-locally">Sanity-check the embeddings locally<a class="anchor" aria-label="anchor" href="#sanity-check-the-embeddings-locally"></a>
</h3>
<p>We can download <code>embeddings.npy</code> back into the notebook
and inspect its shape to confirm the job ran successfully.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>local_embeddings_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"embeddings.npy"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>embeddings_key <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>emb_output_prefix<span class="sc">}</span><span class="ss">/embeddings.npy"</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>s3_client.download_file(bucket_name, embeddings_key, local_embeddings_path)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>chunk_embeddings <span class="op">=</span> np.load(local_embeddings_path)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Embeddings shape:"</span>, chunk_embeddings.shape)</span></code></pre>
</div>
</div>
</div>
<div class="section level2">
<h2 id="step-5-processing-job-2-full-wattbot-rag-over-all-questions">Step 5 – Processing Job 2: full WattBot RAG over all questions<a class="anchor" aria-label="anchor" href="#step-5-processing-job-2-full-wattbot-rag-over-all-questions"></a>
</h2>
<p>For the second job, we pass four inputs:</p>
<ul>
<li>
<code>wattbot_chunks.jsonl</code> – serialized chunks</li>
<li>
<code>embeddings.npy</code> – precomputed chunk embeddings</li>
<li>
<code>train_QA.csv</code> – training questions (to compare with
ground truth)</li>
<li>
<code>metadata.csv</code> – to resolve <code>ref_id</code> →
URL</li>
</ul>
<p>The script <code>wattbot_rag_batch.py</code> reuses the RAG helpers
from Episode 1:</p>
<ul>
<li>cosine similarity + <code>retrieve_top_k</code>
</li>
<li><code>retrieve_context_for_question</code></li>
<li>
<code>answer_phase_for_question</code> (Qwen answer, answer_value,
ref_ids, is_blank)</li>
<li><code>explanation_phase_for_question</code></li>
<li>
<code>run_single_qa</code> (hybrid unanswerable logic: retrieval
threshold + LLM is_blank)</li>
</ul>
<p>The job writes out <code>wattbot_solutions.csv</code> in the WattBot
submission format.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co"># Upload CSVs so the job can read them</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>train_qa_key <span class="op">=</span> <span class="st">"train_QA.csv"</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>metadata_key <span class="op">=</span> <span class="st">"metadata.csv"</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>train_qa_s3 <span class="op">=</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>train_qa_key<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>metadata_s3 <span class="op">=</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>metadata_key<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>emb_output_s3 <span class="op">=</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>emb_output_prefix<span class="sc">}</span><span class="ss">/embeddings.npy"</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train_QA:"</span>, train_qa_s3)</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"metadata:"</span>, metadata_s3)</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"embeddings:"</span>, emb_output_s3)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>rag_script <span class="op">=</span> <span class="st">"wattbot_rag_batch.py"</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>rag_output_prefix <span class="op">=</span> <span class="st">"solutions"</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>rag_output_path <span class="op">=</span> <span class="ss">f"s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>rag_output_prefix<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>rag_processor <span class="op">=</span> HuggingFaceProcessor(</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>    base_job_name<span class="op">=</span><span class="st">"WattBot-rag-batch"</span>,</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>    instance_type<span class="op">=</span><span class="st">"ml.g5.xlarge"</span>,</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>    instance_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>    transformers_version<span class="op">=</span><span class="st">"4.56"</span>,</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>    pytorch_version<span class="op">=</span><span class="st">"2.8"</span>,</span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py312"</span>,</span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>session,</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>    max_runtime_in_seconds<span class="op">=</span><span class="dv">4</span> <span class="op">*</span> <span class="dv">60</span> <span class="op">*</span> <span class="dv">60</span>,</span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a>)</span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a>rag_processor.run(</span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a>    code<span class="op">=</span>rag_script,</span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a>    source_dir<span class="op">=</span><span class="st">"code/"</span>,</span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a>    inputs<span class="op">=</span>[</span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a>        ProcessingInput(</span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a>            source<span class="op">=</span>chunks_s3_uri,</span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a>            destination<span class="op">=</span><span class="st">"/opt/ml/processing/input/chunks"</span>,</span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a>        ),</span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a>        ProcessingInput(</span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a>            source<span class="op">=</span>emb_output_s3,</span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a>            destination<span class="op">=</span><span class="st">"/opt/ml/processing/input/embeddings"</span>,</span>
<span id="cb15-30"><a href="#cb15-30" tabindex="-1"></a>        ),</span>
<span id="cb15-31"><a href="#cb15-31" tabindex="-1"></a>        ProcessingInput(</span>
<span id="cb15-32"><a href="#cb15-32" tabindex="-1"></a>            source<span class="op">=</span>train_qa_s3,</span>
<span id="cb15-33"><a href="#cb15-33" tabindex="-1"></a>            destination<span class="op">=</span><span class="st">"/opt/ml/processing/input/train"</span>,</span>
<span id="cb15-34"><a href="#cb15-34" tabindex="-1"></a>        ),</span>
<span id="cb15-35"><a href="#cb15-35" tabindex="-1"></a>        ProcessingInput(</span>
<span id="cb15-36"><a href="#cb15-36" tabindex="-1"></a>            source<span class="op">=</span>metadata_s3,</span>
<span id="cb15-37"><a href="#cb15-37" tabindex="-1"></a>            destination<span class="op">=</span><span class="st">"/opt/ml/processing/input/metadata"</span>,</span>
<span id="cb15-38"><a href="#cb15-38" tabindex="-1"></a>        ),</span>
<span id="cb15-39"><a href="#cb15-39" tabindex="-1"></a>    ],</span>
<span id="cb15-40"><a href="#cb15-40" tabindex="-1"></a>    outputs<span class="op">=</span>[</span>
<span id="cb15-41"><a href="#cb15-41" tabindex="-1"></a>        ProcessingOutput(</span>
<span id="cb15-42"><a href="#cb15-42" tabindex="-1"></a>            output_name<span class="op">=</span><span class="st">"solutions"</span>,</span>
<span id="cb15-43"><a href="#cb15-43" tabindex="-1"></a>            source<span class="op">=</span><span class="st">"/opt/ml/processing/output"</span>,</span>
<span id="cb15-44"><a href="#cb15-44" tabindex="-1"></a>            destination<span class="op">=</span>rag_output_path,</span>
<span id="cb15-45"><a href="#cb15-45" tabindex="-1"></a>        )</span>
<span id="cb15-46"><a href="#cb15-46" tabindex="-1"></a>    ],</span>
<span id="cb15-47"><a href="#cb15-47" tabindex="-1"></a>    arguments<span class="op">=</span>[</span>
<span id="cb15-48"><a href="#cb15-48" tabindex="-1"></a>        <span class="st">"--input_dir"</span>, <span class="st">"/opt/ml/processing/input"</span>,</span>
<span id="cb15-49"><a href="#cb15-49" tabindex="-1"></a>        <span class="st">"--output_dir"</span>, <span class="st">"/opt/ml/processing/output"</span>,</span>
<span id="cb15-50"><a href="#cb15-50" tabindex="-1"></a>        <span class="st">"--embedding_model_id"</span>, embedding_model_id,</span>
<span id="cb15-51"><a href="#cb15-51" tabindex="-1"></a>        <span class="st">"--top_k"</span>, <span class="st">"8"</span>,</span>
<span id="cb15-52"><a href="#cb15-52" tabindex="-1"></a>    ],</span>
<span id="cb15-53"><a href="#cb15-53" tabindex="-1"></a>)</span>
<span id="cb15-54"><a href="#cb15-54" tabindex="-1"></a></span>
<span id="cb15-55"><a href="#cb15-55" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RAG batch job complete."</span>)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-6-download-predictions-and-evaluate">Step 6 – Download predictions and evaluate<a class="anchor" aria-label="anchor" href="#step-6-download-predictions-and-evaluate"></a>
</h2>
<p>Finally, we download <code>wattbot_solutions.csv</code> from S3,
inspect a few rows, and (optionally) compute the WattBot score against
<code>train_QA.csv</code> using the <code>Score.py</code> logic.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>solutions_key <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>rag_output_prefix<span class="sc">}</span><span class="ss">/wattbot_solutions.csv"</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>local_solutions_path <span class="op">=</span> os.path.join(local_data_dir, <span class="st">"wattbot_solutions.csv"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>s3_client.download_file(bucket_name, solutions_key, local_solutions_path)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>solutions_df <span class="op">=</span> pd.read_csv(local_solutions_path)</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>solutions_df.head()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="kw">def</span> _to_bool_flag(x):</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>    <span class="co">"""Convert typical truthy/falsey strings to bool."""</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(x, <span class="bu">str</span>):</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>        s <span class="op">=</span> x.strip().lower()</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">in</span> {<span class="st">"1"</span>, <span class="st">"True"</span>, <span class="st">"true"</span>, <span class="st">"yes"</span>}:</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">in</span> {<span class="st">"0"</span>, <span class="st">"False"</span>, <span class="st">"false"</span>, <span class="st">"no"</span>}:</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">bool</span>(x)</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a><span class="kw">def</span> _parse_float_or_none(x):</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">float</span>(<span class="bu">str</span>(x).strip())</span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a><span class="kw">def</span> _answer_value_correct(gt_val, pred_val, rel_tol<span class="op">=</span><span class="fl">1e-3</span>):</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a><span class="co">    gt_val, pred_val: values from answer_value columns.</span></span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a><span class="co">    rel_tol = 0.001 =&gt; 0.1% relative tolerance.</span></span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a>    gt_str <span class="op">=</span> <span class="bu">str</span>(gt_val).strip()</span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a>    pred_str <span class="op">=</span> <span class="bu">str</span>(pred_val).strip()</span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a>    </span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a>    <span class="co"># If either is 'is_blank', treat as categorical</span></span>
<span id="cb17-29"><a href="#cb17-29" tabindex="-1"></a>    <span class="cf">if</span> gt_str.lower() <span class="op">==</span> <span class="st">"is_blank"</span> <span class="kw">or</span> pred_str.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb17-30"><a href="#cb17-30" tabindex="-1"></a>        <span class="cf">return</span> gt_str.lower() <span class="op">==</span> pred_str.lower()</span>
<span id="cb17-31"><a href="#cb17-31" tabindex="-1"></a>    </span>
<span id="cb17-32"><a href="#cb17-32" tabindex="-1"></a>    gt_num <span class="op">=</span> _parse_float_or_none(gt_val)</span>
<span id="cb17-33"><a href="#cb17-33" tabindex="-1"></a>    pred_num <span class="op">=</span> _parse_float_or_none(pred_val)</span>
<span id="cb17-34"><a href="#cb17-34" tabindex="-1"></a>    </span>
<span id="cb17-35"><a href="#cb17-35" tabindex="-1"></a>    <span class="co"># If both numeric, use relative tolerance</span></span>
<span id="cb17-36"><a href="#cb17-36" tabindex="-1"></a>    <span class="cf">if</span> gt_num <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_num <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb17-37"><a href="#cb17-37" tabindex="-1"></a>        <span class="cf">if</span> gt_num <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb17-38"><a href="#cb17-38" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">abs</span>(pred_num <span class="op">-</span> gt_num) <span class="op">&lt;=</span> rel_tol  <span class="co"># small absolute tolerance around 0</span></span>
<span id="cb17-39"><a href="#cb17-39" tabindex="-1"></a>        rel_err <span class="op">=</span> <span class="bu">abs</span>(pred_num <span class="op">-</span> gt_num) <span class="op">/</span> <span class="bu">max</span>(<span class="bu">abs</span>(gt_num), <span class="fl">1e-12</span>)</span>
<span id="cb17-40"><a href="#cb17-40" tabindex="-1"></a>        <span class="cf">return</span> rel_err <span class="op">&lt;=</span> rel_tol</span>
<span id="cb17-41"><a href="#cb17-41" tabindex="-1"></a>    </span>
<span id="cb17-42"><a href="#cb17-42" tabindex="-1"></a>    <span class="co"># Otherwise, fall back to normalized string match</span></span>
<span id="cb17-43"><a href="#cb17-43" tabindex="-1"></a>    <span class="cf">return</span> gt_str.lower() <span class="op">==</span> pred_str.lower()</span>
<span id="cb17-44"><a href="#cb17-44" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" tabindex="-1"></a><span class="kw">def</span> _ref_id_jaccard(gt_ref, pred_ref):</span>
<span id="cb17-46"><a href="#cb17-46" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-47"><a href="#cb17-47" tabindex="-1"></a><span class="co">    Jaccard overlap between sets of ref_ids.</span></span>
<span id="cb17-48"><a href="#cb17-48" tabindex="-1"></a><span class="co">    Strings may contain semicolon-separated IDs, or 'is_blank'.</span></span>
<span id="cb17-49"><a href="#cb17-49" tabindex="-1"></a><span class="co">    Case-insensitive.</span></span>
<span id="cb17-50"><a href="#cb17-50" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-51"><a href="#cb17-51" tabindex="-1"></a>    <span class="kw">def</span> to_set(s):</span>
<span id="cb17-52"><a href="#cb17-52" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb17-53"><a href="#cb17-53" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">set</span>()</span>
<span id="cb17-54"><a href="#cb17-54" tabindex="-1"></a>        s <span class="op">=</span> <span class="bu">str</span>(s).strip()</span>
<span id="cb17-55"><a href="#cb17-55" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> s <span class="kw">or</span> s.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb17-56"><a href="#cb17-56" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">set</span>()</span>
<span id="cb17-57"><a href="#cb17-57" tabindex="-1"></a>        parts <span class="op">=</span> [p.strip().lower() <span class="cf">for</span> p <span class="kw">in</span> s.split(<span class="st">";"</span>) <span class="cf">if</span> p.strip()]</span>
<span id="cb17-58"><a href="#cb17-58" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">set</span>(parts)</span>
<span id="cb17-59"><a href="#cb17-59" tabindex="-1"></a>    </span>
<span id="cb17-60"><a href="#cb17-60" tabindex="-1"></a>    gt_set <span class="op">=</span> to_set(gt_ref)</span>
<span id="cb17-61"><a href="#cb17-61" tabindex="-1"></a>    pred_set <span class="op">=</span> to_set(pred_ref)</span>
<span id="cb17-62"><a href="#cb17-62" tabindex="-1"></a>    </span>
<span id="cb17-63"><a href="#cb17-63" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> gt_set <span class="kw">and</span> <span class="kw">not</span> pred_set:</span>
<span id="cb17-64"><a href="#cb17-64" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1.0</span></span>
<span id="cb17-65"><a href="#cb17-65" tabindex="-1"></a>    union <span class="op">=</span> gt_set <span class="op">|</span> pred_set</span>
<span id="cb17-66"><a href="#cb17-66" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> union:</span>
<span id="cb17-67"><a href="#cb17-67" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.0</span></span>
<span id="cb17-68"><a href="#cb17-68" tabindex="-1"></a>    inter <span class="op">=</span> gt_set <span class="op">&amp;</span> pred_set</span>
<span id="cb17-69"><a href="#cb17-69" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(inter) <span class="op">/</span> <span class="bu">len</span>(union)</span>
<span id="cb17-70"><a href="#cb17-70" tabindex="-1"></a></span>
<span id="cb17-71"><a href="#cb17-71" tabindex="-1"></a><span class="kw">def</span> compute_wattbot_score(</span>
<span id="cb17-72"><a href="#cb17-72" tabindex="-1"></a>    train_qa_path<span class="op">=</span><span class="st">"train_QA.csv"</span>,</span>
<span id="cb17-73"><a href="#cb17-73" tabindex="-1"></a>    preds_path<span class="op">=</span><span class="st">"train_solutions_qwen.csv"</span>,</span>
<span id="cb17-74"><a href="#cb17-74" tabindex="-1"></a>    id_col<span class="op">=</span><span class="st">"id"</span>,</span>
<span id="cb17-75"><a href="#cb17-75" tabindex="-1"></a>    gt_answer_col<span class="op">=</span><span class="st">"answer_value"</span>,</span>
<span id="cb17-76"><a href="#cb17-76" tabindex="-1"></a>    gt_ref_col<span class="op">=</span><span class="st">"ref_id"</span>,</span>
<span id="cb17-77"><a href="#cb17-77" tabindex="-1"></a>    gt_is_na_col<span class="op">=</span><span class="st">"is_NA"</span>,   <span class="co"># can also pass "is_blank" or None</span></span>
<span id="cb17-78"><a href="#cb17-78" tabindex="-1"></a>    pred_answer_col<span class="op">=</span><span class="st">"answer_value"</span>,</span>
<span id="cb17-79"><a href="#cb17-79" tabindex="-1"></a>    pred_ref_col<span class="op">=</span><span class="st">"ref_id"</span>,</span>
<span id="cb17-80"><a href="#cb17-80" tabindex="-1"></a>    pred_is_na_col<span class="op">=</span><span class="va">None</span>,    <span class="co"># can pass "is_blank", or leave None to auto</span></span>
<span id="cb17-81"><a href="#cb17-81" tabindex="-1"></a>    n_examples<span class="op">=</span><span class="dv">10</span>,          <span class="co"># how many incorrect examples to print</span></span>
<span id="cb17-82"><a href="#cb17-82" tabindex="-1"></a>):</span>
<span id="cb17-83"><a href="#cb17-83" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-84"><a href="#cb17-84" tabindex="-1"></a><span class="co">    Compare your solutions to train_QA.csv using a WattBot-style score.</span></span>
<span id="cb17-85"><a href="#cb17-85" tabindex="-1"></a></span>
<span id="cb17-86"><a href="#cb17-86" tabindex="-1"></a><span class="co">    NA logic:</span></span>
<span id="cb17-87"><a href="#cb17-87" tabindex="-1"></a><span class="co">    - If an explicit NA column is found/used (e.g. is_NA), we use it via _to_bool_flag.</span></span>
<span id="cb17-88"><a href="#cb17-88" tabindex="-1"></a><span class="co">    - If you pass gt_is_na_col="is_blank" or pred_is_na_col="is_blank",</span></span>
<span id="cb17-89"><a href="#cb17-89" tabindex="-1"></a><span class="co">      we *derive* NA from answer_value == "is_blank" instead of expecting a real column.</span></span>
<span id="cb17-90"><a href="#cb17-90" tabindex="-1"></a><span class="co">    - If no NA column is available at all, we derive from answer_value == "is_blank".</span></span>
<span id="cb17-91"><a href="#cb17-91" tabindex="-1"></a></span>
<span id="cb17-92"><a href="#cb17-92" tabindex="-1"></a><span class="co">    Also prints up to `n_examples` rows where the model is not perfect</span></span>
<span id="cb17-93"><a href="#cb17-93" tabindex="-1"></a><span class="co">    (answer_score &lt; 1, ref_id_score &lt; 1, or is_NA_score &lt; 1).</span></span>
<span id="cb17-94"><a href="#cb17-94" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-95"><a href="#cb17-95" tabindex="-1"></a>    gt <span class="op">=</span> pd.read_csv(train_qa_path)</span>
<span id="cb17-96"><a href="#cb17-96" tabindex="-1"></a>    preds <span class="op">=</span> pd.read_csv(preds_path)</span>
<span id="cb17-97"><a href="#cb17-97" tabindex="-1"></a>    </span>
<span id="cb17-98"><a href="#cb17-98" tabindex="-1"></a>    <span class="co"># Inner join on id to be strict</span></span>
<span id="cb17-99"><a href="#cb17-99" tabindex="-1"></a>    merged <span class="op">=</span> gt.merge(preds, on<span class="op">=</span>id_col, suffixes<span class="op">=</span>(<span class="st">"_gt"</span>, <span class="st">"_pred"</span>))</span>
<span id="cb17-100"><a href="#cb17-100" tabindex="-1"></a>    <span class="cf">if</span> merged.empty:</span>
<span id="cb17-101"><a href="#cb17-101" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"No overlapping ids between ground truth and predictions."</span>)</span>
<span id="cb17-102"><a href="#cb17-102" tabindex="-1"></a></span>
<span id="cb17-103"><a href="#cb17-103" tabindex="-1"></a>    <span class="co"># ----- ground truth NA flags -----</span></span>
<span id="cb17-104"><a href="#cb17-104" tabindex="-1"></a>    <span class="cf">if</span> gt_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> gt_is_na_col <span class="kw">in</span> merged.columns:</span>
<span id="cb17-105"><a href="#cb17-105" tabindex="-1"></a>        <span class="co"># Use explicit column (e.g. "is_NA")</span></span>
<span id="cb17-106"><a href="#cb17-106" tabindex="-1"></a>        gt_is_na_series <span class="op">=</span> merged[gt_is_na_col].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb17-107"><a href="#cb17-107" tabindex="-1"></a>    <span class="cf">elif</span> gt_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> gt_is_na_col.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb17-108"><a href="#cb17-108" tabindex="-1"></a>        <span class="co"># Special meaning: derive NA from answer_value_gt == "is_blank"</span></span>
<span id="cb17-109"><a href="#cb17-109" tabindex="-1"></a>        gt_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb17-110"><a href="#cb17-110" tabindex="-1"></a>        merged[<span class="st">"gt_is_blank_flag"</span>] <span class="op">=</span> gt_is_na_series</span>
<span id="cb17-111"><a href="#cb17-111" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb17-112"><a href="#cb17-112" tabindex="-1"></a>        <span class="co"># Fallback: if we have is_NA or is_blank col, use it; else derive</span></span>
<span id="cb17-113"><a href="#cb17-113" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"is_NA"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb17-114"><a href="#cb17-114" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="st">"is_NA"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb17-115"><a href="#cb17-115" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">"is_blank"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb17-116"><a href="#cb17-116" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="st">"is_blank"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb17-117"><a href="#cb17-117" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-118"><a href="#cb17-118" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb17-119"><a href="#cb17-119" tabindex="-1"></a>            merged[<span class="st">"gt_is_blank_flag"</span>] <span class="op">=</span> gt_is_na_series</span>
<span id="cb17-120"><a href="#cb17-120" tabindex="-1"></a></span>
<span id="cb17-121"><a href="#cb17-121" tabindex="-1"></a>    <span class="co"># ----- prediction NA flags -----</span></span>
<span id="cb17-122"><a href="#cb17-122" tabindex="-1"></a>    <span class="cf">if</span> pred_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_is_na_col <span class="kw">in</span> merged.columns:</span>
<span id="cb17-123"><a href="#cb17-123" tabindex="-1"></a>        pred_is_na_series <span class="op">=</span> merged[pred_is_na_col].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb17-124"><a href="#cb17-124" tabindex="-1"></a>    <span class="cf">elif</span> pred_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_is_na_col.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb17-125"><a href="#cb17-125" tabindex="-1"></a>        <span class="co"># Same convention: derive from answer_value_pred</span></span>
<span id="cb17-126"><a href="#cb17-126" tabindex="-1"></a>        pred_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb17-127"><a href="#cb17-127" tabindex="-1"></a>        merged[<span class="st">"pred_is_blank_flag"</span>] <span class="op">=</span> pred_is_na_series</span>
<span id="cb17-128"><a href="#cb17-128" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb17-129"><a href="#cb17-129" tabindex="-1"></a>        <span class="co"># Auto-detect or derive if no NA column in preds</span></span>
<span id="cb17-130"><a href="#cb17-130" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"is_NA"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb17-131"><a href="#cb17-131" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="st">"is_NA"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb17-132"><a href="#cb17-132" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">"is_blank"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb17-133"><a href="#cb17-133" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="st">"is_blank"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb17-134"><a href="#cb17-134" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-135"><a href="#cb17-135" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb17-136"><a href="#cb17-136" tabindex="-1"></a>            merged[<span class="st">"pred_is_blank_flag"</span>] <span class="op">=</span> pred_is_na_series</span>
<span id="cb17-137"><a href="#cb17-137" tabindex="-1"></a></span>
<span id="cb17-138"><a href="#cb17-138" tabindex="-1"></a>    ans_scores <span class="op">=</span> []</span>
<span id="cb17-139"><a href="#cb17-139" tabindex="-1"></a>    ref_scores <span class="op">=</span> []</span>
<span id="cb17-140"><a href="#cb17-140" tabindex="-1"></a>    na_scores <span class="op">=</span> []</span>
<span id="cb17-141"><a href="#cb17-141" tabindex="-1"></a>    </span>
<span id="cb17-142"><a href="#cb17-142" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> merged.iterrows():</span>
<span id="cb17-143"><a href="#cb17-143" tabindex="-1"></a>        gt_ans <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>]</span>
<span id="cb17-144"><a href="#cb17-144" tabindex="-1"></a>        pred_ans <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>]</span>
<span id="cb17-145"><a href="#cb17-145" tabindex="-1"></a>        gt_ref <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>gt_ref_col<span class="sc">}</span><span class="ss">_gt"</span>]</span>
<span id="cb17-146"><a href="#cb17-146" tabindex="-1"></a>        pred_ref <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>pred_ref_col<span class="sc">}</span><span class="ss">_pred"</span>]</span>
<span id="cb17-147"><a href="#cb17-147" tabindex="-1"></a>        </span>
<span id="cb17-148"><a href="#cb17-148" tabindex="-1"></a>        gt_is_na <span class="op">=</span> <span class="bu">bool</span>(gt_is_na_series.iloc[idx])</span>
<span id="cb17-149"><a href="#cb17-149" tabindex="-1"></a>        pred_is_na <span class="op">=</span> <span class="bu">bool</span>(pred_is_na_series.iloc[idx])</span>
<span id="cb17-150"><a href="#cb17-150" tabindex="-1"></a>        </span>
<span id="cb17-151"><a href="#cb17-151" tabindex="-1"></a>        <span class="co"># 1. answer_value component</span></span>
<span id="cb17-152"><a href="#cb17-152" tabindex="-1"></a>        ans_correct <span class="op">=</span> _answer_value_correct(gt_ans, pred_ans)</span>
<span id="cb17-153"><a href="#cb17-153" tabindex="-1"></a>        ans_scores.append(<span class="fl">1.0</span> <span class="op">*</span> ans_correct)</span>
<span id="cb17-154"><a href="#cb17-154" tabindex="-1"></a>        </span>
<span id="cb17-155"><a href="#cb17-155" tabindex="-1"></a>        <span class="co"># 2. ref_id Jaccard</span></span>
<span id="cb17-156"><a href="#cb17-156" tabindex="-1"></a>        ref_j <span class="op">=</span> _ref_id_jaccard(gt_ref, pred_ref)</span>
<span id="cb17-157"><a href="#cb17-157" tabindex="-1"></a>        ref_scores.append(ref_j)</span>
<span id="cb17-158"><a href="#cb17-158" tabindex="-1"></a>        </span>
<span id="cb17-159"><a href="#cb17-159" tabindex="-1"></a>        <span class="co"># 3. is_NA component (simple: must match ground truth flag)</span></span>
<span id="cb17-160"><a href="#cb17-160" tabindex="-1"></a>        na_scores.append(<span class="fl">1.0</span> <span class="cf">if</span> gt_is_na <span class="op">==</span> pred_is_na <span class="cf">else</span> <span class="fl">0.0</span>)</span>
<span id="cb17-161"><a href="#cb17-161" tabindex="-1"></a>    </span>
<span id="cb17-162"><a href="#cb17-162" tabindex="-1"></a>    merged[<span class="st">"answer_score"</span>] <span class="op">=</span> ans_scores</span>
<span id="cb17-163"><a href="#cb17-163" tabindex="-1"></a>    merged[<span class="st">"ref_id_score"</span>] <span class="op">=</span> ref_scores</span>
<span id="cb17-164"><a href="#cb17-164" tabindex="-1"></a>    merged[<span class="st">"is_NA_score"</span>] <span class="op">=</span> na_scores</span>
<span id="cb17-165"><a href="#cb17-165" tabindex="-1"></a>    </span>
<span id="cb17-166"><a href="#cb17-166" tabindex="-1"></a>    merged[<span class="st">"wattbot_score"</span>] <span class="op">=</span> (</span>
<span id="cb17-167"><a href="#cb17-167" tabindex="-1"></a>        <span class="fl">0.75</span> <span class="op">*</span> merged[<span class="st">"answer_score"</span>]</span>
<span id="cb17-168"><a href="#cb17-168" tabindex="-1"></a>        <span class="op">+</span> <span class="fl">0.15</span> <span class="op">*</span> merged[<span class="st">"ref_id_score"</span>]</span>
<span id="cb17-169"><a href="#cb17-169" tabindex="-1"></a>        <span class="op">+</span> <span class="fl">0.10</span> <span class="op">*</span> merged[<span class="st">"is_NA_score"</span>]</span>
<span id="cb17-170"><a href="#cb17-170" tabindex="-1"></a>    )</span>
<span id="cb17-171"><a href="#cb17-171" tabindex="-1"></a>    </span>
<span id="cb17-172"><a href="#cb17-172" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Rows compared: </span><span class="sc">{</span><span class="bu">len</span>(merged)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-173"><a href="#cb17-173" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean answer_value score: </span><span class="sc">{</span>merged[<span class="st">'answer_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-174"><a href="#cb17-174" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean ref_id score:       </span><span class="sc">{</span>merged[<span class="st">'ref_id_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-175"><a href="#cb17-175" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean is_NA score:        </span><span class="sc">{</span>merged[<span class="st">'is_NA_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-176"><a href="#cb17-176" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Overall WattBot score:   </span><span class="sc">{</span>merged[<span class="st">'wattbot_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-177"><a href="#cb17-177" tabindex="-1"></a>    </span>
<span id="cb17-178"><a href="#cb17-178" tabindex="-1"></a>    <span class="co"># ----- Show some incorrect examples -----</span></span>
<span id="cb17-179"><a href="#cb17-179" tabindex="-1"></a>    incorrect <span class="op">=</span> merged[</span>
<span id="cb17-180"><a href="#cb17-180" tabindex="-1"></a>        (merged[<span class="st">"answer_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb17-181"><a href="#cb17-181" tabindex="-1"></a>        <span class="op">|</span> (merged[<span class="st">"ref_id_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb17-182"><a href="#cb17-182" tabindex="-1"></a>        <span class="op">|</span> (merged[<span class="st">"is_NA_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb17-183"><a href="#cb17-183" tabindex="-1"></a>    ]</span>
<span id="cb17-184"><a href="#cb17-184" tabindex="-1"></a>    </span>
<span id="cb17-185"><a href="#cb17-185" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> incorrect.empty <span class="kw">and</span> n_examples <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb17-186"><a href="#cb17-186" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Examples of incorrect / partially correct responses "</span></span>
<span id="cb17-187"><a href="#cb17-187" tabindex="-1"></a>              <span class="ss">f"(up to </span><span class="sc">{</span>n_examples<span class="sc">}</span><span class="ss"> rows):</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb17-188"><a href="#cb17-188" tabindex="-1"></a>        <span class="co"># Grab up to n_examples "worst" rows by wattbot_score</span></span>
<span id="cb17-189"><a href="#cb17-189" tabindex="-1"></a>        <span class="cf">for</span> _, row <span class="kw">in</span> incorrect.sort_values(<span class="st">"wattbot_score"</span>).head(n_examples).iterrows():</span>
<span id="cb17-190"><a href="#cb17-190" tabindex="-1"></a>            q <span class="op">=</span> row[<span class="st">"question_gt"</span>] <span class="cf">if</span> <span class="st">"question_gt"</span> <span class="kw">in</span> row.index <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb17-191"><a href="#cb17-191" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb17-192"><a href="#cb17-192" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"id: </span><span class="sc">{</span>row[id_col]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-193"><a href="#cb17-193" tabindex="-1"></a>            <span class="cf">if</span> q <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb17-194"><a href="#cb17-194" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>q<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-195"><a href="#cb17-195" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"GT answer_value:   </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-196"><a href="#cb17-196" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Pred answer_value: </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-197"><a href="#cb17-197" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"GT ref_id:         </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>gt_ref_col<span class="sc">}</span><span class="ss">_gt'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-198"><a href="#cb17-198" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Pred ref_id:       </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>pred_ref_col<span class="sc">}</span><span class="ss">_pred'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-199"><a href="#cb17-199" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"answer_score: </span><span class="sc">{</span>row[<span class="st">'answer_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb17-200"><a href="#cb17-200" tabindex="-1"></a>                  <span class="ss">f"ref_id_score: </span><span class="sc">{</span>row[<span class="st">'ref_id_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb17-201"><a href="#cb17-201" tabindex="-1"></a>                  <span class="ss">f"is_NA_score: </span><span class="sc">{</span>row[<span class="st">'is_NA_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb17-202"><a href="#cb17-202" tabindex="-1"></a>                  <span class="ss">f"wattbot_score: </span><span class="sc">{</span>row[<span class="st">'wattbot_score'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb17-203"><a href="#cb17-203" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb17-204"><a href="#cb17-204" tabindex="-1"></a>    </span>
<span id="cb17-205"><a href="#cb17-205" tabindex="-1"></a>    <span class="cf">return</span> merged</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>results_df <span class="op">=</span> compute_wattbot_score(</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>    train_qa_path<span class="op">=</span><span class="st">"./data/train_QA.csv"</span>,</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>    preds_path<span class="op">=</span><span class="st">"./data/wattbot_solutions.csv"</span>,</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>    gt_is_na_col<span class="op">=</span><span class="st">"is_blank"</span>,</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    pred_is_na_col<span class="op">=</span><span class="st">"is_blank"</span>,</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>)</span></code></pre>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>TODO</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div></section><section id="aio-03_RAG_WattBot_Bedrock"><p>Content from <a href="03_RAG_WattBot_Bedrock.html">RAG with Bedrock</a></p>
<hr>
<p>Last updated on 2025-11-26 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/03_RAG_WattBot_Bedrock.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>TODO</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>TODO</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In the previous episodes you built a basic RAG pipeline for WattBot
using a local GPU instance and then an offline SageMaker Processing job.
Both approaches gave you full control over the models, but you were
responsible for provisioning compute and keeping model versions up to
date.</p>
<p>In this episode we move the core model work — <strong>both text
embeddings and answer generation</strong> — onto <strong>Amazon
Bedrock</strong>. We’ll use:</p>
<ul>
<li>an <strong>Amazon Titan Text Embeddings V2</strong> model to turn
WattBot chunks into vectors, and<br>
</li>
<li>an <strong>Anthropic Claude</strong> model hosted on Bedrock to
generate answers and explanations.</li>
</ul>
<p>The retrieval, evaluation, and WattBot scoring logic are exactly the
same as before; we’re just swapping out the underlying models and where
they run. This lets you experiment with hosted, state‑of‑the‑art models
without having to manage GPUs or container images yourself.</p>
<section><h2 class="section-heading" id="why-bedrock-for-wattbot">Why Bedrock for WattBot?<a class="anchor" aria-label="anchor" href="#why-bedrock-for-wattbot"></a>
</h2>
<hr class="half-width">
<p>For the GPU instance and Processing Job episodes, you were
responsible for picking a model, managing versions, and making sure your
instance had enough VRAM. That’s fine for experiments, but it can get
painful once multiple teams or challenges want to reuse the same
pipeline.</p>
<p>Running your <strong>embedding + generation</strong> steps on Amazon
Bedrock gives you a few nice properties:</p>
<ul>
<li>
<strong>Managed, up‑to‑date models.</strong> You can use
high‑quality models from Anthropic, Amazon, and others without worrying
about container images or CUDA versions.</li>
<li>
<strong>Pay for what you use (in tokens).</strong> Instead of paying
for a GPU instance that might sit idle, you pay per token (input +
output) when you call the model. For some workloads this is cheaper; for
large offline batches with smaller models, a dedicated GPU can still
win.</li>
<li>
<strong>Easier sharing and governance.</strong> It’s easier to
standardize on a small set of Bedrock models across courses, hackathons,
or labs than to manage many separate GPU instances.</li>
</ul>
<p>In this notebook, we’ll keep the same WattBot training questions and
scoring helper you used before, and we’ll simply move both the
<strong>embedding</strong> and <strong>answer/explanation</strong> steps
onto Bedrock-hosted models.</p>
</section><section><h2 class="section-heading" id="setup-what-you-should-already-have">Setup: what you should already have<a class="anchor" aria-label="anchor" href="#setup-what-you-should-already-have"></a>
</h2>
<hr class="half-width">
<p>This notebook assumes you have already run the earlier WattBot
episodes so that:</p>
<ul>
<li>the WattBot corpus has been chunked into
<code>wattbot_chunks.jsonl</code>
</li>
<li>the WattBot training questions <code>train_QA.csv</code> and
<code>metadata.csv</code> live under a <code>data/</code> folder</li>
<li>(optionally) you have a local embedding file from earlier
experiments, e.g. <code>embeddings.npy</code>
</li>
</ul>
<p>In this episode we’ll recompute embeddings <strong>using an Amazon
Titan Text Embeddings V2 model on Bedrock</strong>, and we’ll save those
vectors out as <code>embeddings_bedrock.npy</code>. That keeps this
notebook self‑contained while still letting you compare against the
earlier GPU / Processing Job runs if you want.</p>
<div class="section level3">
<h3 id="models-used-in-this-episode">Models used in this episode<a class="anchor" aria-label="anchor" href="#models-used-in-this-episode"></a>
</h3>
<p>We’ll work with <strong>Amazon Bedrock–hosted foundation
models</strong> for both embedding and generation:</p>
<ul>
<li>
<p><strong>Amazon Titan Text Embeddings V2</strong>
(<code>amazon.titan-embed-text-v2:0</code>)</p>
<ul>
<li>General‑purpose text‑embedding model for semantic search, retrieval,
clustering, and classification.</li>
<li>Supports configurable embedding dimensions (for example 256–8,192)
and has presets tuned for retrieval or binary indexing.</li>
<li>AWS does not publish the exact number of parameters for Titan
models; you can treat it as a modern transformer specialized for
embeddings rather than free‑form text generation.</li>
</ul>
</li>
<li>
<p><strong>Anthropic Claude 3 Haiku</strong>
(<code>anthropic.claude-3-haiku-20240307-v1:0</code> via Bedrock)</p>
<ul>
<li>A fast, mid‑sized Claude model that balances cost and quality for
workloads like RAG, chat, and lightweight analysis.</li>
<li>Particularly useful when you want many calls (e.g., one per
question) and care about low latency and lower per‑token pricing
compared to flagship models such as Claude Opus or Claude 3.5
Sonnet.</li>
<li>Anthropic does not publish exact parameter counts for Claude models;
Haiku sits in the “smallest / fastest” tier within the Claude 3
family.</li>
</ul>
</li>
<li>
<p><strong>(Optional) Multimodal models for tables and
figures</strong></p>
<ul>
<li>Bedrock also exposes <strong>multimodal models</strong> that can
reason over images, charts, and document layouts (for example, Claude
3.5 Sonnet with vision, or Amazon Titan Multimodal Embeddings). These
are a good fit if much of your evidence lives in <strong>figures,
tables, or scanned PDFs</strong>.</li>
<li>To use them from Bedrock you send <strong>both text and image
content</strong> in a single request:
<ul>
<li>Pre‑process PDFs by rendering pages (or cropping individual
tables/figures) to images using a tool like <code>pdf2image</code> or a
headless browser.</li>
<li>Base64‑encode those images and include them as image parts alongside
text in the model request.</li>
<li>For multimodal embeddings, you call a Titan multimodal embedding
model with an <code>inputImage</code> (and optionally
<code>inputText</code>) payload to obtain a single vector that mixes
visual and textual information.</li>
</ul>
</li>
<li>This notebook stays with <strong>text‑only</strong> embeddings +
generation to keep the workflow simple, but the same RAG pattern extends
naturally to multimodal models once you add an image‑extraction step to
your preprocessing pipeline.</li>
</ul>
</li>
</ul>
<p>For a full catalog of available models (including other Claude
variants, Amazon models, and partner models), open the <strong>Model
catalog</strong> in the Amazon Bedrock console. Each entry provides a
model card with capabilities, typical use cases, and pricing details so
learners can explore alternatives for their own RAG systems.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Any, List</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co"># from sentence_transformers import SentenceTransformer</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">from</span> botocore.exceptions <span class="im">import</span> ClientError</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co"># ---- AWS configuration ----</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>session <span class="op">=</span> sagemaker.Session()</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>region <span class="op">=</span> session.boto_region_name</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co"># Claude 3 Haiku is a good starting point for batch evaluation.</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a><span class="co"># Swap for Sonnet/Opus if you have access and want higher quality.</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>bedrock_model_id <span class="op">=</span> <span class="st">"deepseek.v3-v1:0"</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a><span class="co"># S3 bucket + keys where Episode 02 wrote the artifacts.</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Update these keys to match your pipeline.</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">"chris-rag"</span>  <span class="co"># &lt;-- change to your bucket</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>chunks_key <span class="op">=</span> <span class="st">"wattbot_chunks.jsonl"</span></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a><span class="co"># embeddings_key = "embeddings/embeddings.npy"</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>train_key <span class="op">=</span> <span class="st">"train_QA.csv"</span></span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a>metadata_key <span class="op">=</span> <span class="st">"metadata.csv"</span></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a><span class="co"># Local working directory for downloaded artifacts</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a>local_data_dir <span class="op">=</span> <span class="st">"bedrock"</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a>os.makedirs(local_data_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a><span class="co"># AWS clients</span></span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a>s3 <span class="op">=</span> boto3.client(<span class="st">"s3"</span>, region_name<span class="op">=</span>region)</span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a>bedrock_runtime <span class="op">=</span> boto3.client(<span class="st">"bedrock-runtime"</span>, region_name<span class="op">=</span>region)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">def</span> download_from_s3(key: <span class="bu">str</span>, local_name: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    <span class="co">"""Download a file from S3 to local_data_dir and return the local path."""</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    local_path <span class="op">=</span> os.path.join(local_data_dir, local_name)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Downloading s3://</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>local_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    s3.download_file(bucket_name, key, local_path)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    <span class="cf">return</span> local_path</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>chunks_path <span class="op">=</span> download_from_s3(chunks_key, <span class="st">"wattbot_chunks.jsonl"</span>)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># emb_path = download_from_s3(embeddings_key, "embeddings.npy")</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>train_qa_path <span class="op">=</span> download_from_s3(train_key, <span class="st">"train_QA.csv"</span>)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>metadata_path <span class="op">=</span> download_from_s3(metadata_key, <span class="st">"metadata.csv"</span>)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="co"># Load artifacts</span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(chunks_path, <span class="st">"r"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> f:</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    chunked_docs <span class="op">=</span> [json.loads(line) <span class="cf">for</span> line <span class="kw">in</span> f]</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co"># chunk_embeddings = np.load(emb_path)</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>train_df <span class="op">=</span> pd.read_csv(train_qa_path)</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a><span class="co"># Robust metadata load: handle possible non-UTF-8 characters</span></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>    metadata_df <span class="op">=</span> pd.read_csv(metadata_path)</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a><span class="cf">except</span> <span class="pp">UnicodeDecodeError</span>:</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>    metadata_df <span class="op">=</span> pd.read_csv(metadata_path, encoding<span class="op">=</span><span class="st">"latin1"</span>)</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Chunks: </span><span class="sc">{</span><span class="bu">len</span>(chunked_docs)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train QAs: </span><span class="sc">{</span><span class="bu">len</span>(train_df)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a><span class="co"># print("Embeddings shape:", chunk_embeddings.shape)</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">def</span> retrieve_context_for_question_bedrock(</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    question: <span class="bu">str</span>,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    chunk_embeddings: np.ndarray,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>    chunked_docs,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>    top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>):</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">    Retrieve top-k chunks for a question using Bedrock embeddings.</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">    We call the Bedrock embedding model (via `bedrock_embed_text`) to</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">    embed the question, then compute cosine similarity against the</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">    pre-computed `chunk_embeddings` array.</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>    <span class="co"># Embed the question with the same Bedrock model used for chunks</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>    q_emb <span class="op">=</span> bedrock_embed_text(question)</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    <span class="co"># Use the same cosine similarity + top-k helper as before</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    retrieved <span class="op">=</span> retrieve_top_k(q_emb, chunk_embeddings, chunked_docs, k<span class="op">=</span>top_k)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    <span class="cf">return</span> retrieved, q_emb</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Build a mapping from doc_id -&gt; URL so we can surface links in our outputs</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>docid_to_url <span class="op">=</span> {}</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> metadata_df.iterrows():</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    doc_id <span class="op">=</span> <span class="bu">str</span>(row.get(<span class="st">"id"</span>, <span class="st">""</span>)).strip()</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    url <span class="op">=</span> row.get(<span class="st">"url"</span>, <span class="st">""</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    <span class="cf">if</span> doc_id <span class="kw">and</span> <span class="bu">isinstance</span>(url, <span class="bu">str</span>) <span class="kw">and</span> url.strip():</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        docid_to_url[doc_id] <span class="op">=</span> url.strip()</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"docid_to_url has </span><span class="sc">{</span><span class="bu">len</span>(docid_to_url)<span class="sc">}</span><span class="ss"> entries."</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># ----------------------------------------------------------------------------------</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co"># Bedrock embeddings for WattBot chunks</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co"># ----------------------------------------------------------------------------------</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>embedding_model_id_bedrock <span class="op">=</span> <span class="st">"amazon.titan-embed-text-v2:0"</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">"data"</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>data_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>emb_save_path <span class="op">=</span> data_dir <span class="op">/</span> <span class="st">"embeddings_bedrock.npy"</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="kw">def</span> bedrock_embed_text(text: <span class="bu">str</span>, model_id: <span class="bu">str</span> <span class="op">=</span> embedding_model_id_bedrock):</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    <span class="co">"""Call a Bedrock embedding model for a single input string."""</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    body <span class="op">=</span> json.dumps({<span class="st">"inputText"</span>: text})</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>    response <span class="op">=</span> bedrock_runtime.invoke_model(</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>        modelId<span class="op">=</span>model_id,</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>        body<span class="op">=</span>body,</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>    )</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>    response_body <span class="op">=</span> json.loads(response[<span class="st">"body"</span>].read())</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>    embedding <span class="op">=</span> response_body.get(<span class="st">"embedding"</span>)</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>    <span class="cf">if</span> embedding <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"No 'embedding' found in response: </span><span class="sc">{</span>response_body<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>    <span class="cf">return</span> embedding</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="co"># If an embedding file already exists, skip recomputing and load it instead</span></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a><span class="co"># -------------------------------------------------------------------------</span></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a><span class="cf">if</span> emb_save_path.exists():</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Found existing embeddings at </span><span class="sc">{</span>emb_save_path<span class="sc">}</span><span class="ss">. Skipping re-computation."</span>)</span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a>    chunk_embeddings <span class="op">=</span> np.load(emb_save_path)</span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No existing embeddings found. Computing via Bedrock..."</span>)</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a>    all_embeddings <span class="op">=</span> []</span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>    <span class="cf">for</span> idx, ch <span class="kw">in</span> <span class="bu">enumerate</span>(chunked_docs):</span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>        <span class="cf">if</span> (idx <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">250</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Embedding chunk </span><span class="sc">{</span>idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> / </span><span class="sc">{</span><span class="bu">len</span>(chunked_docs)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a>        text <span class="op">=</span> ch.get(<span class="st">"text"</span>, <span class="st">""</span>)</span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a>        emb <span class="op">=</span> bedrock_embed_text(text)</span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a>        all_embeddings.append(emb)</span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a>    chunk_embeddings <span class="op">=</span> np.array(all_embeddings, dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb6-42"><a href="#cb6-42" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" tabindex="-1"></a>    <span class="co"># Save embeddings for reuse</span></span>
<span id="cb6-44"><a href="#cb6-44" tabindex="-1"></a>    np.save(emb_save_path, chunk_embeddings)</span>
<span id="cb6-45"><a href="#cb6-45" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Saved embeddings to </span><span class="sc">{</span>emb_save_path<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Save embeddings so we can reuse them later without re-calling Bedrock</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>np.save(emb_save_path, chunk_embeddings)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Saved Bedrock chunk embeddings to"</span>, emb_save_path)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Embeddings shape:"</span>, chunk_embeddings.shape)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># ---------------------- similarity + retrieval ----------------------</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># ---------------------- similarity + retrieval ----------------------</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="kw">def</span> cosine_similarity_matrix(a: np.ndarray, b: np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    <span class="co">"""Cosine similarity between two sets of vectors.</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">    This helper is intentionally defensive: it will accept Python lists,</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">    list-of-lists, or NumPy arrays and cast everything to float32 arrays</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">    before computing similarities.</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>    a <span class="op">=</span> np.asarray(a, dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    b <span class="op">=</span> np.asarray(b, dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    <span class="co"># Ensure 2D</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    <span class="cf">if</span> a.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>        a <span class="op">=</span> a.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>    <span class="cf">if</span> b.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>        b <span class="op">=</span> b.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>    a_norm <span class="op">=</span> a <span class="op">/</span> np.linalg.norm(a, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    b_norm <span class="op">=</span> b <span class="op">/</span> np.linalg.norm(b, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    <span class="cf">return</span> np.matmul(a_norm, b_norm.T)</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a><span class="kw">def</span> retrieve_top_k(</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>    query_embedding: np.ndarray,</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>    chunk_embeddings: np.ndarray,</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>    chunked_docs: List[Dict[<span class="bu">str</span>, Any]],</span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>    k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>) <span class="op">-&gt;</span> List[Dict[<span class="bu">str</span>, Any]]:</span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>    <span class="co">"""Return the top–k chunks for a single query embedding.</span></span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a><span class="co">    Accepts query/collection embeddings as either NumPy arrays or lists.</span></span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a>    <span class="co"># Defensive casting in case we accidentally pass in lists</span></span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>    query <span class="op">=</span> np.asarray(query_embedding, dtype<span class="op">=</span><span class="st">"float32"</span>).reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>    chunks <span class="op">=</span> np.asarray(chunk_embeddings, dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>    sims <span class="op">=</span> cosine_similarity_matrix(query, chunks)[<span class="dv">0</span>]</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a>    top_idx <span class="op">=</span> np.argsort(<span class="op">-</span>sims)[:k]</span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_idx:</span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a>        ch <span class="op">=</span> chunked_docs[idx]</span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a>        results.append(</span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a>            {</span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a>                <span class="st">"score"</span>: <span class="bu">float</span>(sims[idx]),</span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>                <span class="st">"text"</span>: ch[<span class="st">"text"</span>],</span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>                <span class="st">"doc_id"</span>: ch.get(<span class="st">"doc_id"</span>, <span class="st">""</span>),</span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a>                <span class="st">"title"</span>: ch.get(<span class="st">"title"</span>, <span class="st">""</span>),</span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a>                <span class="st">"url"</span>: ch.get(<span class="st">"url"</span>, <span class="st">""</span>),</span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a>                <span class="st">"page_num"</span>: ch.get(<span class="st">"page_num"</span>, <span class="va">None</span>),</span>
<span id="cb8-56"><a href="#cb8-56" tabindex="-1"></a>                <span class="st">"page_label"</span>: ch.get(<span class="st">"page_label"</span>, <span class="va">None</span>),</span>
<span id="cb8-57"><a href="#cb8-57" tabindex="-1"></a>            }</span>
<span id="cb8-58"><a href="#cb8-58" tabindex="-1"></a>        )</span>
<span id="cb8-59"><a href="#cb8-59" tabindex="-1"></a>    <span class="cf">return</span> results</span>
<span id="cb8-60"><a href="#cb8-60" tabindex="-1"></a></span>
<span id="cb8-61"><a href="#cb8-61" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" tabindex="-1"></a></span>
<span id="cb8-63"><a href="#cb8-63" tabindex="-1"></a><span class="kw">def</span> format_context_for_prompt(retrieved_chunks: List[Dict[<span class="bu">str</span>, Any]]) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb8-64"><a href="#cb8-64" tabindex="-1"></a>    <span class="co">"""Turn retrieved chunk dicts into a compact context string for the LLM."""</span></span>
<span id="cb8-65"><a href="#cb8-65" tabindex="-1"></a>    lines <span class="op">=</span> []</span>
<span id="cb8-66"><a href="#cb8-66" tabindex="-1"></a>    <span class="cf">for</span> i, ch <span class="kw">in</span> <span class="bu">enumerate</span>(retrieved_chunks, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb8-67"><a href="#cb8-67" tabindex="-1"></a>        label <span class="op">=</span> ch.get(<span class="st">"doc_id"</span>, <span class="ss">f"chunk_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-68"><a href="#cb8-68" tabindex="-1"></a>        page <span class="op">=</span> ch.get(<span class="st">"page_label"</span>, ch.get(<span class="st">"page_num"</span>, <span class="st">""</span>))</span>
<span id="cb8-69"><a href="#cb8-69" tabindex="-1"></a>        header <span class="op">=</span> <span class="ss">f"[</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">, page </span><span class="sc">{</span>page<span class="sc">}</span><span class="ss">]"</span>.strip()</span>
<span id="cb8-70"><a href="#cb8-70" tabindex="-1"></a>        txt <span class="op">=</span> ch[<span class="st">"text"</span>].replace(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>, <span class="st">" "</span>)</span>
<span id="cb8-71"><a href="#cb8-71" tabindex="-1"></a>        lines.append(<span class="ss">f"</span><span class="sc">{</span>header<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>txt<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-72"><a href="#cb8-72" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(lines)</span>
<span id="cb8-73"><a href="#cb8-73" tabindex="-1"></a></span>
<span id="cb8-74"><a href="#cb8-74" tabindex="-1"></a></span>
<span id="cb8-75"><a href="#cb8-75" tabindex="-1"></a><span class="kw">def</span> retrieve_context_for_question(</span>
<span id="cb8-76"><a href="#cb8-76" tabindex="-1"></a>    question: <span class="bu">str</span>,</span>
<span id="cb8-77"><a href="#cb8-77" tabindex="-1"></a>    chunk_embeddings: np.ndarray,</span>
<span id="cb8-78"><a href="#cb8-78" tabindex="-1"></a>    chunked_docs,</span>
<span id="cb8-79"><a href="#cb8-79" tabindex="-1"></a>    top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb8-80"><a href="#cb8-80" tabindex="-1"></a>):</span>
<span id="cb8-81"><a href="#cb8-81" tabindex="-1"></a>    <span class="co">"""Use Bedrock embeddings to retrieve the top-k chunks for a question."""</span></span>
<span id="cb8-82"><a href="#cb8-82" tabindex="-1"></a>    <span class="co"># Embed question with Bedrock and make sure we end up with a 1D float32 vector</span></span>
<span id="cb8-83"><a href="#cb8-83" tabindex="-1"></a>    q_vec <span class="op">=</span> bedrock_embed_text(question)</span>
<span id="cb8-84"><a href="#cb8-84" tabindex="-1"></a>    q_emb <span class="op">=</span> np.asarray(q_vec, dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb8-85"><a href="#cb8-85" tabindex="-1"></a></span>
<span id="cb8-86"><a href="#cb8-86" tabindex="-1"></a>    retrieved <span class="op">=</span> retrieve_top_k(q_emb, chunk_embeddings, chunked_docs, k<span class="op">=</span>top_k)</span>
<span id="cb8-87"><a href="#cb8-87" tabindex="-1"></a>    <span class="cf">return</span> retrieved, q_emb</span>
<span id="cb8-88"><a href="#cb8-88" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># ---------------------- answer normalization ----------------------</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="kw">def</span> normalize_answer_value(raw_value: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    <span class="co">"""Normalize answer_value according to WattBot conventions."""</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    <span class="cf">if</span> raw_value <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    s <span class="op">=</span> <span class="bu">str</span>(raw_value).strip()</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> s <span class="kw">or</span> s.lower() <span class="op">==</span> <span class="st">"none"</span>:</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    <span class="cf">if</span> s.startswith(<span class="st">"["</span>) <span class="kw">and</span> s.endswith(<span class="st">"]"</span>):</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>        <span class="cf">return</span> s</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    <span class="cf">if</span> s.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    <span class="co"># If there is whitespace, keep only the first token</span></span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">" "</span> <span class="kw">in</span> s:</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>        first, <span class="op">*</span>_ <span class="op">=</span> s.split()</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>        s <span class="op">=</span> first</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>    <span class="co"># Remove commas</span></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>    s <span class="op">=</span> s.replace(<span class="st">","</span>, <span class="st">""</span>)</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>        val <span class="op">=</span> <span class="bu">float</span>(s)</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>        <span class="cf">if</span> val.is_integer():</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">str</span>(<span class="bu">int</span>(val))</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span>val<span class="sc">:.10g}</span><span class="ss">"</span>  <span class="co"># avoid scientific notation</span></span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">ValueError</span>:</span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>        <span class="cf">return</span> s</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="kw">def</span> call_bedrock_claude(</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    system_prompt: <span class="bu">str</span>,</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>    user_prompt: <span class="bu">str</span>,</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>    model_id: <span class="bu">str</span> <span class="op">=</span> bedrock_model_id,</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>    max_tokens: <span class="bu">int</span> <span class="op">=</span> <span class="dv">512</span>,</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.3</span>,</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">    Call a Bedrock chat model (Anthropic 4.x / Claude 3.5 / Llama 3.x, etc.)</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co">    that uses the OpenAI-style chat completions schema.</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    <span class="co"># OpenAI-style chat body – this is what your error message is asking for</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    body <span class="op">=</span> {</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>        <span class="st">"model"</span>: model_id,  <span class="co"># some models allow omitting this, but it's safe to include</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>        <span class="st">"messages"</span>: [</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>            {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: system_prompt},</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>            {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: user_prompt},</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>        ],</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>        <span class="st">"max_tokens"</span>: max_tokens,</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>        <span class="st">"temperature"</span>: temperature,</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    }</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>    request <span class="op">=</span> json.dumps(body)</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>        response <span class="op">=</span> bedrock_runtime.invoke_model(modelId<span class="op">=</span>model_id, body<span class="op">=</span>request)</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    <span class="cf">except</span> ClientError <span class="im">as</span> e:</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"ERROR calling Bedrock model </span><span class="sc">{</span>model_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>        <span class="cf">raise</span></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>    model_response <span class="op">=</span> json.loads(response[<span class="st">"body"</span>].read())</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>    <span class="co"># OpenAI-style response: choices[0].message.content</span></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>        text <span class="op">=</span> model_response[<span class="st">"choices"</span>][<span class="dv">0</span>][<span class="st">"message"</span>][<span class="st">"content"</span>]</span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>        <span class="co"># Fallback / debug</span></span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Unexpected model response:"</span>, model_response)</span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>        <span class="cf">raise</span></span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>    <span class="cf">return</span> text.strip()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># ---------------------- explanation helpers ----------------------</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="kw">def</span> explanation_system_prompt() <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>        <span class="st">"You are an AI assistant that explains how evidence supports answers about "</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>        <span class="st">"energy, water, and carbon footprint of AI models.</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>        <span class="st">"Instructions:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>        <span class="st">"- Write 1–3 sentences.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>        <span class="st">"- Directly explain how the cited supporting materials justify the answer.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>        <span class="st">"- Do NOT include any planning text, meta-reasoning, or tags like &lt;reasoning&gt;.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>        <span class="st">"- Do NOT start with phrases like 'We need to answer'—just give the explanation."</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>    )</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="kw">def</span> explanation_system_prompt() <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>        <span class="st">"You are an AI assistant that explains how evidence supports answers about "</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>        <span class="st">"energy, water, and carbon footprint. Focus on clear, factual reasoning, "</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>        <span class="st">"and refer directly to the cited documents when appropriate."</span></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>    )</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a><span class="kw">def</span> bedrock_explanation_phase_for_question(</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>    qid: <span class="bu">str</span>,</span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>    question: <span class="bu">str</span>,</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>    answer: <span class="bu">str</span>,</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>    supporting_materials: <span class="bu">str</span>,</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>    model_id: <span class="bu">str</span> <span class="op">=</span> bedrock_model_id,</span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>    sys_prompt <span class="op">=</span> explanation_system_prompt()</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a>    prompt <span class="op">=</span> build_explanation_prompt(question, answer, supporting_materials)</span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>    raw_explanation <span class="op">=</span> call_bedrock_claude(</span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>        system_prompt<span class="op">=</span>sys_prompt,</span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a>        user_prompt<span class="op">=</span>prompt,</span>
<span id="cb11-36"><a href="#cb11-36" tabindex="-1"></a>        model_id<span class="op">=</span>model_id,</span>
<span id="cb11-37"><a href="#cb11-37" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb11-38"><a href="#cb11-38" tabindex="-1"></a>    )</span>
<span id="cb11-39"><a href="#cb11-39" tabindex="-1"></a>    <span class="cf">return</span> raw_explanation.strip()</span>
<span id="cb11-40"><a href="#cb11-40" tabindex="-1"></a></span>
<span id="cb11-41"><a href="#cb11-41" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" tabindex="-1"></a><span class="co"># ---------------------- answer phase (JSON contract) ----------------------</span></span>
<span id="cb11-43"><a href="#cb11-43" tabindex="-1"></a></span>
<span id="cb11-44"><a href="#cb11-44" tabindex="-1"></a><span class="kw">def</span> bedrock_answer_phase_for_question(</span>
<span id="cb11-45"><a href="#cb11-45" tabindex="-1"></a>    qid: <span class="bu">str</span>,</span>
<span id="cb11-46"><a href="#cb11-46" tabindex="-1"></a>    question: <span class="bu">str</span>,</span>
<span id="cb11-47"><a href="#cb11-47" tabindex="-1"></a>    retrieved_chunks: List[Dict[<span class="bu">str</span>, Any]],</span>
<span id="cb11-48"><a href="#cb11-48" tabindex="-1"></a>    model_id: <span class="bu">str</span> <span class="op">=</span> bedrock_model_id,</span>
<span id="cb11-49"><a href="#cb11-49" tabindex="-1"></a>):</span>
<span id="cb11-50"><a href="#cb11-50" tabindex="-1"></a>    <span class="co">"""Use Bedrock to answer a single WattBot question given retrieved chunks."""</span></span>
<span id="cb11-51"><a href="#cb11-51" tabindex="-1"></a>    context <span class="op">=</span> format_context_for_prompt(retrieved_chunks)</span>
<span id="cb11-52"><a href="#cb11-52" tabindex="-1"></a></span>
<span id="cb11-53"><a href="#cb11-53" tabindex="-1"></a>    system_prompt <span class="op">=</span> (</span>
<span id="cb11-54"><a href="#cb11-54" tabindex="-1"></a>        <span class="st">"You are WattBot, a question-answering assistant for energy, water, and carbon footprint.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-55"><a href="#cb11-55" tabindex="-1"></a>        <span class="st">"You must answer questions using ONLY the provided context from scientific papers.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-56"><a href="#cb11-56" tabindex="-1"></a>        <span class="st">"If the context does not contain enough information to answer or infer,</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-57"><a href="#cb11-57" tabindex="-1"></a>        <span class="st">"you must mark the question as unanswerable.</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb11-58"><a href="#cb11-58" tabindex="-1"></a>        <span class="st">"You must respond with a single JSON object with the following keys:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-59"><a href="#cb11-59" tabindex="-1"></a>        <span class="st">"- answer: natural language answer, including numeric value and units if applicable.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-60"><a href="#cb11-60" tabindex="-1"></a>        <span class="st">"- answer_value: normalized numeric (0 for false, 1 for true), or categorical value with NO units or symbols;</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-61"><a href="#cb11-61" tabindex="-1"></a>        <span class="st">"  use 'is_blank' if the question is unanswerable.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-62"><a href="#cb11-62" tabindex="-1"></a>        <span class="st">"- answer_unit: unit string (e.g., kWh, gCO2, %, is_blank).</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-63"><a href="#cb11-63" tabindex="-1"></a>        <span class="st">"- ref_id: list of document IDs that support the answer, e.g., ['ID1', 'ID2'].</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-64"><a href="#cb11-64" tabindex="-1"></a>        <span class="st">"- is_blank: true if unanswerable, false otherwise.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-65"><a href="#cb11-65" tabindex="-1"></a>        <span class="st">"- supporting_materials: short quote or table/figure pointer from the context.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb11-66"><a href="#cb11-66" tabindex="-1"></a>    )</span>
<span id="cb11-67"><a href="#cb11-67" tabindex="-1"></a></span>
<span id="cb11-68"><a href="#cb11-68" tabindex="-1"></a>    user_prompt <span class="op">=</span> (</span>
<span id="cb11-69"><a href="#cb11-69" tabindex="-1"></a>        <span class="st">"Use the context below to answer the question. "</span></span>
<span id="cb11-70"><a href="#cb11-70" tabindex="-1"></a>        <span class="st">"Return ONLY a JSON object, no extra commentary.</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb11-71"><a href="#cb11-71" tabindex="-1"></a>        <span class="ss">f"Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb11-72"><a href="#cb11-72" tabindex="-1"></a>        <span class="ss">f"Context:</span><span class="ch">\n</span><span class="sc">{</span>context<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb11-73"><a href="#cb11-73" tabindex="-1"></a>    )</span>
<span id="cb11-74"><a href="#cb11-74" tabindex="-1"></a></span>
<span id="cb11-75"><a href="#cb11-75" tabindex="-1"></a>    raw_answer <span class="op">=</span> call_bedrock_claude(</span>
<span id="cb11-76"><a href="#cb11-76" tabindex="-1"></a>        system_prompt<span class="op">=</span>system_prompt,</span>
<span id="cb11-77"><a href="#cb11-77" tabindex="-1"></a>        user_prompt<span class="op">=</span>user_prompt,</span>
<span id="cb11-78"><a href="#cb11-78" tabindex="-1"></a>        model_id<span class="op">=</span>model_id,</span>
<span id="cb11-79"><a href="#cb11-79" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb11-80"><a href="#cb11-80" tabindex="-1"></a>    )</span>
<span id="cb11-81"><a href="#cb11-81" tabindex="-1"></a></span>
<span id="cb11-82"><a href="#cb11-82" tabindex="-1"></a>    parsed <span class="op">=</span> {</span>
<span id="cb11-83"><a href="#cb11-83" tabindex="-1"></a>        <span class="st">"answer"</span>: <span class="st">""</span>,</span>
<span id="cb11-84"><a href="#cb11-84" tabindex="-1"></a>        <span class="st">"answer_value"</span>: <span class="st">"is_blank"</span>,</span>
<span id="cb11-85"><a href="#cb11-85" tabindex="-1"></a>        <span class="st">"answer_unit"</span>: <span class="st">"is_blank"</span>,</span>
<span id="cb11-86"><a href="#cb11-86" tabindex="-1"></a>        <span class="st">"ref_id"</span>: [],</span>
<span id="cb11-87"><a href="#cb11-87" tabindex="-1"></a>        <span class="st">"is_blank"</span>: <span class="va">True</span>,</span>
<span id="cb11-88"><a href="#cb11-88" tabindex="-1"></a>        <span class="st">"supporting_materials"</span>: <span class="st">"is_blank"</span>,</span>
<span id="cb11-89"><a href="#cb11-89" tabindex="-1"></a>    }</span>
<span id="cb11-90"><a href="#cb11-90" tabindex="-1"></a></span>
<span id="cb11-91"><a href="#cb11-91" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb11-92"><a href="#cb11-92" tabindex="-1"></a>        first_brace <span class="op">=</span> raw_answer.find(<span class="st">"{"</span>)</span>
<span id="cb11-93"><a href="#cb11-93" tabindex="-1"></a>        last_brace <span class="op">=</span> raw_answer.rfind(<span class="st">"}"</span>)</span>
<span id="cb11-94"><a href="#cb11-94" tabindex="-1"></a>        <span class="cf">if</span> first_brace <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">and</span> last_brace <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb11-95"><a href="#cb11-95" tabindex="-1"></a>            json_str <span class="op">=</span> raw_answer[first_brace : last_brace <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb11-96"><a href="#cb11-96" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-97"><a href="#cb11-97" tabindex="-1"></a>            json_str <span class="op">=</span> raw_answer</span>
<span id="cb11-98"><a href="#cb11-98" tabindex="-1"></a></span>
<span id="cb11-99"><a href="#cb11-99" tabindex="-1"></a>        candidate <span class="op">=</span> json.loads(json_str)</span>
<span id="cb11-100"><a href="#cb11-100" tabindex="-1"></a></span>
<span id="cb11-101"><a href="#cb11-101" tabindex="-1"></a>        parsed[<span class="st">"answer"</span>] <span class="op">=</span> candidate.get(<span class="st">"answer"</span>, <span class="st">""</span>).strip()</span>
<span id="cb11-102"><a href="#cb11-102" tabindex="-1"></a>        parsed[<span class="st">"answer_value"</span>] <span class="op">=</span> normalize_answer_value(candidate.get(<span class="st">"answer_value"</span>, <span class="st">"is_blank"</span>))</span>
<span id="cb11-103"><a href="#cb11-103" tabindex="-1"></a>        parsed[<span class="st">"answer_unit"</span>] <span class="op">=</span> <span class="bu">str</span>(candidate.get(<span class="st">"answer_unit"</span>, <span class="st">"is_blank"</span>)).strip() <span class="kw">or</span> <span class="st">"is_blank"</span></span>
<span id="cb11-104"><a href="#cb11-104" tabindex="-1"></a></span>
<span id="cb11-105"><a href="#cb11-105" tabindex="-1"></a>        ref_id <span class="op">=</span> candidate.get(<span class="st">"ref_id"</span>, [])</span>
<span id="cb11-106"><a href="#cb11-106" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(ref_id, <span class="bu">str</span>):</span>
<span id="cb11-107"><a href="#cb11-107" tabindex="-1"></a>            ref_ids <span class="op">=</span> [ref_id]</span>
<span id="cb11-108"><a href="#cb11-108" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(ref_id, <span class="bu">list</span>):</span>
<span id="cb11-109"><a href="#cb11-109" tabindex="-1"></a>            ref_ids <span class="op">=</span> [<span class="bu">str</span>(x).strip() <span class="cf">for</span> x <span class="kw">in</span> ref_id <span class="cf">if</span> x]</span>
<span id="cb11-110"><a href="#cb11-110" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-111"><a href="#cb11-111" tabindex="-1"></a>            ref_ids <span class="op">=</span> []</span>
<span id="cb11-112"><a href="#cb11-112" tabindex="-1"></a>        parsed[<span class="st">"ref_id"</span>] <span class="op">=</span> ref_ids</span>
<span id="cb11-113"><a href="#cb11-113" tabindex="-1"></a></span>
<span id="cb11-114"><a href="#cb11-114" tabindex="-1"></a>        is_blank_flag <span class="op">=</span> candidate.get(<span class="st">"is_blank"</span>, <span class="va">False</span>)</span>
<span id="cb11-115"><a href="#cb11-115" tabindex="-1"></a>        parsed[<span class="st">"is_blank"</span>] <span class="op">=</span> <span class="bu">bool</span>(is_blank_flag)</span>
<span id="cb11-116"><a href="#cb11-116" tabindex="-1"></a></span>
<span id="cb11-117"><a href="#cb11-117" tabindex="-1"></a>        supp <span class="op">=</span> candidate.get(<span class="st">"supporting_materials"</span>, <span class="st">"is_blank"</span>)</span>
<span id="cb11-118"><a href="#cb11-118" tabindex="-1"></a>        parsed[<span class="st">"supporting_materials"</span>] <span class="op">=</span> <span class="bu">str</span>(supp).strip() <span class="kw">or</span> <span class="st">"is_blank"</span></span>
<span id="cb11-119"><a href="#cb11-119" tabindex="-1"></a></span>
<span id="cb11-120"><a href="#cb11-120" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb11-121"><a href="#cb11-121" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"JSON parse error for question </span><span class="sc">{</span>qid<span class="sc">}</span><span class="ss">; defaulting to is_blank. Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-122"><a href="#cb11-122" tabindex="-1"></a></span>
<span id="cb11-123"><a href="#cb11-123" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb11-124"><a href="#cb11-124" tabindex="-1"></a>        parsed[<span class="st">"answer"</span>],</span>
<span id="cb11-125"><a href="#cb11-125" tabindex="-1"></a>        parsed[<span class="st">"answer_value"</span>],</span>
<span id="cb11-126"><a href="#cb11-126" tabindex="-1"></a>        parsed[<span class="st">"is_blank"</span>],</span>
<span id="cb11-127"><a href="#cb11-127" tabindex="-1"></a>        parsed[<span class="st">"ref_id"</span>],</span>
<span id="cb11-128"><a href="#cb11-128" tabindex="-1"></a>        parsed[<span class="st">"supporting_materials"</span>],</span>
<span id="cb11-129"><a href="#cb11-129" tabindex="-1"></a>    )</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="kw">def</span> run_single_qa_bedrock(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>    row,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>    chunk_embeddings: np.ndarray,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    chunked_docs,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    docid_to_url: <span class="bu">dict</span>,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    retrieval_threshold: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.25</span>,</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    model_id: <span class="bu">str</span> <span class="op">=</span> <span class="st">"anthropic.claude-3-haiku-20240307-v1:0"</span>,</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>):</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="co">    Full pipeline for a single question using Bedrock for both retrieval-time</span></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="co">    embeddings and generation.</span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>    qid <span class="op">=</span> row[<span class="st">"id"</span>]</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>    question <span class="op">=</span> row[<span class="st">"question"</span>]</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>    <span class="co"># 1. Retrieve supporting chunks using Bedrock embeddings for the query</span></span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>    retrieved, q_emb <span class="op">=</span> retrieve_context_for_question_bedrock(</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>        question<span class="op">=</span>question,</span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>        chunk_embeddings<span class="op">=</span>chunk_embeddings,</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>        chunked_docs<span class="op">=</span>chunked_docs,</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>        top_k<span class="op">=</span>top_k,</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>    )</span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>    top_score <span class="op">=</span> retrieved[<span class="dv">0</span>][<span class="st">"score"</span>] <span class="cf">if</span> retrieved <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>    <span class="co"># 2. Call Bedrock Claude to produce answer JSON</span></span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>    (</span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a>        answer,</span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a>        answer_value,</span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>        is_blank_llm,</span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>        ref_ids,</span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a>        supporting_materials,</span>
<span id="cb12-34"><a href="#cb12-34" tabindex="-1"></a>    ) <span class="op">=</span> bedrock_answer_phase_for_question(</span>
<span id="cb12-35"><a href="#cb12-35" tabindex="-1"></a>        qid<span class="op">=</span>qid,</span>
<span id="cb12-36"><a href="#cb12-36" tabindex="-1"></a>        question<span class="op">=</span>question,</span>
<span id="cb12-37"><a href="#cb12-37" tabindex="-1"></a>        retrieved_chunks<span class="op">=</span>retrieved,</span>
<span id="cb12-38"><a href="#cb12-38" tabindex="-1"></a>        model_id<span class="op">=</span>model_id,</span>
<span id="cb12-39"><a href="#cb12-39" tabindex="-1"></a>    )</span>
<span id="cb12-40"><a href="#cb12-40" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" tabindex="-1"></a>    <span class="co"># --------------------------------------------------------</span></span>
<span id="cb12-42"><a href="#cb12-42" tabindex="-1"></a>    <span class="co"># 3. DECISION: retrieval_threshold OR model blank?</span></span>
<span id="cb12-43"><a href="#cb12-43" tabindex="-1"></a>    <span class="co"># --------------------------------------------------------</span></span>
<span id="cb12-44"><a href="#cb12-44" tabindex="-1"></a>    <span class="co"># </span><span class="al">NOTE</span><span class="co">: we only tell the user when it *actually* gets blanked.</span></span>
<span id="cb12-45"><a href="#cb12-45" tabindex="-1"></a>    <span class="cf">if</span> is_blank_llm:</span>
<span id="cb12-46"><a href="#cb12-46" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"[diag][</span><span class="sc">{</span>qid<span class="sc">}</span><span class="ss">] → Model returned is_blank (LLM could not answer)."</span>)</span>
<span id="cb12-47"><a href="#cb12-47" tabindex="-1"></a>    <span class="cf">elif</span> top_score <span class="op">&lt;</span> retrieval_threshold:</span>
<span id="cb12-48"><a href="#cb12-48" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb12-49"><a href="#cb12-49" tabindex="-1"></a>            <span class="ss">f"[diag][</span><span class="sc">{</span>qid<span class="sc">}</span><span class="ss">] → Retrieval blocked: top cosine=</span><span class="sc">{</span>top_score<span class="sc">:.3f}</span><span class="ss"> "</span></span>
<span id="cb12-50"><a href="#cb12-50" tabindex="-1"></a>            <span class="ss">f"&lt; threshold=</span><span class="sc">{</span>retrieval_threshold<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb12-51"><a href="#cb12-51" tabindex="-1"></a>        )</span>
<span id="cb12-52"><a href="#cb12-52" tabindex="-1"></a>    is_blank <span class="op">=</span> <span class="bu">bool</span>(is_blank_llm) <span class="kw">or</span> (top_score <span class="op">&lt;</span> retrieval_threshold)</span>
<span id="cb12-53"><a href="#cb12-53" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" tabindex="-1"></a>    <span class="cf">if</span> is_blank:</span>
<span id="cb12-55"><a href="#cb12-55" tabindex="-1"></a>        answer <span class="op">=</span> <span class="st">"Unable to answer with confidence based on the provided documents."</span></span>
<span id="cb12-56"><a href="#cb12-56" tabindex="-1"></a>        answer_value <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-57"><a href="#cb12-57" tabindex="-1"></a>        answer_unit <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-58"><a href="#cb12-58" tabindex="-1"></a>        ref_ids <span class="op">=</span> []</span>
<span id="cb12-59"><a href="#cb12-59" tabindex="-1"></a>        ref_id_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-60"><a href="#cb12-60" tabindex="-1"></a>        ref_url_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-61"><a href="#cb12-61" tabindex="-1"></a>        supporting_materials <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-62"><a href="#cb12-62" tabindex="-1"></a>        explanation <span class="op">=</span> <span class="st">""</span></span>
<span id="cb12-63"><a href="#cb12-63" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb12-64"><a href="#cb12-64" tabindex="-1"></a>        answer_value <span class="op">=</span> normalize_answer_value(answer_value)</span>
<span id="cb12-65"><a href="#cb12-65" tabindex="-1"></a>        answer_unit <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-66"><a href="#cb12-66" tabindex="-1"></a></span>
<span id="cb12-67"><a href="#cb12-67" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(ref_ids, <span class="bu">list</span>) <span class="kw">and</span> ref_ids:</span>
<span id="cb12-68"><a href="#cb12-68" tabindex="-1"></a>            ref_id_str <span class="op">=</span> <span class="st">";"</span>.join(ref_ids)</span>
<span id="cb12-69"><a href="#cb12-69" tabindex="-1"></a>            urls <span class="op">=</span> []</span>
<span id="cb12-70"><a href="#cb12-70" tabindex="-1"></a>            <span class="cf">for</span> rid <span class="kw">in</span> ref_ids:</span>
<span id="cb12-71"><a href="#cb12-71" tabindex="-1"></a>                url <span class="op">=</span> docid_to_url.get(<span class="bu">str</span>(rid), <span class="st">""</span>)</span>
<span id="cb12-72"><a href="#cb12-72" tabindex="-1"></a>                <span class="cf">if</span> url:</span>
<span id="cb12-73"><a href="#cb12-73" tabindex="-1"></a>                    urls.append(url)</span>
<span id="cb12-74"><a href="#cb12-74" tabindex="-1"></a>            ref_url_str <span class="op">=</span> <span class="st">";"</span>.join(urls) <span class="cf">if</span> urls <span class="cf">else</span> <span class="st">"is_blank"</span></span>
<span id="cb12-75"><a href="#cb12-75" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb12-76"><a href="#cb12-76" tabindex="-1"></a>            ref_id_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-77"><a href="#cb12-77" tabindex="-1"></a>            ref_url_str <span class="op">=</span> <span class="st">"is_blank"</span></span>
<span id="cb12-78"><a href="#cb12-78" tabindex="-1"></a></span>
<span id="cb12-79"><a href="#cb12-79" tabindex="-1"></a>        explanation <span class="op">=</span> bedrock_explanation_phase_for_question(</span>
<span id="cb12-80"><a href="#cb12-80" tabindex="-1"></a>            qid<span class="op">=</span>qid,</span>
<span id="cb12-81"><a href="#cb12-81" tabindex="-1"></a>            question<span class="op">=</span>question,</span>
<span id="cb12-82"><a href="#cb12-82" tabindex="-1"></a>            answer<span class="op">=</span>answer,</span>
<span id="cb12-83"><a href="#cb12-83" tabindex="-1"></a>            supporting_materials<span class="op">=</span>supporting_materials,</span>
<span id="cb12-84"><a href="#cb12-84" tabindex="-1"></a>            model_id<span class="op">=</span>model_id,</span>
<span id="cb12-85"><a href="#cb12-85" tabindex="-1"></a>        )</span>
<span id="cb12-86"><a href="#cb12-86" tabindex="-1"></a></span>
<span id="cb12-87"><a href="#cb12-87" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb12-88"><a href="#cb12-88" tabindex="-1"></a>        <span class="st">"id"</span>: qid,</span>
<span id="cb12-89"><a href="#cb12-89" tabindex="-1"></a>        <span class="st">"question"</span>: question,</span>
<span id="cb12-90"><a href="#cb12-90" tabindex="-1"></a>        <span class="st">"answer"</span>: answer,</span>
<span id="cb12-91"><a href="#cb12-91" tabindex="-1"></a>        <span class="st">"answer_value"</span>: answer_value,</span>
<span id="cb12-92"><a href="#cb12-92" tabindex="-1"></a>        <span class="st">"answer_unit"</span>: answer_unit,</span>
<span id="cb12-93"><a href="#cb12-93" tabindex="-1"></a>        <span class="st">"ref_id"</span>: ref_id_str,</span>
<span id="cb12-94"><a href="#cb12-94" tabindex="-1"></a>        <span class="st">"ref_url"</span>: ref_url_str,</span>
<span id="cb12-95"><a href="#cb12-95" tabindex="-1"></a>        <span class="st">"supporting_materials"</span>: supporting_materials,</span>
<span id="cb12-96"><a href="#cb12-96" tabindex="-1"></a>        <span class="st">"explanation"</span>: explanation,</span>
<span id="cb12-97"><a href="#cb12-97" tabindex="-1"></a>    }</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="run-the-wattbot-evaluation-with-bedrock">Run the WattBot evaluation with Bedrock<a class="anchor" aria-label="anchor" href="#run-the-wattbot-evaluation-with-bedrock"></a>
</h2>
<hr class="half-width">
<p>Now we can loop over all questions in <code>train_QA.csv</code>, run
retrieval + Bedrock generation, and write a
<code>wattbot_solutions_bedrock.csv</code> file.</p>
<p>This mirrors the logic from Episode 02 – the only difference is that
the answer and explanation phases call a hosted Claude 3 model instead
of a local Qwen model.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># For quick smoke tests, you can slice train_df (e.g., train_df.head(5))</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> train_df.iterrows():</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>    question <span class="op">=</span> row[<span class="st">"question"</span>]</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"#"</span> <span class="op">*</span> <span class="dv">96</span>)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"QUESTION: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>    out <span class="op">=</span> run_single_qa_bedrock(</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>        row<span class="op">=</span>row,</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>        chunk_embeddings<span class="op">=</span>chunk_embeddings,</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>        chunked_docs<span class="op">=</span>chunked_docs,</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>        docid_to_url<span class="op">=</span>docid_to_url,</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>        top_k<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>        retrieval_threshold<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>        model_id<span class="op">=</span>bedrock_model_id,</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>    )</span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>    answer <span class="op">=</span> out[<span class="st">"answer"</span>]</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>    ref_ids <span class="op">=</span> out[<span class="st">"ref_id"</span>]</span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>    explanation <span class="op">=</span> out[<span class="st">"explanation"</span>]</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"ANSWER: </span><span class="sc">{</span>answer<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"ref_ids: </span><span class="sc">{</span>ref_ids<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"EXPLANATION: </span><span class="sc">{</span>explanation<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>    results.append(out)</span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"outputs"</span></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a>os.makedirs(output_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>output_path <span class="op">=</span> os.path.join(output_dir, <span class="st">"wattbot_solutions_bedrock.csv"</span>)</span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a>results_df.to_csv(output_path, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Wrote predictions to </span><span class="sc">{</span>output_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a>results_df.head()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="kw">def</span> _to_bool_flag(x):</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>    <span class="co">"""Convert typical truthy/falsey strings to bool."""</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(x, <span class="bu">str</span>):</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>        s <span class="op">=</span> x.strip().lower()</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">in</span> {<span class="st">"1"</span>, <span class="st">"True"</span>, <span class="st">"true"</span>, <span class="st">"yes"</span>}:</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">in</span> {<span class="st">"0"</span>, <span class="st">"False"</span>, <span class="st">"false"</span>, <span class="st">"no"</span>}:</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">bool</span>(x)</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="kw">def</span> _parse_float_or_none(x):</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">float</span>(<span class="bu">str</span>(x).strip())</span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a><span class="kw">def</span> _answer_value_correct(gt_val, pred_val, rel_tol<span class="op">=</span><span class="fl">1e-3</span>):</span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a><span class="co">    gt_val, pred_val: values from answer_value columns.</span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a><span class="co">    rel_tol = 0.001 =&gt; 0.1% relative tolerance.</span></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    gt_str <span class="op">=</span> <span class="bu">str</span>(gt_val).strip()</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    pred_str <span class="op">=</span> <span class="bu">str</span>(pred_val).strip()</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>    </span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>    <span class="co"># If either is 'is_blank', treat as categorical</span></span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>    <span class="cf">if</span> gt_str.lower() <span class="op">==</span> <span class="st">"is_blank"</span> <span class="kw">or</span> pred_str.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a>        <span class="cf">return</span> gt_str.lower() <span class="op">==</span> pred_str.lower()</span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a>    </span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>    gt_num <span class="op">=</span> _parse_float_or_none(gt_val)</span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>    pred_num <span class="op">=</span> _parse_float_or_none(pred_val)</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a>    </span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>    <span class="co"># If both numeric, use relative tolerance</span></span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>    <span class="cf">if</span> gt_num <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_num <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a>        <span class="cf">if</span> gt_num <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb14-38"><a href="#cb14-38" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">abs</span>(pred_num <span class="op">-</span> gt_num) <span class="op">&lt;=</span> rel_tol  <span class="co"># small absolute tolerance around 0</span></span>
<span id="cb14-39"><a href="#cb14-39" tabindex="-1"></a>        rel_err <span class="op">=</span> <span class="bu">abs</span>(pred_num <span class="op">-</span> gt_num) <span class="op">/</span> <span class="bu">max</span>(<span class="bu">abs</span>(gt_num), <span class="fl">1e-12</span>)</span>
<span id="cb14-40"><a href="#cb14-40" tabindex="-1"></a>        <span class="cf">return</span> rel_err <span class="op">&lt;=</span> rel_tol</span>
<span id="cb14-41"><a href="#cb14-41" tabindex="-1"></a>    </span>
<span id="cb14-42"><a href="#cb14-42" tabindex="-1"></a>    <span class="co"># Otherwise, fall back to normalized string match</span></span>
<span id="cb14-43"><a href="#cb14-43" tabindex="-1"></a>    <span class="cf">return</span> gt_str.lower() <span class="op">==</span> pred_str.lower()</span>
<span id="cb14-44"><a href="#cb14-44" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" tabindex="-1"></a><span class="kw">def</span> _ref_id_jaccard(gt_ref, pred_ref):</span>
<span id="cb14-46"><a href="#cb14-46" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb14-47"><a href="#cb14-47" tabindex="-1"></a><span class="co">    Jaccard overlap between sets of ref_ids.</span></span>
<span id="cb14-48"><a href="#cb14-48" tabindex="-1"></a><span class="co">    Strings may contain semicolon-separated IDs, or 'is_blank'.</span></span>
<span id="cb14-49"><a href="#cb14-49" tabindex="-1"></a><span class="co">    Case-insensitive.</span></span>
<span id="cb14-50"><a href="#cb14-50" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-51"><a href="#cb14-51" tabindex="-1"></a>    <span class="kw">def</span> to_set(s):</span>
<span id="cb14-52"><a href="#cb14-52" tabindex="-1"></a>        <span class="cf">if</span> s <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb14-53"><a href="#cb14-53" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">set</span>()</span>
<span id="cb14-54"><a href="#cb14-54" tabindex="-1"></a>        s <span class="op">=</span> <span class="bu">str</span>(s).strip()</span>
<span id="cb14-55"><a href="#cb14-55" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> s <span class="kw">or</span> s.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb14-56"><a href="#cb14-56" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">set</span>()</span>
<span id="cb14-57"><a href="#cb14-57" tabindex="-1"></a>        parts <span class="op">=</span> [p.strip().lower() <span class="cf">for</span> p <span class="kw">in</span> s.split(<span class="st">";"</span>) <span class="cf">if</span> p.strip()]</span>
<span id="cb14-58"><a href="#cb14-58" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">set</span>(parts)</span>
<span id="cb14-59"><a href="#cb14-59" tabindex="-1"></a>    </span>
<span id="cb14-60"><a href="#cb14-60" tabindex="-1"></a>    gt_set <span class="op">=</span> to_set(gt_ref)</span>
<span id="cb14-61"><a href="#cb14-61" tabindex="-1"></a>    pred_set <span class="op">=</span> to_set(pred_ref)</span>
<span id="cb14-62"><a href="#cb14-62" tabindex="-1"></a>    </span>
<span id="cb14-63"><a href="#cb14-63" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> gt_set <span class="kw">and</span> <span class="kw">not</span> pred_set:</span>
<span id="cb14-64"><a href="#cb14-64" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1.0</span></span>
<span id="cb14-65"><a href="#cb14-65" tabindex="-1"></a>    union <span class="op">=</span> gt_set <span class="op">|</span> pred_set</span>
<span id="cb14-66"><a href="#cb14-66" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> union:</span>
<span id="cb14-67"><a href="#cb14-67" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.0</span></span>
<span id="cb14-68"><a href="#cb14-68" tabindex="-1"></a>    inter <span class="op">=</span> gt_set <span class="op">&amp;</span> pred_set</span>
<span id="cb14-69"><a href="#cb14-69" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(inter) <span class="op">/</span> <span class="bu">len</span>(union)</span>
<span id="cb14-70"><a href="#cb14-70" tabindex="-1"></a></span>
<span id="cb14-71"><a href="#cb14-71" tabindex="-1"></a><span class="kw">def</span> compute_wattbot_score(</span>
<span id="cb14-72"><a href="#cb14-72" tabindex="-1"></a>    train_qa_path<span class="op">=</span><span class="st">"train_QA.csv"</span>,</span>
<span id="cb14-73"><a href="#cb14-73" tabindex="-1"></a>    preds_path<span class="op">=</span><span class="st">"train_solutions_qwen.csv"</span>,</span>
<span id="cb14-74"><a href="#cb14-74" tabindex="-1"></a>    id_col<span class="op">=</span><span class="st">"id"</span>,</span>
<span id="cb14-75"><a href="#cb14-75" tabindex="-1"></a>    gt_answer_col<span class="op">=</span><span class="st">"answer_value"</span>,</span>
<span id="cb14-76"><a href="#cb14-76" tabindex="-1"></a>    gt_ref_col<span class="op">=</span><span class="st">"ref_id"</span>,</span>
<span id="cb14-77"><a href="#cb14-77" tabindex="-1"></a>    gt_is_na_col<span class="op">=</span><span class="st">"is_NA"</span>,   <span class="co"># can also pass "is_blank" or None</span></span>
<span id="cb14-78"><a href="#cb14-78" tabindex="-1"></a>    pred_answer_col<span class="op">=</span><span class="st">"answer_value"</span>,</span>
<span id="cb14-79"><a href="#cb14-79" tabindex="-1"></a>    pred_ref_col<span class="op">=</span><span class="st">"ref_id"</span>,</span>
<span id="cb14-80"><a href="#cb14-80" tabindex="-1"></a>    pred_is_na_col<span class="op">=</span><span class="va">None</span>,    <span class="co"># can pass "is_blank", or leave None to auto</span></span>
<span id="cb14-81"><a href="#cb14-81" tabindex="-1"></a>    n_examples<span class="op">=</span><span class="dv">10</span>,          <span class="co"># how many incorrect examples to print</span></span>
<span id="cb14-82"><a href="#cb14-82" tabindex="-1"></a>):</span>
<span id="cb14-83"><a href="#cb14-83" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb14-84"><a href="#cb14-84" tabindex="-1"></a><span class="co">    Compare your solutions to train_QA.csv using a WattBot-style score.</span></span>
<span id="cb14-85"><a href="#cb14-85" tabindex="-1"></a></span>
<span id="cb14-86"><a href="#cb14-86" tabindex="-1"></a><span class="co">    NA logic:</span></span>
<span id="cb14-87"><a href="#cb14-87" tabindex="-1"></a><span class="co">    - If an explicit NA column is found/used (e.g. is_NA), we use it via _to_bool_flag.</span></span>
<span id="cb14-88"><a href="#cb14-88" tabindex="-1"></a><span class="co">    - If you pass gt_is_na_col="is_blank" or pred_is_na_col="is_blank",</span></span>
<span id="cb14-89"><a href="#cb14-89" tabindex="-1"></a><span class="co">      we *derive* NA from answer_value == "is_blank" instead of expecting a real column.</span></span>
<span id="cb14-90"><a href="#cb14-90" tabindex="-1"></a><span class="co">    - If no NA column is available at all, we derive from answer_value == "is_blank".</span></span>
<span id="cb14-91"><a href="#cb14-91" tabindex="-1"></a></span>
<span id="cb14-92"><a href="#cb14-92" tabindex="-1"></a><span class="co">    Also prints up to `n_examples` rows where the model is not perfect</span></span>
<span id="cb14-93"><a href="#cb14-93" tabindex="-1"></a><span class="co">    (answer_score &lt; 1, ref_id_score &lt; 1, or is_NA_score &lt; 1).</span></span>
<span id="cb14-94"><a href="#cb14-94" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-95"><a href="#cb14-95" tabindex="-1"></a>    gt <span class="op">=</span> pd.read_csv(train_qa_path)</span>
<span id="cb14-96"><a href="#cb14-96" tabindex="-1"></a>    preds <span class="op">=</span> pd.read_csv(preds_path)</span>
<span id="cb14-97"><a href="#cb14-97" tabindex="-1"></a>    </span>
<span id="cb14-98"><a href="#cb14-98" tabindex="-1"></a>    <span class="co"># Inner join on id to be strict</span></span>
<span id="cb14-99"><a href="#cb14-99" tabindex="-1"></a>    merged <span class="op">=</span> gt.merge(preds, on<span class="op">=</span>id_col, suffixes<span class="op">=</span>(<span class="st">"_gt"</span>, <span class="st">"_pred"</span>))</span>
<span id="cb14-100"><a href="#cb14-100" tabindex="-1"></a>    <span class="cf">if</span> merged.empty:</span>
<span id="cb14-101"><a href="#cb14-101" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"No overlapping ids between ground truth and predictions."</span>)</span>
<span id="cb14-102"><a href="#cb14-102" tabindex="-1"></a></span>
<span id="cb14-103"><a href="#cb14-103" tabindex="-1"></a>    <span class="co"># ----- ground truth NA flags -----</span></span>
<span id="cb14-104"><a href="#cb14-104" tabindex="-1"></a>    <span class="cf">if</span> gt_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> gt_is_na_col <span class="kw">in</span> merged.columns:</span>
<span id="cb14-105"><a href="#cb14-105" tabindex="-1"></a>        <span class="co"># Use explicit column (e.g. "is_NA")</span></span>
<span id="cb14-106"><a href="#cb14-106" tabindex="-1"></a>        gt_is_na_series <span class="op">=</span> merged[gt_is_na_col].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb14-107"><a href="#cb14-107" tabindex="-1"></a>    <span class="cf">elif</span> gt_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> gt_is_na_col.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb14-108"><a href="#cb14-108" tabindex="-1"></a>        <span class="co"># Special meaning: derive NA from answer_value_gt == "is_blank"</span></span>
<span id="cb14-109"><a href="#cb14-109" tabindex="-1"></a>        gt_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb14-110"><a href="#cb14-110" tabindex="-1"></a>        merged[<span class="st">"gt_is_blank_flag"</span>] <span class="op">=</span> gt_is_na_series</span>
<span id="cb14-111"><a href="#cb14-111" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb14-112"><a href="#cb14-112" tabindex="-1"></a>        <span class="co"># Fallback: if we have is_NA or is_blank col, use it; else derive</span></span>
<span id="cb14-113"><a href="#cb14-113" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"is_NA"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb14-114"><a href="#cb14-114" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="st">"is_NA"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb14-115"><a href="#cb14-115" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">"is_blank"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb14-116"><a href="#cb14-116" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="st">"is_blank"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb14-117"><a href="#cb14-117" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-118"><a href="#cb14-118" tabindex="-1"></a>            gt_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb14-119"><a href="#cb14-119" tabindex="-1"></a>            merged[<span class="st">"gt_is_blank_flag"</span>] <span class="op">=</span> gt_is_na_series</span>
<span id="cb14-120"><a href="#cb14-120" tabindex="-1"></a></span>
<span id="cb14-121"><a href="#cb14-121" tabindex="-1"></a>    <span class="co"># ----- prediction NA flags -----</span></span>
<span id="cb14-122"><a href="#cb14-122" tabindex="-1"></a>    <span class="cf">if</span> pred_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_is_na_col <span class="kw">in</span> merged.columns:</span>
<span id="cb14-123"><a href="#cb14-123" tabindex="-1"></a>        pred_is_na_series <span class="op">=</span> merged[pred_is_na_col].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb14-124"><a href="#cb14-124" tabindex="-1"></a>    <span class="cf">elif</span> pred_is_na_col <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> pred_is_na_col.lower() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb14-125"><a href="#cb14-125" tabindex="-1"></a>        <span class="co"># Same convention: derive from answer_value_pred</span></span>
<span id="cb14-126"><a href="#cb14-126" tabindex="-1"></a>        pred_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb14-127"><a href="#cb14-127" tabindex="-1"></a>        merged[<span class="st">"pred_is_blank_flag"</span>] <span class="op">=</span> pred_is_na_series</span>
<span id="cb14-128"><a href="#cb14-128" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb14-129"><a href="#cb14-129" tabindex="-1"></a>        <span class="co"># Auto-detect or derive if no NA column in preds</span></span>
<span id="cb14-130"><a href="#cb14-130" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"is_NA"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb14-131"><a href="#cb14-131" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="st">"is_NA"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb14-132"><a href="#cb14-132" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">"is_blank"</span> <span class="kw">in</span> merged.columns:</span>
<span id="cb14-133"><a href="#cb14-133" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="st">"is_blank"</span>].<span class="bu">map</span>(_to_bool_flag)</span>
<span id="cb14-134"><a href="#cb14-134" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-135"><a href="#cb14-135" tabindex="-1"></a>            pred_is_na_series <span class="op">=</span> merged[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>].astype(<span class="bu">str</span>).<span class="bu">str</span>.lower().eq(<span class="st">"is_blank"</span>)</span>
<span id="cb14-136"><a href="#cb14-136" tabindex="-1"></a>            merged[<span class="st">"pred_is_blank_flag"</span>] <span class="op">=</span> pred_is_na_series</span>
<span id="cb14-137"><a href="#cb14-137" tabindex="-1"></a></span>
<span id="cb14-138"><a href="#cb14-138" tabindex="-1"></a>    ans_scores <span class="op">=</span> []</span>
<span id="cb14-139"><a href="#cb14-139" tabindex="-1"></a>    ref_scores <span class="op">=</span> []</span>
<span id="cb14-140"><a href="#cb14-140" tabindex="-1"></a>    na_scores <span class="op">=</span> []</span>
<span id="cb14-141"><a href="#cb14-141" tabindex="-1"></a>    </span>
<span id="cb14-142"><a href="#cb14-142" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> merged.iterrows():</span>
<span id="cb14-143"><a href="#cb14-143" tabindex="-1"></a>        gt_ans <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt"</span>]</span>
<span id="cb14-144"><a href="#cb14-144" tabindex="-1"></a>        pred_ans <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred"</span>]</span>
<span id="cb14-145"><a href="#cb14-145" tabindex="-1"></a>        gt_ref <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>gt_ref_col<span class="sc">}</span><span class="ss">_gt"</span>]</span>
<span id="cb14-146"><a href="#cb14-146" tabindex="-1"></a>        pred_ref <span class="op">=</span> row[<span class="ss">f"</span><span class="sc">{</span>pred_ref_col<span class="sc">}</span><span class="ss">_pred"</span>]</span>
<span id="cb14-147"><a href="#cb14-147" tabindex="-1"></a>        </span>
<span id="cb14-148"><a href="#cb14-148" tabindex="-1"></a>        gt_is_na <span class="op">=</span> <span class="bu">bool</span>(gt_is_na_series.iloc[idx])</span>
<span id="cb14-149"><a href="#cb14-149" tabindex="-1"></a>        pred_is_na <span class="op">=</span> <span class="bu">bool</span>(pred_is_na_series.iloc[idx])</span>
<span id="cb14-150"><a href="#cb14-150" tabindex="-1"></a>        </span>
<span id="cb14-151"><a href="#cb14-151" tabindex="-1"></a>        <span class="co"># 1. answer_value component</span></span>
<span id="cb14-152"><a href="#cb14-152" tabindex="-1"></a>        ans_correct <span class="op">=</span> _answer_value_correct(gt_ans, pred_ans)</span>
<span id="cb14-153"><a href="#cb14-153" tabindex="-1"></a>        ans_scores.append(<span class="fl">1.0</span> <span class="op">*</span> ans_correct)</span>
<span id="cb14-154"><a href="#cb14-154" tabindex="-1"></a>        </span>
<span id="cb14-155"><a href="#cb14-155" tabindex="-1"></a>        <span class="co"># 2. ref_id Jaccard</span></span>
<span id="cb14-156"><a href="#cb14-156" tabindex="-1"></a>        ref_j <span class="op">=</span> _ref_id_jaccard(gt_ref, pred_ref)</span>
<span id="cb14-157"><a href="#cb14-157" tabindex="-1"></a>        ref_scores.append(ref_j)</span>
<span id="cb14-158"><a href="#cb14-158" tabindex="-1"></a>        </span>
<span id="cb14-159"><a href="#cb14-159" tabindex="-1"></a>        <span class="co"># 3. is_NA component (simple: must match ground truth flag)</span></span>
<span id="cb14-160"><a href="#cb14-160" tabindex="-1"></a>        na_scores.append(<span class="fl">1.0</span> <span class="cf">if</span> gt_is_na <span class="op">==</span> pred_is_na <span class="cf">else</span> <span class="fl">0.0</span>)</span>
<span id="cb14-161"><a href="#cb14-161" tabindex="-1"></a>    </span>
<span id="cb14-162"><a href="#cb14-162" tabindex="-1"></a>    merged[<span class="st">"answer_score"</span>] <span class="op">=</span> ans_scores</span>
<span id="cb14-163"><a href="#cb14-163" tabindex="-1"></a>    merged[<span class="st">"ref_id_score"</span>] <span class="op">=</span> ref_scores</span>
<span id="cb14-164"><a href="#cb14-164" tabindex="-1"></a>    merged[<span class="st">"is_NA_score"</span>] <span class="op">=</span> na_scores</span>
<span id="cb14-165"><a href="#cb14-165" tabindex="-1"></a>    </span>
<span id="cb14-166"><a href="#cb14-166" tabindex="-1"></a>    merged[<span class="st">"wattbot_score"</span>] <span class="op">=</span> (</span>
<span id="cb14-167"><a href="#cb14-167" tabindex="-1"></a>        <span class="fl">0.75</span> <span class="op">*</span> merged[<span class="st">"answer_score"</span>]</span>
<span id="cb14-168"><a href="#cb14-168" tabindex="-1"></a>        <span class="op">+</span> <span class="fl">0.15</span> <span class="op">*</span> merged[<span class="st">"ref_id_score"</span>]</span>
<span id="cb14-169"><a href="#cb14-169" tabindex="-1"></a>        <span class="op">+</span> <span class="fl">0.10</span> <span class="op">*</span> merged[<span class="st">"is_NA_score"</span>]</span>
<span id="cb14-170"><a href="#cb14-170" tabindex="-1"></a>    )</span>
<span id="cb14-171"><a href="#cb14-171" tabindex="-1"></a>    </span>
<span id="cb14-172"><a href="#cb14-172" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Rows compared: </span><span class="sc">{</span><span class="bu">len</span>(merged)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-173"><a href="#cb14-173" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean answer_value score: </span><span class="sc">{</span>merged[<span class="st">'answer_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-174"><a href="#cb14-174" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean ref_id score:       </span><span class="sc">{</span>merged[<span class="st">'ref_id_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-175"><a href="#cb14-175" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean is_NA score:        </span><span class="sc">{</span>merged[<span class="st">'is_NA_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-176"><a href="#cb14-176" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Overall WattBot score:   </span><span class="sc">{</span>merged[<span class="st">'wattbot_score'</span>]<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-177"><a href="#cb14-177" tabindex="-1"></a>    </span>
<span id="cb14-178"><a href="#cb14-178" tabindex="-1"></a>    <span class="co"># ----- Show some incorrect examples -----</span></span>
<span id="cb14-179"><a href="#cb14-179" tabindex="-1"></a>    incorrect <span class="op">=</span> merged[</span>
<span id="cb14-180"><a href="#cb14-180" tabindex="-1"></a>        (merged[<span class="st">"answer_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb14-181"><a href="#cb14-181" tabindex="-1"></a>        <span class="op">|</span> (merged[<span class="st">"ref_id_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb14-182"><a href="#cb14-182" tabindex="-1"></a>        <span class="op">|</span> (merged[<span class="st">"is_NA_score"</span>] <span class="op">&lt;</span> <span class="fl">1.0</span>)</span>
<span id="cb14-183"><a href="#cb14-183" tabindex="-1"></a>    ]</span>
<span id="cb14-184"><a href="#cb14-184" tabindex="-1"></a>    </span>
<span id="cb14-185"><a href="#cb14-185" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> incorrect.empty <span class="kw">and</span> n_examples <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb14-186"><a href="#cb14-186" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Examples of incorrect / partially correct responses "</span></span>
<span id="cb14-187"><a href="#cb14-187" tabindex="-1"></a>              <span class="ss">f"(up to </span><span class="sc">{</span>n_examples<span class="sc">}</span><span class="ss"> rows):</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb14-188"><a href="#cb14-188" tabindex="-1"></a>        <span class="co"># Grab up to n_examples "worst" rows by wattbot_score</span></span>
<span id="cb14-189"><a href="#cb14-189" tabindex="-1"></a>        <span class="cf">for</span> _, row <span class="kw">in</span> incorrect.sort_values(<span class="st">"wattbot_score"</span>).head(n_examples).iterrows():</span>
<span id="cb14-190"><a href="#cb14-190" tabindex="-1"></a>            q <span class="op">=</span> row[<span class="st">"question_gt"</span>] <span class="cf">if</span> <span class="st">"question_gt"</span> <span class="kw">in</span> row.index <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb14-191"><a href="#cb14-191" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb14-192"><a href="#cb14-192" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"id: </span><span class="sc">{</span>row[id_col]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-193"><a href="#cb14-193" tabindex="-1"></a>            <span class="cf">if</span> q <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb14-194"><a href="#cb14-194" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>q<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-195"><a href="#cb14-195" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"GT answer_value:   </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>gt_answer_col<span class="sc">}</span><span class="ss">_gt'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-196"><a href="#cb14-196" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Pred answer_value: </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>pred_answer_col<span class="sc">}</span><span class="ss">_pred'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-197"><a href="#cb14-197" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"GT ref_id:         </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>gt_ref_col<span class="sc">}</span><span class="ss">_gt'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-198"><a href="#cb14-198" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Pred ref_id:       </span><span class="sc">{</span>row[<span class="ss">f'</span><span class="sc">{</span>pred_ref_col<span class="sc">}</span><span class="ss">_pred'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-199"><a href="#cb14-199" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"answer_score: </span><span class="sc">{</span>row[<span class="st">'answer_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb14-200"><a href="#cb14-200" tabindex="-1"></a>                  <span class="ss">f"ref_id_score: </span><span class="sc">{</span>row[<span class="st">'ref_id_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb14-201"><a href="#cb14-201" tabindex="-1"></a>                  <span class="ss">f"is_NA_score: </span><span class="sc">{</span>row[<span class="st">'is_NA_score'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb14-202"><a href="#cb14-202" tabindex="-1"></a>                  <span class="ss">f"wattbot_score: </span><span class="sc">{</span>row[<span class="st">'wattbot_score'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb14-203"><a href="#cb14-203" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb14-204"><a href="#cb14-204" tabindex="-1"></a>    </span>
<span id="cb14-205"><a href="#cb14-205" tabindex="-1"></a>    <span class="cf">return</span> merged</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># ------------------------------------------------------------------</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="co"># Normalize reference IDs + answer ranges after results are created</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="co"># ------------------------------------------------------------------</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Any</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="kw">def</span> normalize_ref_ids(refs: Any) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="co">    Normalize reference IDs to a Python-list-style string.</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co">    Output format examples:</span></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co">      Input                       → Output</span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a><span class="co">      ---------------------------------------------------------</span></span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co">      "chen2024"                 → "['chen2024']"</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a><span class="co">      ['chen2024']               → "['chen2024']"</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a><span class="co">      "[chen2024]"               → "['chen2024']"</span></span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a><span class="co">      "['chen2024']"             → "['chen2024']"</span></span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a><span class="co">      "chen2024;smith2023"       → "['chen2024', 'smith2023']"</span></span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a><span class="co">      "chen2024, smith2023"      → "['chen2024', 'smith2023']"</span></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a><span class="co">      "[wu2021b;wu2021a]"        → "['wu2021b', 'wu2021a']"</span></span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a><span class="co">      ['wu2021b','wu2021a']      → "['wu2021b', 'wu2021a']"</span></span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a><span class="co">      None                       → "is_blank"</span></span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a><span class="co">      "is_blank"                 → "is_blank"</span></span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a><span class="co">    Rules:</span></span>
<span id="cb15-30"><a href="#cb15-30" tabindex="-1"></a><span class="co">      - "is_blank" stays exactly "is_blank".</span></span>
<span id="cb15-31"><a href="#cb15-31" tabindex="-1"></a><span class="co">      - Semicolons are treated as separators (→ commas).</span></span>
<span id="cb15-32"><a href="#cb15-32" tabindex="-1"></a><span class="co">      - Strips stray brackets, quotes, spaces.</span></span>
<span id="cb15-33"><a href="#cb15-33" tabindex="-1"></a><span class="co">      - Produces Python-list-style: ['id'] or ['id1', 'id2'].</span></span>
<span id="cb15-34"><a href="#cb15-34" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb15-35"><a href="#cb15-35" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-36"><a href="#cb15-36" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" tabindex="-1"></a>    <span class="co"># ----- 1. Handle blanks -----</span></span>
<span id="cb15-38"><a href="#cb15-38" tabindex="-1"></a>    <span class="cf">if</span> refs <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="bu">str</span>(refs).strip() <span class="op">==</span> <span class="st">"is_blank"</span>:</span>
<span id="cb15-39"><a href="#cb15-39" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb15-40"><a href="#cb15-40" tabindex="-1"></a></span>
<span id="cb15-41"><a href="#cb15-41" tabindex="-1"></a>    <span class="co"># ----- 2. True iterable input -----</span></span>
<span id="cb15-42"><a href="#cb15-42" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(refs, (<span class="bu">list</span>, <span class="bu">tuple</span>, np.ndarray)):</span>
<span id="cb15-43"><a href="#cb15-43" tabindex="-1"></a>        cleaned <span class="op">=</span> [<span class="bu">str</span>(x).strip().strip(<span class="st">"[]'</span><span class="ch">\"</span><span class="st"> "</span>) <span class="cf">for</span> x <span class="kw">in</span> refs <span class="cf">if</span> <span class="bu">str</span>(x).strip()]</span>
<span id="cb15-44"><a href="#cb15-44" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"["</span> <span class="op">+</span> <span class="st">", "</span>.join(<span class="ss">f"'</span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">'"</span> <span class="cf">for</span> c <span class="kw">in</span> cleaned) <span class="op">+</span> <span class="st">"]"</span></span>
<span id="cb15-45"><a href="#cb15-45" tabindex="-1"></a></span>
<span id="cb15-46"><a href="#cb15-46" tabindex="-1"></a>    <span class="co"># ----- 3. Treat as string -----</span></span>
<span id="cb15-47"><a href="#cb15-47" tabindex="-1"></a>    s <span class="op">=</span> <span class="bu">str</span>(refs).strip()</span>
<span id="cb15-48"><a href="#cb15-48" tabindex="-1"></a></span>
<span id="cb15-49"><a href="#cb15-49" tabindex="-1"></a>    <span class="co"># Strip outer brackets if present (e.g., "[chen2024]" or "['chen2024']")</span></span>
<span id="cb15-50"><a href="#cb15-50" tabindex="-1"></a>    <span class="cf">if</span> s.startswith(<span class="st">"["</span>) <span class="kw">and</span> s.endswith(<span class="st">"]"</span>):</span>
<span id="cb15-51"><a href="#cb15-51" tabindex="-1"></a>        s <span class="op">=</span> s[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>].strip()</span>
<span id="cb15-52"><a href="#cb15-52" tabindex="-1"></a></span>
<span id="cb15-53"><a href="#cb15-53" tabindex="-1"></a>    <span class="co"># Replace semicolons with commas</span></span>
<span id="cb15-54"><a href="#cb15-54" tabindex="-1"></a>    s <span class="op">=</span> s.replace(<span class="st">";"</span>, <span class="st">","</span>)</span>
<span id="cb15-55"><a href="#cb15-55" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" tabindex="-1"></a>    <span class="co"># Split, strip quotes/spaces</span></span>
<span id="cb15-57"><a href="#cb15-57" tabindex="-1"></a>    parts <span class="op">=</span> [p.strip().strip(<span class="st">"'</span><span class="ch">\"</span><span class="st">"</span>) <span class="cf">for</span> p <span class="kw">in</span> s.split(<span class="st">","</span>) <span class="cf">if</span> p.strip()]</span>
<span id="cb15-58"><a href="#cb15-58" tabindex="-1"></a></span>
<span id="cb15-59"><a href="#cb15-59" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(parts) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-60"><a href="#cb15-60" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"is_blank"</span></span>
<span id="cb15-61"><a href="#cb15-61" tabindex="-1"></a></span>
<span id="cb15-62"><a href="#cb15-62" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(parts) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb15-63"><a href="#cb15-63" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"['</span><span class="sc">{</span>parts[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">']"</span></span>
<span id="cb15-64"><a href="#cb15-64" tabindex="-1"></a></span>
<span id="cb15-65"><a href="#cb15-65" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"["</span> <span class="op">+</span> <span class="st">", "</span>.join(<span class="ss">f"'</span><span class="sc">{</span>p<span class="sc">}</span><span class="ss">'"</span> <span class="cf">for</span> p <span class="kw">in</span> parts) <span class="op">+</span> <span class="st">"]"</span></span>
<span id="cb15-66"><a href="#cb15-66" tabindex="-1"></a></span>
<span id="cb15-67"><a href="#cb15-67" tabindex="-1"></a></span>
<span id="cb15-68"><a href="#cb15-68" tabindex="-1"></a></span>
<span id="cb15-69"><a href="#cb15-69" tabindex="-1"></a><span class="kw">def</span> normalize_answer_value(val: Any) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb15-70"><a href="#cb15-70" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb15-71"><a href="#cb15-71" tabindex="-1"></a><span class="co">    Normalize answer_value so that:</span></span>
<span id="cb15-72"><a href="#cb15-72" tabindex="-1"></a><span class="co">      - single numbers stay as-is (300 -&gt; "300")</span></span>
<span id="cb15-73"><a href="#cb15-73" tabindex="-1"></a><span class="co">      - ranges get bracketed ("300-1000" -&gt; "[300,1000]")</span></span>
<span id="cb15-74"><a href="#cb15-74" tabindex="-1"></a><span class="co">      - lists/tuples become bracketed ranges</span></span>
<span id="cb15-75"><a href="#cb15-75" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb15-76"><a href="#cb15-76" tabindex="-1"></a>    <span class="im">import</span> re</span>
<span id="cb15-77"><a href="#cb15-77" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-78"><a href="#cb15-78" tabindex="-1"></a></span>
<span id="cb15-79"><a href="#cb15-79" tabindex="-1"></a>    <span class="co"># list / tuple / array → always a range</span></span>
<span id="cb15-80"><a href="#cb15-80" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(val, (<span class="bu">list</span>, <span class="bu">tuple</span>, np.ndarray)):</span>
<span id="cb15-81"><a href="#cb15-81" tabindex="-1"></a>        vals <span class="op">=</span> []</span>
<span id="cb15-82"><a href="#cb15-82" tabindex="-1"></a>        <span class="cf">for</span> v <span class="kw">in</span> val:</span>
<span id="cb15-83"><a href="#cb15-83" tabindex="-1"></a>            <span class="co"># convert ints cleanly</span></span>
<span id="cb15-84"><a href="#cb15-84" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(v, (<span class="bu">int</span>, <span class="bu">float</span>)) <span class="kw">and</span> <span class="bu">float</span>(v).is_integer():</span>
<span id="cb15-85"><a href="#cb15-85" tabindex="-1"></a>                vals.append(<span class="bu">str</span>(<span class="bu">int</span>(v)))</span>
<span id="cb15-86"><a href="#cb15-86" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb15-87"><a href="#cb15-87" tabindex="-1"></a>                vals.append(<span class="bu">str</span>(v))</span>
<span id="cb15-88"><a href="#cb15-88" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"["</span> <span class="op">+</span> <span class="st">","</span>.join(vals) <span class="op">+</span> <span class="st">"]"</span></span>
<span id="cb15-89"><a href="#cb15-89" tabindex="-1"></a></span>
<span id="cb15-90"><a href="#cb15-90" tabindex="-1"></a>    <span class="co"># numeric scalar → leave alone</span></span>
<span id="cb15-91"><a href="#cb15-91" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(val, (<span class="bu">int</span>, <span class="bu">float</span>)):</span>
<span id="cb15-92"><a href="#cb15-92" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">float</span>(val).is_integer():</span>
<span id="cb15-93"><a href="#cb15-93" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">str</span>(<span class="bu">int</span>(val))</span>
<span id="cb15-94"><a href="#cb15-94" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">str</span>(val)</span>
<span id="cb15-95"><a href="#cb15-95" tabindex="-1"></a></span>
<span id="cb15-96"><a href="#cb15-96" tabindex="-1"></a>    <span class="co"># string cases</span></span>
<span id="cb15-97"><a href="#cb15-97" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(val, <span class="bu">str</span>):</span>
<span id="cb15-98"><a href="#cb15-98" tabindex="-1"></a>        s <span class="op">=</span> val.strip()</span>
<span id="cb15-99"><a href="#cb15-99" tabindex="-1"></a></span>
<span id="cb15-100"><a href="#cb15-100" tabindex="-1"></a>        <span class="co"># already bracketed</span></span>
<span id="cb15-101"><a href="#cb15-101" tabindex="-1"></a>        <span class="cf">if</span> s.startswith(<span class="st">"["</span>) <span class="kw">and</span> s.endswith(<span class="st">"]"</span>):</span>
<span id="cb15-102"><a href="#cb15-102" tabindex="-1"></a>            <span class="cf">return</span> s</span>
<span id="cb15-103"><a href="#cb15-103" tabindex="-1"></a></span>
<span id="cb15-104"><a href="#cb15-104" tabindex="-1"></a>        <span class="co"># detect range: 300-1000 or 300 – 1000</span></span>
<span id="cb15-105"><a href="#cb15-105" tabindex="-1"></a>        m <span class="op">=</span> re.match(<span class="vs">r"^\s*([0-9]+(?:\.[0-9]+)?)\s*[-–—]\s*([0-9]+(?:\.[0-9]+)?)\s*$"</span>, s)</span>
<span id="cb15-106"><a href="#cb15-106" tabindex="-1"></a>        <span class="cf">if</span> m:</span>
<span id="cb15-107"><a href="#cb15-107" tabindex="-1"></a>            a, b <span class="op">=</span> m.groups()</span>
<span id="cb15-108"><a href="#cb15-108" tabindex="-1"></a>            <span class="co"># strip trailing .0</span></span>
<span id="cb15-109"><a href="#cb15-109" tabindex="-1"></a>            a <span class="op">=</span> a.rstrip(<span class="st">".0"</span>)</span>
<span id="cb15-110"><a href="#cb15-110" tabindex="-1"></a>            b <span class="op">=</span> b.rstrip(<span class="st">".0"</span>)</span>
<span id="cb15-111"><a href="#cb15-111" tabindex="-1"></a>            <span class="cf">return</span> <span class="ss">f"[</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">]"</span></span>
<span id="cb15-112"><a href="#cb15-112" tabindex="-1"></a></span>
<span id="cb15-113"><a href="#cb15-113" tabindex="-1"></a>        <span class="co"># otherwise single value → leave alone</span></span>
<span id="cb15-114"><a href="#cb15-114" tabindex="-1"></a>        <span class="cf">return</span> s</span>
<span id="cb15-115"><a href="#cb15-115" tabindex="-1"></a></span>
<span id="cb15-116"><a href="#cb15-116" tabindex="-1"></a>    <span class="co"># fallback: return string without brackets</span></span>
<span id="cb15-117"><a href="#cb15-117" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">str</span>(val)</span>
<span id="cb15-118"><a href="#cb15-118" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>solutions_df <span class="op">=</span> pd.read_csv(output_dir <span class="op">+</span> <span class="st">"/wattbot_solutions_bedrock.csv"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>solutions_df.head()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>solutions_df[<span class="st">"ref_id"</span>] <span class="op">=</span> solutions_df[<span class="st">"ref_id"</span>].<span class="bu">apply</span>(normalize_ref_ids)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>solutions_df[<span class="st">"answer_value"</span>] <span class="op">=</span> solutions_df[<span class="st">"answer_value"</span>].<span class="bu">apply</span>(normalize_answer_value)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>solutions_df.head()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>solutions_df.to_csv(output_dir <span class="op">+</span> <span class="st">"/solutions_normalized.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>results_df <span class="op">=</span> compute_wattbot_score(</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>    train_qa_path<span class="op">=</span><span class="st">"./data/train_QA.csv"</span>,</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>    preds_path<span class="op">=</span>output_dir <span class="op">+</span> <span class="st">"/solutions_normalized.csv"</span>,</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>    gt_is_na_col<span class="op">=</span><span class="st">"is_NA"</span>,   <span class="co"># or "is_blank" / None depending on how you mark NAs</span></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>    n_examples<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="wrapup-comparing-bedrock-to-gpubased-runs">Wrap‑up: comparing Bedrock to GPU‑based runs<a class="anchor" aria-label="anchor" href="#wrapup-comparing-bedrock-to-gpubased-runs"></a>
</h2>
<hr class="half-width">
<p>At this point you should have three versions of the WattBot
evaluation:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Episode 01 – Notebook GPU instance</strong> using a locally
loaded open‑source model.<br>
</li>
<li>
<strong>Episode 02 – SageMaker Processing job</strong> running the
same model in batch with on-demand compute.</li>
<li>
<strong>Episode 03 – Bedrock</strong> using a hosted Claude 3 model
with per‑token billing.</li>
</ol>
<p>When deciding between these options in practice:</p>
<ul>
<li>Use <strong>Bedrock or other hosted APIs</strong> when:
<ul>
<li>You want to try the latest frontier models quickly.<br>
</li>
<li>You only need to run a modest number of questions, or you are still
prototyping.<br>
</li>
<li>You prefer a simple, token‑based cost model and don’t want to manage
GPU capacity.</li>
</ul>
</li>
<li>Use <strong>self‑hosted models on GPU instances</strong> when:
<ul>
<li>You expect to run large batches repeatedly (e.g., many thousands of
questions).<br>
</li>
<li>You want tight control over which architectures/checkpoints you run
or fine‑tune.<br>
</li>
<li>You already have institutional access to cost‑effective on‑prem or
cloud GPUs.</li>
</ul>
</li>
</ul>
<p>The core <strong>RAG evaluation logic stays identical</strong> across
all three episodes, which is the main takeaway: once you have a clean
retrieval + normalization pipeline (like WattBot’s), swapping out the
generator is mostly a matter of re‑implementing
<code>answer_phase_for_question</code> and
<code>explanation_phase_for_question</code> for each compute option you
care about.</p>
</section><section><h2 class="section-heading" id="concluding-remarks-bedrock-models-are-one-piece-of-the-rag-puzzle">Concluding remarks: Bedrock models are one piece of the RAG
puzzle<a class="anchor" aria-label="anchor" href="#concluding-remarks-bedrock-models-are-one-piece-of-the-rag-puzzle"></a>
</h2>
<hr class="half-width">
<p>In this episode we swapped in Bedrock-hosted models for
<strong>both</strong> embedding and generation. Larger, higher-quality
models can definitely help a ton — especially on messy real-world
questions — but it’s important to remember that they are still just
<strong>one component</strong> in your RAG system.</p>
<ul>
<li>
<strong>Bigger or newer models do not magically fix weak
retrieval.</strong> If your chunks are poorly aligned with the
questions, a very strong LLM will still struggle.</li>
<li>
<strong>Most of the long‑term accuracy gains in RAG systems come
from the plumbing around the LLMs</strong>, including:
<ul>
<li>smarter / semantic chunking strategies</li>
<li>good metadata and filtering</li>
<li>reranking or multi‑stage retrieval</li>
<li>domain‑specific heuristics and post‑processing</li>
</ul>
</li>
<li>
<strong>Cost and latency live in tension with quality.</strong>
Larger models (or higher token budgets) often improve answers, but at
the cost of more inference time and higher per‑request spend. Bedrock
makes it easier to experiment with that tradeoff by switching models
without rewriting your pipeline.</li>
</ul>
<p>As you adapt this notebook to your own projects, treat the LLM choice
as <strong>one tunable component</strong> in a larger system. Iterating
on chunking, indexing, and retrieval policies will almost always give
you more headroom than swapping between already-good models.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>TODO</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-Resource-management-cleanup"><p>Content from <a href="Resource-management-cleanup.html">Resource Management and Monitoring</a></p>
<hr>
<p>Last updated on 2024-11-08 |

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/episodes/Resource-management-cleanup.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I monitor and manage AWS resources to avoid unnecessary
costs?</li>
<li>What steps are necessary to clean up SageMaker and S3 resources
after the workshop?</li>
<li>What best practices can help with efficient resource
utilization?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand how to shut down SageMaker notebook instances to minimize
costs.</li>
<li>Learn to clean up S3 storage and terminate unused training
jobs.</li>
<li>Explore basic resource management strategies and tools for AWS.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="shutting-down-notebook-instances">Shutting down notebook instances<a class="anchor" aria-label="anchor" href="#shutting-down-notebook-instances"></a>
</h2>
<hr class="half-width">
<p>Notebook instances in SageMaker are billed per hour, so it’s
essential to stop or delete them when they are no longer needed. Earlier
in the <strong>Notebooks as controllers</strong> episode, we discussed
using lower-cost instance types like <code>ml.t3.medium</code>
(approximately $0.05/hour) for controlling workflows. While this makes
open notebooks less costly than larger instances, it’s still a good
habit to stop or delete notebooks to avoid unnecessary spending,
especially if left idle for long periods.</p>
<ol style="list-style-type: decimal">
<li><strong>Navigate to SageMaker in the AWS Console.</strong></li>
<li>In the left-hand menu, click <strong>Notebooks</strong>.</li>
<li>Locate your notebook instance and select it.</li>
<li>Choose <strong>Stop</strong> to shut it down temporarily or
<strong>Delete</strong> to permanently remove it. &gt;
<strong>Tip:</strong> If you plan to reuse the notebook later, stopping
it is sufficient. Deleting is recommended if you are finished with the
workshop.</li>
</ol></section><section><h2 class="section-heading" id="cleaning-up-s3-storage">Cleaning up S3 storage<a class="anchor" aria-label="anchor" href="#cleaning-up-s3-storage"></a>
</h2>
<hr class="half-width">
<p>While S3 storage is relatively inexpensive, cleaning up unused
buckets and files helps keep costs minimal and your workspace
organized.</p>
<ol style="list-style-type: decimal">
<li><strong>Navigate to the S3 Console.</strong></li>
<li>Locate the bucket(s) you created for this workshop.</li>
<li>Open the bucket and select any objects (files) you no longer
need.</li>
<li>Click <strong>Delete</strong> to remove the selected objects.</li>
<li>To delete an entire bucket:
<ul>
<li>Empty the bucket by selecting <strong>Empty bucket</strong> under
<strong>Bucket actions</strong>.</li>
<li>Delete the bucket by clicking <strong>Delete bucket</strong>.</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>Reminder:</strong> Earlier in the workshop, we set up tags
for S3 buckets. Use these tags to filter and identify workshop-related
buckets, ensuring that only unnecessary resources are deleted.</p>
</blockquote>
</section><section><h2 class="section-heading" id="monitoring-and-stopping-active-jobs">Monitoring and stopping active jobs<a class="anchor" aria-label="anchor" href="#monitoring-and-stopping-active-jobs"></a>
</h2>
<hr class="half-width">
<p>SageMaker charges for training and tuning jobs while they run, so
make sure to terminate unused jobs.</p>
<ol style="list-style-type: decimal">
<li>In the SageMaker Console, go to <strong>Training Jobs</strong> or
<strong>Tuning Jobs</strong>.</li>
<li>Identify any active jobs that you no longer need.</li>
<li>Select the jobs and click <strong>Stop</strong>. &gt;
<strong>Tip:</strong> Review the job logs to ensure you’ve saved the
results before stopping a job.</li>
</ol></section><section><h2 class="section-heading" id="billing-and-cost-monitoring">Billing and cost monitoring<a class="anchor" aria-label="anchor" href="#billing-and-cost-monitoring"></a>
</h2>
<hr class="half-width">
<p>Managing your AWS expenses is vital to staying within budget. Follow
these steps to monitor and control costs:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Set up billing alerts:</strong>
<ul>
<li>Go to the AWS <strong>Billing Dashboard</strong>.</li>
<li>Navigate to <strong>Budgets</strong> and create a budget alert to
track your spending.</li>
</ul>
</li>
<li>
<strong>Review usage and costs:</strong>
<ul>
<li>Use the AWS <strong>Cost Explorer</strong> in the Billing Dashboard
to view detailed expenses by service, such as SageMaker and S3.</li>
</ul>
</li>
<li>
<strong>Use tags for cost tracking:</strong>
<ul>
<li>Refer to the tags you set up earlier in the workshop for your
notebooks and S3 buckets. These tags help you identify and monitor costs
associated with specific resources.</li>
</ul>
</li>
</ol></section><section><h2 class="section-heading" id="best-practices-for-resource-management">Best practices for resource management<a class="anchor" aria-label="anchor" href="#best-practices-for-resource-management"></a>
</h2>
<hr class="half-width">
<p>Efficient resource management can save significant costs and improve
your workflows. Below are some best practices:</p>
<ul>
<li>
<strong>Automate resource cleanup:</strong> Use AWS SDK or CLI
scripts to automatically shut down instances and clean up S3 buckets
when not in use. <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html" class="external-link">Learn
more about automation with AWS CLI</a>.</li>
<li>
<strong>Schedule resource usage:</strong> Schedule instance start
and stop times using AWS Lambda. <a href="https://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events.html" class="external-link">Learn
how to schedule tasks with AWS Lambda</a>.</li>
<li>
<strong>Test workflows locally first:</strong> Before scaling up
experiments in SageMaker, test them locally to minimize cloud usage and
costs. <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/hosting-alternatives.html" class="external-link">Learn
about SageMaker local mode</a>.</li>
<li>
<strong>Use cost tracking tools:</strong> Explore AWS’s cost
allocation tags and budget tracking features. <a href="https://aws.amazon.com/aws-cost-management/" class="external-link">Learn more about cost
management in AWS</a>.</li>
</ul>
<p>By following these practices and leveraging the additional resources
provided, you can optimize your use of AWS while keeping costs under
control.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Always stop or delete notebook instances when not in use to avoid
charges.</li>
<li>Regularly clean up unused S3 buckets and objects to save on storage
costs.</li>
<li>Monitor your expenses through the AWS Billing Dashboard and set up
alerts.</li>
<li>Use tags (set up earlier in the workshop) to track and monitor costs
by resource.</li>
<li>Following best practices for AWS resource management can
significantly reduce costs and improve efficiency.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/" class="external-link">Source</a></p>
				<p><a href="https://github.com/UW-Madison-DataScience/ml-with-aws-sagemaker/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:endemann@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://UW-Madison-DataScience.github.io/ml-with-aws-sagemaker/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "AWS, SageMaker, Cloud Computing, Machine Learning, AI",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://UW-Madison-DataScience.github.io/ml-with-aws-sagemaker/aio.html",
  "identifier": "https://UW-Madison-DataScience.github.io/ml-with-aws-sagemaker/aio.html",
  "dateCreated": "2024-10-31",
  "dateModified": "2025-11-26",
  "datePublished": "2025-11-26"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

